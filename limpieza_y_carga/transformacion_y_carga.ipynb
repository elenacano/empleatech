{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Llamada a la API de OpenAI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada búsqueda realizada de los distintos empleos en Madrid hemos obtenido varias ofertas de trabajo, de las cuales tenemos su correspondiente descripción. Para cada descripción se pretende obtener cúanto se ajusta dicha oferta al puesto para el cual se realizó la búsqueda, por ejemplo cuanto se ajusta la descripción a un puesto de Data Science, cuál es el nivel de inglés si se pidiera, los años de experiencia si se pidieran, las hard skill necesarias y las hard skills deseables.\n",
    "\n",
    "Para llevar a cabo esta tarea usaremos IA generativa a través de la API de OpenAI, la cual se encargará de llevar a cabo la labor de extraer de cada oferta la información deseada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#from googletrans import Translator\n",
    "from difflib import SequenceMatcher\n",
    "from dotenv import load_dotenv\n",
    "import ast\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src import funciones_transformacion as f_transform\n",
    "from src import funciones_bbdd as f_bbdd\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es obtener el listado de los archivos para ambas plataformas en las que se encuentren las descripciones de las ofertas de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../scraping_infojobs/datos_limpios/infojobs_data_analyst.csv',\n",
       " '../scraping_infojobs/datos_limpios/infojobs_data_engineer.csv',\n",
       " '../scraping_infojobs/datos_limpios/infojobs_data_science.csv',\n",
       " '../scraping_linkedin/data/datos_descripcion_ofertas/linkedin_data_analyst.csv',\n",
       " '../scraping_linkedin/data/datos_descripcion_ofertas/linkedin_data_engineer.csv',\n",
       " '../scraping_linkedin/data/datos_descripcion_ofertas/linkedin_data_science.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_ofertas=[]\n",
    "\n",
    "# Files de infojobs\n",
    "folder_path_infojobs = \"../scraping_infojobs/datos_limpios/\"\n",
    "files_infojobs = os.listdir(folder_path_infojobs)\n",
    "[lista_ofertas.append(folder_path_infojobs + file) for file in files_infojobs]\n",
    "\n",
    "# Files de linkedin\n",
    "folder_path_linkedin = \"../scraping_linkedin/data/datos_descripcion_ofertas/\"\n",
    "files_linkedin = os.listdir(folder_path_linkedin)\n",
    "[lista_ofertas.append(folder_path_linkedin + file) for file in files_linkedin]\n",
    "\n",
    "lista_ofertas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente función de `extracion_datos_descripciones` se encargá de extraer de la descripción los años de experiencia que piden, el nivel de inglés, las hard skills necesarias, las hard skill deseables y un porcentaje de ajuste. Este porcetaje representa cuanto se ajusta la descripción de la oferta en cuanto al puesto para el que se realizó la busqueda, por ejemplo, Data analyst. Todos estos datos se añadirán a un json que se irá almacenando en la carpeta `data/response_openai` en este mismo directorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Analizando el archivo -infojobs_data_analyst.csv- de la categoria: Data analyst, con shape: (108, 9)\n",
      "Analizando el archivo -infojobs_data_engineer.csv- de la categoria: Data engineer, con shape: (73, 9)\n",
      "Analizando el archivo -infojobs_data_science.csv- de la categoria: Data science, con shape: (39, 9)\n",
      "Analizando el archivo -linkedin_data_analyst.csv- de la categoria: Data analyst, con shape: (934, 8)\n",
      "Analizando el archivo -linkedin_data_engineer.csv- de la categoria: Data engineer, con shape: (948, 8)\n",
      "Analizando el archivo -linkedin_data_science.csv- de la categoria: Data science, con shape: (745, 8)\n"
     ]
    }
   ],
   "source": [
    "f_transform.extracion_datos_descripciones(lista_ofertas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Limpieza de los JSON**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos las skills de cada oferta hay que hacer un primer filtrado general de estas skills pues en total tenemos alrededor de 3000. Por lo tanto vamos a agrupar skills que se refieren a una herramienta pero han sido recogidas con distintos nombres en cada oferta como: PowerBi, Power BI, experto en PowerBi, todo ello lo pasaremos a un mismo término y asi se pretende reducir el número de skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtrando las skills del archivo: transformed_infojobs_data_analyst.json\n",
      "Filtrando las skills del archivo: transformed_infojobs_data_engineer.json\n",
      "Filtrando las skills del archivo: transformed_infojobs_data_science.json\n",
      "Filtrando las skills del archivo: transformed_linkedin_data_analyst.json\n",
      "Filtrando las skills del archivo: transformed_linkedin_data_engineer.json\n",
      "Filtrando las skills del archivo: transformed_linkedin_data_science.json\n",
      "\n",
      "Skills filtradas y guardadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "f_transform.extraer_y_guardar_skills_filtradas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos cuantas skills en total había antes y después del filtrado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contando skills de los archivos: ['transformed_infojobs_data_analyst.json', 'transformed_infojobs_data_engineer.json', 'transformed_infojobs_data_science.json', 'transformed_linkedin_data_analyst.json', 'transformed_linkedin_data_engineer.json', 'transformed_linkedin_data_science.json']\n",
      "Se han encontrado 3210 skills diferentes.\n",
      "\n",
      "Contando skills de los archivos: ['filtered_transformed_infojobs_data_analyst.json', 'filtered_transformed_infojobs_data_engineer.json', 'filtered_transformed_infojobs_data_science.json', 'filtered_transformed_linkedin_data_analyst.json', 'filtered_transformed_linkedin_data_engineer.json', 'filtered_transformed_linkedin_data_science.json']\n",
      "Se han encontrado 2464 skills diferentes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lista_skills = f_transform.contador_skills(\"data/response_openai/\")\n",
    "\n",
    "lista_skills = f_transform.contador_skills(\"data/skills_filtradas/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos conseguido reducir el número total de skills unas 800, sin embargo, seguir manteniendo 2400 skills es inviable, pues para que el recomendador funcione el usuario deberá chequear si tiene conocimientos en cada una de ellas o no, y revisar una lista de más de 2000 skills no es una opción realista.\n",
    "\n",
    "Por lo tanto, para cada uno de los tres empleos vamos a ver cuales son las skills que más se repiten y haremos una lista con únicamente las más importante para cada oferta de trabajo. Tendremos que filtrar nuevamente las ofertas y dejar solo las skills que estén en la lista de hard skills generada en el paso anterior y la cual podremos encontrar en `data/lista_hard_skills.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han guardado 110 skills relevantes en 'data/lista_hard_skills.pkl'\n",
      "\n",
      "Limpiando las skills de las ofertas, manteniendo solo las más relevantes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:00<00:00, 232.39it/s]\n",
      "100%|██████████| 73/73 [00:00<00:00, 292.03it/s]\n",
      "100%|██████████| 39/39 [00:00<00:00, 471.65it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 120.84it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 120.60it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 120.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completado!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "skills_relevantes = f_transform.filtrar_skills_min_apariciones(5)\n",
    "f_transform.filtracion_hard_skills_relevantes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que efectivamente tras el filtrado nos ha quedado el mismo número de skills que en la lista:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contando skills de los archivos: ['relevant_filtered_transformed_infojobs_data_analyst.json', 'relevant_filtered_transformed_infojobs_data_engineer.json', 'relevant_filtered_transformed_infojobs_data_science.json', 'relevant_filtered_transformed_linkedin_data_analyst.json', 'relevant_filtered_transformed_linkedin_data_engineer.json', 'relevant_filtered_transformed_linkedin_data_science.json']\n",
      "Se han encontrado 110 skills diferentes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lista_skills = f_transform.contador_skills(\"data/skills_filtradas_relevantes/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Carga de datos en MongoDB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos limpiado las skills de todas las ofertas de trabajo y las hemos almacenado en los correspondientes `json` el siguiente paso es subir todos estos datos a una base de datos en la nube. En este caso al ser tablas no relacionales hemos escogido MongoDB y los datos se subiran a MongoDB Atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n",
      "Insertando file: relevant_relevant_filtered_transformed_infojobs_data_analyst.json\n",
      "Insertando file: relevant_relevant_filtered_transformed_infojobs_data_engineer.json\n",
      "Insertando file: relevant_relevant_filtered_transformed_infojobs_data_science.json\n",
      "Insertando file: relevant_relevant_filtered_transformed_linkedin_data_analyst.json\n",
      "Insertando file: relevant_relevant_filtered_transformed_linkedin_data_engineer.json\n",
      "Insertando file: relevant_relevant_filtered_transformed_linkedin_data_science.json\n",
      "---- Insercion en la base de datos finalizada ----\n",
      "\n",
      "Pinged your deployment. You successfully connected to MongoDB!\n",
      "Skills insertadas en la base de datos correctamente.\n"
     ]
    }
   ],
   "source": [
    "f_bbdd.cargar_datos_mongo()\n",
    "f_bbdd.cargar_skills_mongo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto_final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
