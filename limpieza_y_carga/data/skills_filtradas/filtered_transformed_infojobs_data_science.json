[
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Scientist - Computer Vision",
        "empresa": "Tinamica, S.L.",
        "fecha_publicacion": "Publicada el 14 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-scientist-computer-vision/of-i365f1de1774eadbe4b4de24180a019?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior - Informática y Comunicaciones\nExperiencia mínima\nAl menos 3 años\nImprescindible residente en\nProvincia Puesto Vacante\nIdiomas requeridos\nEspañol - Nivel Nativo o Bilingüe\nConocimientos necesarios\nOpenCV (Open source Computer Vision)\nPython\nSQL\ntensorflow\nPytorch\nBig data\nedge\nGestión de datos\nDescripción\nEn Tinámica, somos pioneros en el desarrollo de soluciones avanzadas de Big Data, Analítica e Inteligencia Artificial. Nuestro equipo está en crecimiento, y buscamos un Data Scientists Senior especializados en Computer Vision que quieran liderar proyectos estratégicos de gran impacto en la transformación digital de diversas industrias.\nSi tienes amplia experiencia técnica, pasión por resolver desafíos complejos y el deseo de desarrollar soluciones innovadoras, queremos conocerte.\nLo Que Harás:\n- Diseñar y desplegar modelos de Computer Vision: Serás responsable de todo el ciclo de vida, desde la exploración inicial de datos hasta la puesta en producción de modelos avanzados (detección de objetos, segmentación, reconocimiento facial, IA generativa, etc.).\n- Optimizar modelos: Trabajarás con grandes volúmenes de imágenes y datos relacionados, ajustando modelos para garantizar precisión, eficiencia y escalabilidad.\n- Aplicar IA en proyectos innovadores: Explorarás y aplicarás tecnologías de vanguardia en IA, incluyendo redes neuronales convolucionales (CNN), Vision Transformers y herramientas de IA generativa.\n- Integrar soluciones en entornos reales: Desarrollarás APIs personalizadas para integrar modelos en aplicaciones empresariales y optimizarás infraestructuras para garantizar la eficiencia en cloud y on-premises.\n- Colaborar en proyectos multidisciplinares: Formarás parte de equipos con diferentes especializaciones, asegurando que las soluciones de Computer Vision impacten positivamente en nuestros clientes.\n- Asegurar la calidad del código: Implementarás estándares de desarrollo y participarás en revisiones de código para garantizar la robustez y escalabilidad de nuestras soluciones.\nRequisitos Clave:\n- Más de 3 años de experiencia como Data Scientist, con un enfoque destacado en Computer Vision.\n- Dominio de frameworks como TensorFlow, PyTorch o Keras: - Experiencia demostrable en el desarrollo y despliegue de modelos de Computer Vision.\n- Amplia experiencia en Git y SQL: Imprescindibles para la gestión de datos y control de versiones en proyectos complejos.\n- Conocimientos avanzados de Python: Uso de patrones de diseño y buenas prácticas para garantizar la calidad y eficiencia del código.\n- Experiencia en el despliegue de modelos en entornos cloud: Preferiblemente en Azure, aunque se valorará experiencia en AWS, GCP y tecnologías como Docker/Kubernetes.\n- Familiaridad con servicios de IA y APIs: Experiencia en la creación e integración de APIs para servir predicciones en tiempo real.\n- Conocimientos en procesamiento de imágenes: Familiaridad con OpenCV, PIL y otras librerías especializadas.\nQué Ofrecemos:\n- Proyectos de alto impacto: Participarás en iniciativas disruptivas donde la visión por computadora transforma sectores estratégicos.\n- Entorno de trabajo flexible: Combinamos trabajo remoto y presencial según tus necesidades.\n- Desarrollo profesional continuo: Acceso a formación, eventos y certificaciones para mantenerte siempre a la vanguardia.\n- Salario competitivo y beneficios: Alineados con tu experiencia y las exigencias del rol.\n¿Estás listo/a para liderar proyectos de Computer Vision que transforman industrias?\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEspecialista\nPersonal a cargo\n1 - 5\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nPorcentaje sobre objetivos\nFlexibilidad horaria\nTeletrabajo\nSeguro médico\nCheque restaurante\n24 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior - Informática y Comunicaciones<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Imprescindible residente en<br>Provincia Puesto Vacante<br>Idiomas requeridos<br>Español - Nivel Nativo o Bilingüe<br>Conocimientos necesarios<br>OpenCV (Open source Computer Vision)<br>Python<br>SQL<br>tensorflow<br>Pytorch<br>Big data<br>edge<br>Gestión de datos<br><br><h3>Descripción</h3><br>En Tinámica, somos pioneros en el desarrollo de soluciones avanzadas de Big Data, Analítica e Inteligencia Artificial. Nuestro equipo está en crecimiento, y buscamos un Data Scientists Senior especializados en Computer Vision que quieran liderar proyectos estratégicos de gran impacto en la transformación digital de diversas industrias.<br>Si tienes amplia experiencia técnica, pasión por resolver desafíos complejos y el deseo de desarrollar soluciones innovadoras, queremos conocerte.<br>Lo Que Harás:<br>- Diseñar y desplegar modelos de Computer Vision: Serás responsable de todo el ciclo de vida, desde la exploración inicial de datos hasta la puesta en producción de modelos avanzados (detección de objetos, segmentación, reconocimiento facial, IA generativa, etc.).<br>- Optimizar modelos: Trabajarás con grandes volúmenes de imágenes y datos relacionados, ajustando modelos para garantizar precisión, eficiencia y escalabilidad.<br>- Aplicar IA en proyectos innovadores: Explorarás y aplicarás tecnologías de vanguardia en IA, incluyendo redes neuronales convolucionales (CNN), Vision Transformers y herramientas de IA generativa.<br>- Integrar soluciones en entornos reales: Desarrollarás APIs personalizadas para integrar modelos en aplicaciones empresariales y optimizarás infraestructuras para garantizar la eficiencia en cloud y on-premises.<br>- Colaborar en proyectos multidisciplinares: Formarás parte de equipos con diferentes especializaciones, asegurando que las soluciones de Computer Vision impacten positivamente en nuestros clientes.<br>- Asegurar la calidad del código: Implementarás estándares de desarrollo y participarás en revisiones de código para garantizar la robustez y escalabilidad de nuestras soluciones.<br><br><h3>Requisitos</h3> Clave:<br>- Más de 3 años de experiencia como Data Scientist, con un enfoque destacado en Computer Vision.<br>- Dominio de frameworks como TensorFlow, PyTorch o Keras: - Experiencia demostrable en el desarrollo y despliegue de modelos de Computer Vision.<br>- Amplia experiencia en Git y SQL: Imprescindibles para la gestión de datos y control de versiones en proyectos complejos.<br>- Conocimientos avanzados de Python: Uso de patrones de diseño y buenas prácticas para garantizar la calidad y eficiencia del código.<br>- Experiencia en el despliegue de modelos en entornos cloud: Preferiblemente en Azure, aunque se valorará experiencia en AWS, GCP y tecnologías como Docker/Kubernetes.<br>- Familiaridad con servicios de IA y APIs: Experiencia en la creación e integración de APIs para servir predicciones en tiempo real.<br>- Conocimientos en procesamiento de imágenes: Familiaridad con OpenCV, PIL y otras librerías especializadas.<br>Qué Ofrecemos:<br>- Proyectos de alto impacto: Participarás en iniciativas disruptivas donde la visión por computadora transforma sectores estratégicos.<br>- Entorno de trabajo flexible: Combinamos trabajo remoto y presencial según tus necesidades.<br>- Desarrollo profesional continuo: Acceso a formación, eventos y certificaciones para mantenerte siempre a la vanguardia.<br>- Salario competitivo y beneficios: Alineados con tu experiencia y las exigencias del rol.<br>¿Estás listo/a para liderar proyectos de Computer Vision que transforman industrias?<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Especialista<br>Personal a cargo<br>1 - 5<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Porcentaje sobre objetivos<br>Flexibilidad horaria<br>Teletrabajo<br>Seguro médico<br>Cheque restaurante<br>24 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "3",
            "porcentaje": "85",
            "skills_necesarias": [
                "OpenCV",
                "Python",
                "SQL",
                "TensorFlow",
                "PyTorch",
                "Big Data",
                "Data Management"
            ],
            "skills_valoradas": [
                "Docker",
                "Kubernetes",
                "Azure",
                "AWS",
                "GCP (Google Cloud Platform)",
                "API",
                "PIL"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Scientist Junior",
        "empresa": "Tinamica, S.L.",
        "fecha_publicacion": "Publicada el 14 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-scientist-junior/of-i8451ab2cf84557857dd1cabfe08294?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Medio\nExperiencia mínima\nNo Requerida\nImprescindible residente en\nProvincia Puesto Vacante\nConocimientos necesarios\nSQL\nMatlab\nPython\nGit\nDescripción\n¿Estás list@ para iniciar tu carrera en el mundo del Data Science y la ingeniería de datos? ¿Te interesa trabajar en un entorno dinámico donde tu desarrollo profesional sea una prioridad? En Tinámica, buscamos un Data Scientist Junior que quiera crecer con nosotr@s y ser parte de un proyecto en el que podrás aplicar tus conocimientos y adquirir nuevas habilidades.\n¿Cómo será tu día a día?\n- Analizar y preparar datos para el desarrollo de modelos predictivos y algoritmos avanzados.\n- Diseñar y optimizar flujos de datos, asegurando la integración de fuentes de datos diversas.\n- Desarrollar y mantener scripts y pipelines de datos utilizando Python y Matlab.\n- Implementar consultas SQL para extraer y manipular grandes volúmenes de datos.\n- Colaborar con el equipo de desarrollo en la implementación de soluciones utilizando Git para el control de versiones.\n¿Qué valoramos?\n- Python: Experiencia inicial en programación con Python para manipulación de datos y automatización de procesos.\n- Conocimientos básicos de COmputer Vision (Tensorflow o Pytorch)\n- SQL: Habilidad para trabajar con bases de datos y escribir consultas para la extracción y manipulación de datos.\n- Git: Familiaridad con el control de versiones.\nLo que ofrecemos:\n- Un proyecto apasionante donde podrás desarrollar tus conocimientos y aprender de un equipo experto.\n- Contrato indefinido para que puedas enfocarte en crecer sin preocupaciones.\n- Formación continua y acceso a instituciones de prestigio en Madrid.\n- Programa de mentoring para guiarte en tu desarrollo profesional.\n- Colaboración con equipos de alto nivel en proyectos para clientes líderes del sector.\n- Salario competitivo y revisiones salariales periódicas.\n- Seguro médico gratuito, 26 días de vacaciones y otros beneficios adaptables (cheques guardería, tickets restaurante, etc.).\n- Modalidad híbrida de trabajo, con flexibilidad para que concilies tu vida personal y profesional.\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nBecario/a - Prácticas\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nPorcentaje sobre objetivos\nFlexibilidad horaria\nTeletrabajo\nSeguro médico\nCheque restaurante\n418 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Medio<br><h4>Experiencia mínima</h4><br>No Requerida<br>Imprescindible residente en<br>Provincia Puesto Vacante<br>Conocimientos necesarios<br>SQL<br>Matlab<br>Python<br>Git<br><br><h3>Descripción</h3><br>¿Estás list@ para iniciar tu carrera en el mundo del Data Science y la ingeniería de datos? ¿Te interesa trabajar en un entorno dinámico donde tu desarrollo profesional sea una prioridad? En Tinámica, buscamos un Data Scientist Junior que quiera crecer con nosotr@s y ser parte de un proyecto en el que podrás aplicar tus conocimientos y adquirir nuevas habilidades.<br>¿Cómo será tu día a día?<br>- Analizar y preparar datos para el desarrollo de modelos predictivos y algoritmos avanzados.<br>- Diseñar y optimizar flujos de datos, asegurando la integración de fuentes de datos diversas.<br>- Desarrollar y mantener scripts y pipelines de datos utilizando Python y Matlab.<br>- Implementar consultas SQL para extraer y manipular grandes volúmenes de datos.<br>- Colaborar con el equipo de desarrollo en la implementación de soluciones utilizando Git para el control de versiones.<br>¿Qué valoramos?<br>- Python: Experiencia inicial en programación con Python para manipulación de datos y automatización de procesos.<br>- Conocimientos básicos de COmputer Vision (Tensorflow o Pytorch)<br>- SQL: Habilidad para trabajar con bases de datos y escribir consultas para la extracción y manipulación de datos.<br>- Git: Familiaridad con el control de versiones.<br>Lo que ofrecemos:<br>- Un proyecto apasionante donde podrás desarrollar tus conocimientos y aprender de un equipo experto.<br>- Contrato indefinido para que puedas enfocarte en crecer sin preocupaciones.<br>- Formación continua y acceso a instituciones de prestigio en Madrid.<br>- Programa de mentoring para guiarte en tu desarrollo profesional.<br>- Colaboración con equipos de alto nivel en proyectos para clientes líderes del sector.<br>- Salario competitivo y revisiones salariales periódicas.<br>- Seguro médico gratuito, 26 días de vacaciones y otros beneficios adaptables (cheques guardería, tickets restaurante, etc.).<br>- Modalidad híbrida de trabajo, con flexibilidad para que concilies tu vida personal y profesional.<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Becario/a - Prácticas<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Porcentaje sobre objetivos<br>Flexibilidad horaria<br>Teletrabajo<br>Seguro médico<br>Cheque restaurante<br>418 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "No Requerida",
            "porcentaje": "70",
            "skills_necesarias": [
                "SQL",
                "Matlab",
                "Python",
                "Git"
            ],
            "skills_valoradas": [
                "Computer Vision",
                "TensorFlow",
                "PyTorch"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "DataOps Engineer (hybrid work)",
        "empresa": "SERIT CONSULTING",
        "fecha_publicacion": "Publicada hace 1d (Publicada de nuevo)",
        "min_salario": "36.000€",
        "max_salario": "42.000€",
        "url_oferta": "https://www.infojobs.net/madrid/dataops-engineer-hybrid-work/of-ib91596ec474103b93ba81de92b971a?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior - Informática y Comunicaciones\nExperiencia mínima\nAl menos 3 años\nImprescindible residente en\nNo Requerido\nIdiomas requeridos\nInglés - Nivel Avanzado\nConocimientos necesarios\nSCALA\nSPARK\nSQL\nKAFKA\nApache\nS3 Storage\nJenkins\nGitlab\nKubernetes\nElasticsearch\nDescripción\nSERIT is looking for a skilled Data Engineer in a hybrid work model based in Madrid.\nROLE\nAs a Data Engineer, you will be responsible for:\n* Building and maintaining data pipelines with Spark on Scala to process data from diverse sources likeKafka topics, APIs, and HDFS.\n* Ensuring data quality and consistency for robust decision-making.\nImplementing and managing CI/CD pipelines using tools like GitLab and Jenkins.\n* Setting up orchestration processes with Apache Airflow to automate data pipelines.\n* Collaborating on production support, incident resolutions, and continuous code improvements.\n* Writing technical documentation to support knowledge sharing and team growth\nQUALIFICATIONS\nSpark on Scala, Apache Airflow, Kafka, SQL, HDFS, and S3 Storage.\nCI/CD tools (GitLab, Jenkins, etc.).\nExposure to Kubernetes, Elasticsearch, Dremio, Shell scripting, and Dataiku is a plus.\nExperience in data engineering, preferably within the banking industry.\nFluency in English (C1 or higher) - this is a must as English is the daily working language.\nFrench (B1) is a bonus.\nReferencia\n1701-Mad- HibMad (Ing)\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario: 36.000€ - 42.000€ Bruto/año\nBeneficios sociales\nTeletrabajo\n7 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior - Informática y Comunicaciones<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Imprescindible residente en<br>No Requerido<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br>Conocimientos necesarios<br>SCALA<br>SPARK<br>SQL<br>KAFKA<br>Apache<br>S3 Storage<br>Jenkins<br>Gitlab<br>Kubernetes<br>Elasticsearch<br><br><h3>Descripción</h3><br>SERIT is looking for a skilled Data Engineer in a hybrid work model based in Madrid.<br>ROLE<br>As a Data Engineer, you will be responsible for:<br>* Building and maintaining data pipelines with Spark on Scala to process data from diverse sources likeKafka topics, APIs, and HDFS.<br>* Ensuring data quality and consistency for robust decision-making.<br>Implementing and managing CI/CD pipelines using tools like GitLab and Jenkins.<br>* Setting up orchestration processes with Apache Airflow to automate data pipelines.<br>* Collaborating on production support, incident resolutions, and continuous code improvements.<br>* Writing technical documentation to support knowledge sharing and team growth<br>QUALIFICATIONS<br>Spark on Scala, Apache Airflow, Kafka, SQL, HDFS, and S3 Storage.<br>CI/CD tools (GitLab, Jenkins, etc.).<br>Exposure to Kubernetes, Elasticsearch, Dremio, Shell scripting, and Dataiku is a plus.<br>Experience in data engineering, preferably within the banking industry.<br>Fluency in English (C1 or higher) - this is a must as English is the daily working language.<br>French (B1) is a bonus.<br>Referencia<br>1701-Mad- HibMad (Ing)<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario: 36.000€ - 42.000€ Bruto/año<br>Beneficios sociales<br>Teletrabajo<br>7 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "3",
            "porcentaje": "85",
            "skills_necesarias": [
                "Scala",
                "PySpark",
                "SQL",
                "Kafka",
                "Apache",
                "S3 Storage",
                "Jenkins",
                "Git",
                "Kubernetes",
                "Elasticsearch"
            ],
            "skills_valoradas": [
                "Airflow",
                "Dremio",
                "Shell",
                "Dataiku"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "TECNICO DE DATA",
        "empresa": "GESEIN",
        "fecha_publicacion": "Publicada hace 1d",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/tecnico-data/of-i429d3dcb02427e8574613a8d0b998e?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Medio\nExperiencia mínima\nAl menos 3 años\nConocimientos necesarios\nETL\nModelado\nConsultoría\nPentaho\nOracle\nModelado de datos\nRequisitos mínimos\nBase de datos Oracle\nModelado de datos\nConocimientos técnicos en la herramienta de ETL Pentaho\nDescripción\nGesein, consultoría tecnológica con 30 años de experiencia, precisa incorporar en su organización:\nTécnico de Data con experiencia en Base de datos Oracle, Modelado de datos, Conocimientos técnicos en la herramienta de ETL Pentaho.\nProyecto en Madrid.\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\n9 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Medio<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Conocimientos necesarios<br>ETL<br>Modelado<br>Consultoría<br>Pentaho<br>Oracle<br>Modelado de datos<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>Base de datos Oracle<br>Modelado de datos<br>Conocimientos técnicos en la herramienta de ETL Pentaho<br><br><h3>Descripción</h3><br>Gesein, consultoría tecnológica con 30 años de experiencia, precisa incorporar en su organización:<br>Técnico de Data con experiencia en Base de datos Oracle, Modelado de datos, Conocimientos técnicos en la herramienta de ETL Pentaho.<br>Proyecto en Madrid.<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>9 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "3",
            "porcentaje": "70",
            "skills_necesarias": [
                "ETL",
                "Modelado",
                "Pentaho",
                "Oracle"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data engineer(Spark+Python)-Madrid",
        "empresa": "Luca TIC",
        "fecha_publicacion": "Publicada hace 1d",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-spark-python-madrid/of-i653c5676894d828849c2e3f66ea371?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 1 año\nConocimientos necesarios\nPython\nBanca\nInversiones\nBanca privada\nETL\nSector banca\nspark\nPostgreSQL\nSQL\nhibrido\nDescripción\nDesde Luca TIC buscamos un Data engineer para un proyecto del sector bancario.\nRequisitos :\n-Experiencia en el desarrollo de pipelines ETL con Apache Spark y Python.\n-Conocimiento práctico de servicios AWS como S3, RDS (PostgreSQL) e IAM, AWS Glue, Amazon EMR y Lambda.\n-Sólidas habilidades en SQL.\n-Familiaridad con sistemas de control de versiones y flujos de CI/CD.\n-Experiencia con procesamiento de datos en tiempo real (deseable).\nCertificación AWS en relación con datos o arquitecturas cloud (deseable).\nConocimiento de conceptos de inversiones y modelos de datos de banca privada (deseable).\nBuen nivel de inglés B2 (deseable).\n¿Qué ofrecemos?:\n-Contrato indefinido.\n-Modalidad hibrida (4 oficina + 1 casa)+ teletrabajo meses verano y navidad.\n-Seguro médico.\n-Formar parte de un ambiente innovador en constante crecimiento donde desarrollar tu carrera profesional.\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Telecomunicaciones\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\nSeguro médico\n10 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br>Conocimientos necesarios<br>Python<br>Banca<br>Inversiones<br>Banca privada<br>ETL<br>Sector banca<br>spark<br>PostgreSQL<br>SQL<br>hibrido<br><br><h3>Descripción</h3><br>Desde Luca TIC buscamos un Data engineer para un proyecto del sector bancario.<br><br><h3>Requisitos</h3> :<br>-Experiencia en el desarrollo de pipelines ETL con Apache Spark y Python.<br>-Conocimiento práctico de servicios AWS como S3, RDS (PostgreSQL) e IAM, AWS Glue, Amazon EMR y Lambda.<br>-Sólidas habilidades en SQL.<br>-Familiaridad con sistemas de control de versiones y flujos de CI/CD.<br>-Experiencia con procesamiento de datos en tiempo real (deseable).<br>Certificación AWS en relación con datos o arquitecturas cloud (deseable).<br>Conocimiento de conceptos de inversiones y modelos de datos de banca privada (deseable).<br>Buen nivel de inglés B2 (deseable).<br>¿Qué ofrecemos?:<br>-Contrato indefinido.<br>-Modalidad hibrida (4 oficina + 1 casa)+ teletrabajo meses verano y navidad.<br>-Seguro médico.<br>-Formar parte de un ambiente innovador en constante crecimiento donde desarrollar tu carrera profesional.<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Telecomunicaciones<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>Seguro médico<br>10 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B2",
            "anios_experiencia": "1",
            "porcentaje": "75",
            "skills_necesarias": [
                "Python",
                "ETL",
                "PySpark",
                "SQL",
                "AWS"
            ],
            "skills_valoradas": [
                "Procesamiento de datos en tiempo real",
                "AWS",
                "Conocimientos de inversiones",
                "Modelos de datos de banca privada"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "DATA DEVELOPER",
        "empresa": "Laboratorios Normon",
        "fecha_publicacion": "Publicada hace 1d",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/tres-cantos/data-developer/of-i32c990a4e14786adbaeb9d83358a43?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior - Informática y Comunicaciones\nExperiencia mínima\nAl menos 2 años\nImprescindible residente en\nProvincia Puesto Vacante\nIdiomas requeridos\nInglés - Nivel Avanzado\nRequisitos mínimos\n-Experiencia indispensable con git/github y dbt para transformación y documentación.\n- Experiencia en la gestión de bbdd, elaboración de pipelines completos de integración de datos.\n- Experiencia en el manejo de sql avanzado y python para modelado de datos\n- Deseable experiencia con tablas de SAP, Datasphere, Snowflake, y manejo de diferentes servers como Azure o AWS.\nDescripción\n¿Cómo será un día de trabajo como Data Developer?\nAyudar en la definición de esquemas de bases de datos y estructuras de almacenamiento eficientes para los proyectos de datos.\nDesarrollar y mantener pipelines de datos simples, transformando y cargando datos desde diversas fuentes (ETL).\nAplicar técnicas básicas de limpieza y transformación de datos para garantizar que la información esté lista para análisis.\nManejo de bases de datos y mantenimiento en bases de datos (ajustes de rendimiento, limpieza de datos, etc.).\nColaborar en la optimización de los flujos de datos, identificando cuellos de botella y mejorando la eficiencia de los procesos.\nRealizar análisis básicos de los conjuntos de datos, utilizando estadísticas descriptivas y visualizaciones sencillas.\nImplementar modelos básicos de machine learning (regresión, clasificación, etc.), utilizando bibliotecas como scikit-learn o similares.\nAplicar buenas prácticas de seguridad en el manejo de datos, asegurando su privacidad y protección.\nTrabajar de manera cercana con otros departamentos (IT, negocio, producto) para garantizar que las soluciones de datos estén alineadas con las necesidades del negocio.\nMantener una buena documentación de los procesos, herramientas y modelos desarrollados, para facilitar su entendimiento por parte de otros miembros del equipo.\nIdentificar oportunidades de mejora en los flujos y procesos de datos existentes, proponiendo soluciones que optimicen el trabajo en equipo.\nTipo de industria de la oferta\nIndustria farmaceútica\nCategoría\nInformática y telecomunicaciones - ERP, CRM, Business Intelligence\nDepartamento\nPlanificación Estratégica\nNivel\nEmpleado/a\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\nOtros beneficios:\nComedor, Servicio Médico, Lanzaderas (transporte)\n13 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior - Informática y Comunicaciones<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Imprescindible residente en<br>Provincia Puesto Vacante<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Experiencia indispensable con git/github y dbt para transformación y documentación.<br>- Experiencia en la gestión de bbdd, elaboración de pipelines completos de integración de datos.<br>- Experiencia en el manejo de sql avanzado y python para modelado de datos<br>- Deseable experiencia con tablas de SAP, Datasphere, Snowflake, y manejo de diferentes servers como Azure o AWS.<br><br><h3>Descripción</h3><br>¿Cómo será un día de trabajo como Data Developer?<br>Ayudar en la definición de esquemas de bases de datos y estructuras de almacenamiento eficientes para los proyectos de datos.<br>Desarrollar y mantener pipelines de datos simples, transformando y cargando datos desde diversas fuentes (ETL).<br>Aplicar técnicas básicas de limpieza y transformación de datos para garantizar que la información esté lista para análisis.<br>Manejo de bases de datos y mantenimiento en bases de datos (ajustes de rendimiento, limpieza de datos, etc.).<br>Colaborar en la optimización de los flujos de datos, identificando cuellos de botella y mejorando la eficiencia de los procesos.<br>Realizar análisis básicos de los conjuntos de datos, utilizando estadísticas descriptivas y visualizaciones sencillas.<br>Implementar modelos básicos de machine learning (regresión, clasificación, etc.), utilizando bibliotecas como scikit-learn o similares.<br>Aplicar buenas prácticas de seguridad en el manejo de datos, asegurando su privacidad y protección.<br>Trabajar de manera cercana con otros departamentos (IT, negocio, producto) para garantizar que las soluciones de datos estén alineadas con las necesidades del negocio.<br>Mantener una buena documentación de los procesos, herramientas y modelos desarrollados, para facilitar su entendimiento por parte de otros miembros del equipo.<br>Identificar oportunidades de mejora en los flujos y procesos de datos existentes, proponiendo soluciones que optimicen el trabajo en equipo.<br>Tipo de industria de la oferta<br>Industria farmaceútica<br>Categoría<br>Informática y telecomunicaciones - ERP, CRM, Business Intelligence<br>Departamento<br>Planificación Estratégica<br>Nivel<br>Empleado/a<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>Otros beneficios:<br>Comedor, Servicio Médico, Lanzaderas (transporte)<br>13 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "2",
            "porcentaje": "80",
            "skills_necesarias": [
                "Git",
                "DBT (Data Build Tool)",
                "SQL",
                "Python",
                "ETL",
                "Machine Learning",
                "Sklearn"
            ],
            "skills_valoradas": [
                "SAP",
                "Datasphere",
                "Snowflake",
                "Azure",
                "AWS"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer (Azure)",
        "empresa": "CAS Training",
        "fecha_publicacion": "Publicada hace 1d",
        "min_salario": "33.000€",
        "max_salario": "36.000€",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-azure/of-i2e2071eccb4cc495ab1b7db7e3c5c8?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nOtros títulos, certificaciones y carnés\nExperiencia mínima\nAl menos 3 años\nConocimientos necesarios\nAzure\nDatabricks\nSynapse\nData Factory\nSQL\nRequisitos mínimos\n- Experiencia entre 3-4 en arquitecturas Azure: Databricks, Synapse, Datafactory, SQL Database.\n- Nivel de inglés avanzado (mínimo B2)\n- Imprescindible experiencia y autonomía en el diseño y la creación de modelos de datos (definición y creación de tablas, complejidad de relaciones y de queries, grandes volumetrías, procedimientos almacenados...)\n- Imprescindible experiencia en el desarrollo de pipelines y transformaciones de datos complejas (ETLs).\n- Buen nivel de SQL e idealmente experiencia con Python.\n- Experiencia en proyectos agile o Valorable conocimiento y experiencia con metodologías y herramientas para despliegue e integración continua (Azure DevOps, Github, Jenkins, Terraform, Docker, Ansible…)\nRequisitos valorables:\n- Conocimiento/experiencia en Spark/Pyspark.\nDescripción\nEn CAS Training, empresa de referencia con más de 20 años en consultoría tecnológica, outsourcing y formación especializada, estamos buscando a un/a Data Engineer con experiencia en arquitecturas Azure.\nSe ofrece:\n• Formar parte de un equipo dinámico altamente cualificado en una empresa en proceso de expansión.\n• Participar en proyectos innovadores y punteros para grandes clientes de primer nivel en distintos sectores de mercado.\n• Proyectos de larga duración, estabilidad profesional y progresión laboral.\n• Contratación Indefinida.\n• Acceso gratuito al catálogo de formación anual de Cas Training.\n• Salario negociable en base a la experiencia y valía del candidato/a\n• Modalidad de trabajo: 100% remoto\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario: 33.000€ - 36.000€ Bruto/año\n6 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nAl inscribirte en esta oferta tendrás que aceptar que CAS Training reciba y gestione tus datos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Otros títulos, certificaciones y carnés<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Conocimientos necesarios<br>Azure<br>Databricks<br>Synapse<br>Data Factory<br>SQL<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>- Experiencia entre 3-4 en arquitecturas Azure: Databricks, Synapse, Datafactory, SQL Database.<br>- Nivel de inglés avanzado (mínimo B2)<br>- Imprescindible experiencia y autonomía en el diseño y la creación de modelos de datos (definición y creación de tablas, complejidad de relaciones y de queries, grandes volumetrías, procedimientos almacenados...)<br>- Imprescindible experiencia en el desarrollo de pipelines y transformaciones de datos complejas (ETLs).<br>- Buen nivel de SQL e idealmente experiencia con Python.<br>- Experiencia en proyectos agile o Valorable conocimiento y experiencia con metodologías y herramientas para despliegue e integración continua (Azure DevOps, Github, Jenkins, Terraform, Docker, Ansible…)<br><br><h3>Requisitos</h3> valorables:<br>- Conocimiento/experiencia en Spark/Pyspark.<br><br><h3>Descripción</h3><br>En CAS Training, empresa de referencia con más de 20 años en consultoría tecnológica, outsourcing y formación especializada, estamos buscando a un/a Data Engineer con experiencia en arquitecturas Azure.<br>Se ofrece:<br>• Formar parte de un equipo dinámico altamente cualificado en una empresa en proceso de expansión.<br>• Participar en proyectos innovadores y punteros para grandes clientes de primer nivel en distintos sectores de mercado.<br>• Proyectos de larga duración, estabilidad profesional y progresión laboral.<br>• Contratación Indefinida.<br>• Acceso gratuito al catálogo de formación anual de Cas Training.<br>• Salario negociable en base a la experiencia y valía del candidato/a<br>• Modalidad de trabajo: 100% remoto<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario: 33.000€ - 36.000€ Bruto/año<br>6 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Al inscribirte en esta oferta tendrás que aceptar que CAS Training reciba y gestione tus datos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B2",
            "anios_experiencia": "3",
            "porcentaje": "85",
            "skills_necesarias": [
                "Azure",
                "Databricks",
                "Synapse",
                "Data Factory",
                "SQL",
                "ETL"
            ],
            "skills_valoradas": [
                "Python",
                "Azure",
                "Git",
                "Jenkins",
                "Terraform",
                "Docker",
                "Ansible",
                "PySpark"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Ingeniero/a de Datos",
        "empresa": "Bluetab, an IBM Company",
        "fecha_publicacion": "Publicada hace 2d",
        "min_salario": "30.000€",
        "max_salario": "54.000€",
        "url_oferta": "https://www.infojobs.net/madrid/ingeniero-datos/of-i714e61909a487ebee27c05ecfb934f?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior - Informática y Comunicaciones\nExperiencia mínima\nAl menos 2 años\nIdiomas requeridos\nEspañol - Nivel Nativo o Bilingüe\nInglés - Nivel Intermedio\nConocimientos necesarios\nBig data\nPython\nSCALA\nSQL\nAzure\nAWS\nGCP\nDatabricks\nSpark\nCI/CD\nDescripción\n¡Buscamos Ingenieros/as de Datos Multicloud (AWS, Azure o GCP)!\nEn Bluetab, an IBM Company, estamos en plena búsqueda de Ingenieros/as de Datos Multicloud que quieran unirse a nuestro equipo y trabajar en proyectos innovadores en entornos AWS, Azure o GCP.\n¿Qué te ofrecemos?\n- Contrato indefinido y un salario competitivo acorde a tu experiencia y rol asignado.\n- Teletrabajo flexible y acceso a nuestras oficinas en Madrid, Alicante, Barcelona, Bilbao y Málaga.\n- Horario flexible y jornada intensiva los viernes y en los meses de julio y agosto.\n- 23 días de vacaciones.\n- Beneficios sociales:\n- Tarjeta restaurante.\n- Seguro médico y dental con amplia cobertura.\n- Plan de retribución flexible: Transporte y guardería.\n- Formación continua con acceso a más de 1000 cursos y certificaciones oficiales.\n- Programa Career Coach para potenciar tu desarrollo profesional.\n- Tarjeta Regalo Pass de 50€ en tu cumpleaños.\n¿Cuáles serán tus retos?\n- Diseño y desarrollo de procesos de integración de datos con Scala o Python sobre Kubernetes o Databricks (Spark).\n- Orquestación de datos con Azure Data Factory, AWS Step Functions o Google Cloud Composer.\n- Creación y optimización de modelos de datos en entornos SQL y Big Data.\n- Almacenamiento y persistencia en Azure Data Lake Storage, Amazon S3 o Google Cloud Storage, así como Snowflake.\n- Identificación y generalización de componentes reutilizables.\n- Programación en Python y experiencia con Azure Functions, AWS Lambda o Google Cloud Functions.\n- Implementación de soluciones con Azure Synapse, AWS Redshift o BigQuery.\n- Conocimientos de DevOps y herramientas como Azure DevOps, Terraform, Ansible o Jenkins.\n- Valorable experiencia en Data Science, Machine Learning y Notebooks.\n- Si tienes un nivel alto de inglés, será un plus para proyectos internacionales en EMEA.\n¡Queremos conocerte!\nSi te apasiona el mundo de los datos y quieres trabajar en proyectos desafiantes con un gran equipo, ¡únete a Bluetab y construyamos juntos el futuro del dato!\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario: 30.000€ - 54.000€ Bruto/año\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\nSeguro médico\nCheque restaurante\n30 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior - Informática y Comunicaciones<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Idiomas requeridos<br>Español - Nivel Nativo o Bilingüe<br>Inglés - Nivel Intermedio<br>Conocimientos necesarios<br>Big data<br>Python<br>SCALA<br>SQL<br>Azure<br>AWS<br>GCP<br>Databricks<br>Spark<br>CI/CD<br><br><h3>Descripción</h3><br>¡Buscamos Ingenieros/as de Datos Multicloud (AWS, Azure o GCP)!<br>En Bluetab, an IBM Company, estamos en plena búsqueda de Ingenieros/as de Datos Multicloud que quieran unirse a nuestro equipo y trabajar en proyectos innovadores en entornos AWS, Azure o GCP.<br>¿Qué te ofrecemos?<br>- Contrato indefinido y un salario competitivo acorde a tu experiencia y rol asignado.<br>- Teletrabajo flexible y acceso a nuestras oficinas en Madrid, Alicante, Barcelona, Bilbao y Málaga.<br>- Horario flexible y jornada intensiva los viernes y en los meses de julio y agosto.<br>- 23 días de vacaciones.<br>- Beneficios sociales:<br>- Tarjeta restaurante.<br>- Seguro médico y dental con amplia cobertura.<br>- Plan de retribución flexible: Transporte y guardería.<br>- Formación continua con acceso a más de 1000 cursos y certificaciones oficiales.<br>- Programa Career Coach para potenciar tu desarrollo profesional.<br>- Tarjeta Regalo Pass de 50€ en tu cumpleaños.<br>¿Cuáles serán tus retos?<br>- Diseño y desarrollo de procesos de integración de datos con Scala o Python sobre Kubernetes o Databricks (Spark).<br>- Orquestación de datos con Azure Data Factory, AWS Step Functions o Google Cloud Composer.<br>- Creación y optimización de modelos de datos en entornos SQL y Big Data.<br>- Almacenamiento y persistencia en Azure Data Lake Storage, Amazon S3 o Google Cloud Storage, así como Snowflake.<br>- Identificación y generalización de componentes reutilizables.<br>- Programación en Python y experiencia con Azure Functions, AWS Lambda o Google Cloud Functions.<br>- Implementación de soluciones con Azure Synapse, AWS Redshift o BigQuery.<br>- Conocimientos de DevOps y herramientas como Azure DevOps, Terraform, Ansible o Jenkins.<br>- Valorable experiencia en Data Science, Machine Learning y Notebooks.<br>- Si tienes un nivel alto de inglés, será un plus para proyectos internacionales en EMEA.<br>¡Queremos conocerte!<br>Si te apasiona el mundo de los datos y quieres trabajar en proyectos desafiantes con un gran equipo, ¡únete a Bluetab y construyamos juntos el futuro del dato!<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario: 30.000€ - 54.000€ Bruto/año<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>Seguro médico<br>Cheque restaurante<br>30 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B1",
            "anios_experiencia": "2",
            "porcentaje": "85",
            "skills_necesarias": [
                "Big Data",
                "Python",
                "Scala",
                "SQL",
                "Azure",
                "AWS",
                "GCP (Google Cloud Platform)",
                "Databricks",
                "PySpark",
                "CI/CD"
            ],
            "skills_valoradas": [
                "Data Science",
                "Machine Learning",
                "Notebooks",
                "Azure",
                "AWS",
                "Cloud",
                "BigQuery",
                "Terraform",
                "Ansible",
                "Jenkins"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Perfil Big Data",
        "empresa": "Serbyte",
        "fecha_publicacion": "Publicada hace 2d",
        "min_salario": "30.000€",
        "max_salario": "33.000€",
        "url_oferta": "https://www.infojobs.net/madrid/perfil-big-data/of-if1f742c1e64e39a2282d46e75ffec2?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nAl menos 2 años\nConocimientos necesarios\nETL\nOracle\nModelado de datos\nPentaho\nRequisitos mínimos\n-Base de datos Oracle: Experiencia en gestión y administración de bases de datos Oracle.\n- Modelado de datos: Habilidad para diseñar estructuras eficientes de datos.\n- Conocimientos técnicos en la herramienta de ETL Pentaho: Experiencia trabajando con esta herramienta para la integración y transformación de datos.\nDescripción\nDesde Serbyte IT, estamos en la búsqueda de un perfil Data con los siguientes conocimientos técnicos:\n- Base de datos Oracle: Experiencia en gestión y administración de bases de datos Oracle.\nModelado de datos: Habilidad para diseñar estructuras eficientes de - datos.\n- Conocimientos técnicos en la herramienta de ETL Pentaho:\n- Experiencia trabajando con esta herramienta para la integración y transformación de datos.\nValorable: Licenciatura en Tecnologías de la Información y la Comunicación (TIC).\nUbicación: Madrid (más del 50% de presencialidad en oficina).\nSi estás interesado o conoces a alguien que cumpla con estos requisitos, ¡aplica ya!\nTipo de industria de la oferta\nDesarrollo de programación\nCategoría\nInformática y telecomunicaciones - Administración de bases de datos\nNivel\nEmpleado/a\nNúmero de vacantes\n2\nSalario\nSalario: 30.000€ - 33.000€ Bruto/año\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\nSeguro médico\n9 inscritos a esta oferta para 2 vacantes\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Conocimientos necesarios<br>ETL<br>Oracle<br>Modelado de datos<br>Pentaho<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Base de datos Oracle: Experiencia en gestión y administración de bases de datos Oracle.<br>- Modelado de datos: Habilidad para diseñar estructuras eficientes de datos.<br>- Conocimientos técnicos en la herramienta de ETL Pentaho: Experiencia trabajando con esta herramienta para la integración y transformación de datos.<br><br><h3>Descripción</h3><br>Desde Serbyte IT, estamos en la búsqueda de un perfil Data con los siguientes conocimientos técnicos:<br>- Base de datos Oracle: Experiencia en gestión y administración de bases de datos Oracle.<br>Modelado de datos: Habilidad para diseñar estructuras eficientes de - datos.<br>- Conocimientos técnicos en la herramienta de ETL Pentaho:<br>- Experiencia trabajando con esta herramienta para la integración y transformación de datos.<br>Valorable: Licenciatura en Tecnologías de la Información y la Comunicación (TIC).<br>Ubicación: Madrid (más del 50% de presencialidad en oficina).<br>Si estás interesado o conoces a alguien que cumpla con estos requisitos, ¡aplica ya!<br>Tipo de industria de la oferta<br>Desarrollo de programación<br>Categoría<br>Informática y telecomunicaciones - Administración de bases de datos<br>Nivel<br>Empleado/a<br>Número de vacantes<br>2<br>Salario<br>Salario: 30.000€ - 33.000€ Bruto/año<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>Seguro médico<br>9 inscritos a esta oferta para 2 vacantes<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "2",
            "porcentaje": "75",
            "skills_necesarias": [
                "ETL",
                "Oracle",
                "Pentaho"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Prácticas Remuneradas Ingeniero/a Datos",
        "empresa": "Grupo Diusframi",
        "fecha_publicacion": "Publicada hace 2d",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/practicas-remuneradas-ingeniero-datos/of-i31345c80c14677beb23d5fc3f8204b?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCursando: grado\nExperiencia mínima\nNo Requerida\nImprescindible residente en\nProvincia Puesto Vacante\nConocimientos necesarios\nAnálisis\nTecnologías de la información\nPython\nInformatica\nAnálisis de datos\nEstadística\nRequisitos mínimos\n-Poder formalizar convenio de prácticas con tu Universidad.\nRequisitos deseados\nDeseable Poseer Certificado de Discapacidad\nDescripción\nEn Diusframi, buscamos estudiantes en prácticas interesados en desarrollarse en el ámbito de la Ingeniería de Datos. Ofrecemos una oportunidad única para aplicar conocimientos técnicos en proyectos innovadores, dentro de un equipo dinámico y en constante evolución.\nBuscamos estudiantes de grado o máster que puedan formalizar un convenio de prácticas con su universidad y que estén cursando titulaciones relacionadas con Ingeniería de Datos, Ciencia de Datos, Ingeniería Informática, Matemáticas, Estadística o Ingeniería en Tecnologías de la Información Geoespacial, entre otras.\nSerá muy valorable contar con conocimientos en SQL y Python aplicados al análisis de datos, así como interés en desarrollarse en un entorno tecnológico y bancario. Además, también se valorará experiencia en herramientas de visualización como Power BI o Tableau.\n¿Qué ofrecemos?\n- Prácticas remuneradas entre 500-700€ brutos/mes, según nivel de estudios (grado o máster).\n- Horario flexible.\n- Incorporación prevista entre marzo y mayo.\n- Posibilidad de continuidad tras las prácticas.\nSi te apasionan los datos y quieres formar parte de un equipo innovador, ¡te estamos esperando!\nGrupo Diusframi promueve activamente la igualdad de oportunidades entre hombres y mujeres.\nSe valorará positivamente encontrarse en posesión del certificado de discapacidad.\nTipo de industria de la oferta\nServicios financieros\nCategoría\nIngenieros y técnicos - Otras ingenierías\nNivel\nBecario/a - Prácticas\nNúmero de vacantes\n1\nSalario\nSalario no disponible\n39 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Cursando: grado<br><h4>Experiencia mínima</h4><br>No Requerida<br>Imprescindible residente en<br>Provincia Puesto Vacante<br>Conocimientos necesarios<br>Análisis<br>Tecnologías de la información<br>Python<br>Informatica<br>Análisis de datos<br>Estadística<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Poder formalizar convenio de prácticas con tu Universidad.<br><br><h3>Requisitos</h3> deseados<br>Deseable Poseer Certificado de Discapacidad<br><br><h3>Descripción</h3><br>En Diusframi, buscamos estudiantes en prácticas interesados en desarrollarse en el ámbito de la Ingeniería de Datos. Ofrecemos una oportunidad única para aplicar conocimientos técnicos en proyectos innovadores, dentro de un equipo dinámico y en constante evolución.<br>Buscamos estudiantes de grado o máster que puedan formalizar un convenio de prácticas con su universidad y que estén cursando titulaciones relacionadas con Ingeniería de Datos, Ciencia de Datos, Ingeniería Informática, Matemáticas, Estadística o Ingeniería en Tecnologías de la Información Geoespacial, entre otras.<br>Será muy valorable contar con conocimientos en SQL y Python aplicados al análisis de datos, así como interés en desarrollarse en un entorno tecnológico y bancario. Además, también se valorará experiencia en herramientas de visualización como Power BI o Tableau.<br>¿Qué ofrecemos?<br>- Prácticas remuneradas entre 500-700€ brutos/mes, según nivel de estudios (grado o máster).<br>- Horario flexible.<br>- Incorporación prevista entre marzo y mayo.<br>- Posibilidad de continuidad tras las prácticas.<br>Si te apasionan los datos y quieres formar parte de un equipo innovador, ¡te estamos esperando!<br>Grupo Diusframi promueve activamente la igualdad de oportunidades entre hombres y mujeres.<br>Se valorará positivamente encontrarse en posesión del certificado de discapacidad.<br>Tipo de industria de la oferta<br>Servicios financieros<br>Categoría<br>Ingenieros y técnicos - Otras ingenierías<br>Nivel<br>Becario/a - Prácticas<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>39 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "No Requerida",
            "porcentaje": "50",
            "skills_necesarias": [
                "Análisis de datos",
                "Tecnologías de la información",
                "Python"
            ],
            "skills_valoradas": [
                "SQL",
                "Power BI",
                "Tableau"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Ingeniero/a de datos",
        "empresa": "Serikat",
        "fecha_publicacion": "Publicada hace 3d",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/ingeniero-datos/of-ie6855673af443da823e8f2e51db6c5?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Medio\nExperiencia mínima\nMás de 5 años\nImprescindible residente en\nNo Requerido\nConocimientos necesarios\nPython\nETL\nBig data\nPyspark\nRequisitos mínimos\n-Contar con mínimo 5 años de experiencia en las tareas y tecnologías descritas.\n- Que seas una persona con capacidades analíticas y te guste el trabajo en equipo y colaborativo.\n- Interés por el aprendizaje continuo, la evolución y la adaptación.\nDescripción\nEn SERIKAT precisamos perfiles como tú, experto/a en el mundo DATA ¡Estamos abordando alguno de los desafíos tecnológicos más excitantes de nuestro tiempo!\nImagina trabajar con las tecnologías más disruptivas en un entorno en el que se promueve la diversidad, la inclusión y la igualdad de oportunidades ¡Nos encantaría contar contigo e integrarte en un equipo abierto, colaborativo y con visión de futuro!\n¿Cuáles serán tus funciones?\n- Liderar proyectos Big Data en distintos clientes.\n- Realización de procesos ETL utilizando tecnologías Big Data.\n- Diseño y desarrollo de soluciones alineadas con las necesidades de negocio.\n- Soporte en el mantenimiento y productivización de modelos de Machine Learning para el área de Analítica Avanzada.\n¿Cuál será el Stack Tecnológico?\n- Python y Pyspark.\n- Transact SQL.\n- Tecnologías Big Data (preferiblemente utilizando Apache Hadoop)\n- Herramientas de control de versión de código (Git).\n- Experiencia de alguna plataforma Big Data (Cloud pak for Data, Azure, AWS, Stratio, etc.)\n- Experiencia en diseño y desarrollo de procesos ETL y modelización de datos para analítica (modelos en estrella, copo de nieve, etc.)\n¿Cuáles son los requisitos que vamos a tener en cuenta?\n- Contar con mínimo 5 años de experiencia en las tareas y tecnologías descritas.\n- Que seas una persona con capacidades analíticas y te guste el trabajo en equipo y colaborativo.\n- Interés por el aprendizaje continuo, la evolución y la adaptación.\n- Deseable: conocimiento de otros lenguajes de programación, como R, Java;); Herramientas de visualización y dashboards (Power BI); Apache Kafka, NIFI, ElasticSearch, BBDD no relacionales y experiencia en metodologías agile (kanban, scrum, design thinking,...)\n¿Qué encontrarás en Serikat?\nESTABILIDAD. Exclusivamente contratación indefinida en una compañía puramente tecnológica que forma parte de un sólido grupo empresarial.\nFORMACIÓN ABIERTA. Para seguir desarrollando tu carrera profesional.\nCONCILIACIÓN. Horario flexible, modalidad remota de trabajo, jornada intensiva 3 meses de verano y todos los viernes de año.\nOTRAS VENTAJAS. Programa de retribución flexible a medida: seguro médico, cheques guardería, tarjeta restaurante, SKT Benefits, etc.\n¿¡Te interesa!? No lo dudes, haznos llegar tu candidatura para que podamos valorar mejor tu perfil.\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\n29 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Medio<br><h4>Experiencia mínima</h4><br>Más de 5 años<br>Imprescindible residente en<br>No Requerido<br>Conocimientos necesarios<br>Python<br>ETL<br>Big data<br>Pyspark<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Contar con mínimo 5 años de experiencia en las tareas y tecnologías descritas.<br>- Que seas una persona con capacidades analíticas y te guste el trabajo en equipo y colaborativo.<br>- Interés por el aprendizaje continuo, la evolución y la adaptación.<br><br><h3>Descripción</h3><br>En SERIKAT precisamos perfiles como tú, experto/a en el mundo DATA ¡Estamos abordando alguno de los desafíos tecnológicos más excitantes de nuestro tiempo!<br>Imagina trabajar con las tecnologías más disruptivas en un entorno en el que se promueve la diversidad, la inclusión y la igualdad de oportunidades ¡Nos encantaría contar contigo e integrarte en un equipo abierto, colaborativo y con visión de futuro!<br>¿Cuáles serán tus funciones?<br>- Liderar proyectos Big Data en distintos clientes.<br>- Realización de procesos ETL utilizando tecnologías Big Data.<br>- Diseño y desarrollo de soluciones alineadas con las necesidades de negocio.<br>- Soporte en el mantenimiento y productivización de modelos de Machine Learning para el área de Analítica Avanzada.<br>¿Cuál será el Stack Tecnológico?<br>- Python y Pyspark.<br>- Transact SQL.<br>- Tecnologías Big Data (preferiblemente utilizando Apache Hadoop)<br>- Herramientas de control de versión de código (Git).<br>- Experiencia de alguna plataforma Big Data (Cloud pak for Data, Azure, AWS, Stratio, etc.)<br>- Experiencia en diseño y desarrollo de procesos ETL y modelización de datos para analítica (modelos en estrella, copo de nieve, etc.)<br>¿Cuáles son los requisitos que vamos a tener en cuenta?<br>- Contar con mínimo 5 años de experiencia en las tareas y tecnologías descritas.<br>- Que seas una persona con capacidades analíticas y te guste el trabajo en equipo y colaborativo.<br>- Interés por el aprendizaje continuo, la evolución y la adaptación.<br>- Deseable: conocimiento de otros lenguajes de programación, como R, Java;); Herramientas de visualización y dashboards (Power BI); Apache Kafka, NIFI, ElasticSearch, BBDD no relacionales y experiencia en metodologías agile (kanban, scrum, design thinking,...)<br>¿Qué encontrarás en Serikat?<br>ESTABILIDAD. Exclusivamente contratación indefinida en una compañía puramente tecnológica que forma parte de un sólido grupo empresarial.<br>FORMACIÓN ABIERTA. Para seguir desarrollando tu carrera profesional.<br>CONCILIACIÓN. Horario flexible, modalidad remota de trabajo, jornada intensiva 3 meses de verano y todos los viernes de año.<br>OTRAS VENTAJAS. Programa de retribución flexible a medida: seguro médico, cheques guardería, tarjeta restaurante, SKT Benefits, etc.<br>¿¡Te interesa!? No lo dudes, haznos llegar tu candidatura para que podamos valorar mejor tu perfil.<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>29 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "5",
            "porcentaje": "85",
            "skills_necesarias": [
                "Python",
                "ETL",
                "Big Data",
                "PySpark",
                "SQL"
            ],
            "skills_valoradas": [
                "Hadoop",
                "Git",
                "R",
                "Java",
                "Power BI",
                "Kafka",
                "NIFI",
                "ElasticSearch"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer Scala/Spark",
        "empresa": "ALVEA SOLUCIONES TECNOLOGICAS, S.L.",
        "fecha_publicacion": "Publicada hace 3d (Publicada de nuevo)",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-scala-spark/of-i3dd3df5cc14dd9b3ae76a593f17316?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nEducación Secundaria Obligatoria\nExperiencia mínima\nAl menos 1 año\nImprescindible residente en\nEspaña\nConocimientos necesarios\nSCALA\nSpark\nMantenimiento\nDescripción\nData Engineer (Spark/Scala) - Alvea Soluciones Tecnológicas\nUbicación: 100% remoto\nContrato: Indefinido\nDescripción del puesto: En Alvea Soluciones Tecnológicas, estamos buscando un Data Engineer con experiencia en Scala para unirse a nuestro equipo. Esta posición está orientada a la mantenimiento y monitoreo de aplicaciones, por lo que será necesario revisar logs de procesos que corren en ADA (AWS) para garantizar el correcto funcionamiento de la infraestructura.\nResponsabilidades:\nMonitoreo y mantenimiento de la aplicación en producción.\nAnálisis y resolución de incidencias observadas en los logs de los procesos.\nSoporte durante guardias programadas para asegurar el funcionamiento continuo.\nColaboración con el equipo de desarrollo para identificar y resolver problemas.\nImplementación de mejoras en la eficiencia y estabilidad del sistema.\nRequisitos:\nExperiencia sólida en Scala.\nConocimiento de ADA (AWS) y experiencia trabajando con servicios en la nube.\nExperiencia en manejo y análisis de logs.\nCapacidad para gestionar y solucionar problemas de producción.\nDisponibilidad para realizar guardias programadas.\nOfrecemos:\nTrabajo 100% remoto, desde cualquier lugar.\nContrato indefinido.\nOportunidades de crecimiento y desarrollo profesional en un equipo dinámico.\nSi estás buscando un desafío en el mundo de los datos y tienes las habilidades necesarias, ¡queremos conocerte!\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nFinanzas y banca - Productos y servicios bancarios\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n59 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Educación Secundaria Obligatoria<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br>Imprescindible residente en<br>España<br>Conocimientos necesarios<br>SCALA<br>Spark<br>Mantenimiento<br><br><h3>Descripción</h3><br>Data Engineer (Spark/Scala) - Alvea Soluciones Tecnológicas<br>Ubicación: 100% remoto<br>Contrato: Indefinido<br><br><h3>Descripción</h3> del puesto: En Alvea Soluciones Tecnológicas, estamos buscando un Data Engineer con experiencia en Scala para unirse a nuestro equipo. Esta posición está orientada a la mantenimiento y monitoreo de aplicaciones, por lo que será necesario revisar logs de procesos que corren en ADA (AWS) para garantizar el correcto funcionamiento de la infraestructura.<br>Responsabilidades:<br>Monitoreo y mantenimiento de la aplicación en producción.<br>Análisis y resolución de incidencias observadas en los logs de los procesos.<br>Soporte durante guardias programadas para asegurar el funcionamiento continuo.<br>Colaboración con el equipo de desarrollo para identificar y resolver problemas.<br>Implementación de mejoras en la eficiencia y estabilidad del sistema.<br><br><h3>Requisitos</h3>:<br>Experiencia sólida en Scala.<br>Conocimiento de ADA (AWS) y experiencia trabajando con servicios en la nube.<br>Experiencia en manejo y análisis de logs.<br>Capacidad para gestionar y solucionar problemas de producción.<br>Disponibilidad para realizar guardias programadas.<br>Ofrecemos:<br>Trabajo 100% remoto, desde cualquier lugar.<br>Contrato indefinido.<br>Oportunidades de crecimiento y desarrollo profesional en un equipo dinámico.<br>Si estás buscando un desafío en el mundo de los datos y tienes las habilidades necesarias, ¡queremos conocerte!<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Finanzas y banca - Productos y servicios bancarios<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>59 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "1",
            "porcentaje": "60",
            "skills_necesarias": [
                "Scala",
                "PySpark",
                "ADA",
                "AWS"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer",
        "empresa": "BOYCOR",
        "fecha_publicacion": "Publicada hace 3d",
        "min_salario": "36.000€",
        "max_salario": "41.000€",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer/of-ie0baf8892041da84ec4fcd862b16b9?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 1 año\nImprescindible residente en\nNo Requerido\nIdiomas requeridos\nInglés - Nivel Avanzado\nConocimientos necesarios\nSpark\nSCALA\nKafka\nAirflow\nRequisitos mínimos\n-Experiencia en desarrollo y optimización de pipelines con Apache Spark y Scala.\n- Conocimientos en procesamiento de datos en tiempo real con Apache Kafka.\n-Habilidad en orquestación y automatización de flujos con Apache Airflow.\n-Nivel alto de inglés\nDescripción\n¿Eres Ingeniero de datos y buscas un cambio profesional ? Desde Boycor buscamos un Data Engineer para trabajar en una multinacional francesa del sector IT en un importante proyecto del sector bancario de una de las principales entidades financieras a nivel global, donde podrás participar en la optimización y gestión de grandes volúmenes de datos, contribuyendo a la creación de soluciones innovadoras y eficientes.\n¡Te estamos esperando!\n¿Cómo SERÁ tu día a día?\n- Diseñar, construir y mantener pipelines de datos utilizando Apache Spark sobre Scala, procesando datos desde diversas fuentes como Kafka, APIs y HDFS.\n- Implementar y gestionar pipelines de CI/CD empleando herramientas como GitLab y Jenkins.\n-Configurar procesos de orquestación con Apache Airflow para automatizar flujos de datos complejos.\n-Garantizar la calidad y consistencia de los datos para conseguir buenos resultados.\n- Colaborar en la resolución de incidentes, el soporte en producción y la mejora continua del código.\n-Documentar procesos técnicos, fomentando el intercambio de conocimiento y el desarrollo del equipo.\n¿Cuál es la CLAVE de este puesto?\n-Experiencia en desarrollo y optimización de pipelines con Apache Spark y Scala.\n- Conocimientos en procesamiento de datos en tiempo real con Apache Kafka.\n- Habilidad en orquestación y automatización de flujos con Apache Airflow.\n-Nivel alto de inglés\nTendrás puntos extras si cuentas con experiencia o conocimientos en:\n- Tecnologías de almacenamiento: HDFS y S3.\n- Herramientas de integración continua: GitLab, Jenkins, etc.\n- Contenedores y orquestación: Kubernetes.\n-Bases de datos y análisis: Elasticsearch y Dremio.\n¿Qué te podemos OFRECER?\n- Contrato indefinido con Boycor para proyecto estable\n- Modalidad de trabajo: hibrido\n-Ubicación: Madrid\n-Horario flexible: L-J 09:00 a 18:00 y V 08:00-15:00, jornada intensiva en verano\n-Salario: 41.000€ brutos anuales (cifra orientativa abierta a negociación)\n¿Te sientes identificado/a? No dudes en inscribirte.\nReferencia\nEPT02425\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nDuración del contrato\nEstable\nSalario\nSalario: 36.000€ - 41.000€ Bruto/año\nBeneficios sociales\nTeletrabajo\n3 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br>Imprescindible residente en<br>No Requerido<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br>Conocimientos necesarios<br>Spark<br>SCALA<br>Kafka<br>Airflow<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Experiencia en desarrollo y optimización de pipelines con Apache Spark y Scala.<br>- Conocimientos en procesamiento de datos en tiempo real con Apache Kafka.<br>-Habilidad en orquestación y automatización de flujos con Apache Airflow.<br>-Nivel alto de inglés<br><br><h3>Descripción</h3><br>¿Eres Ingeniero de datos y buscas un cambio profesional ? Desde Boycor buscamos un Data Engineer para trabajar en una multinacional francesa del sector IT en un importante proyecto del sector bancario de una de las principales entidades financieras a nivel global, donde podrás participar en la optimización y gestión de grandes volúmenes de datos, contribuyendo a la creación de soluciones innovadoras y eficientes.<br>¡Te estamos esperando!<br>¿Cómo SERÁ tu día a día?<br>- Diseñar, construir y mantener pipelines de datos utilizando Apache Spark sobre Scala, procesando datos desde diversas fuentes como Kafka, APIs y HDFS.<br>- Implementar y gestionar pipelines de CI/CD empleando herramientas como GitLab y Jenkins.<br>-Configurar procesos de orquestación con Apache Airflow para automatizar flujos de datos complejos.<br>-Garantizar la calidad y consistencia de los datos para conseguir buenos resultados.<br>- Colaborar en la resolución de incidentes, el soporte en producción y la mejora continua del código.<br>-Documentar procesos técnicos, fomentando el intercambio de conocimiento y el desarrollo del equipo.<br>¿Cuál es la CLAVE de este puesto?<br>-Experiencia en desarrollo y optimización de pipelines con Apache Spark y Scala.<br>- Conocimientos en procesamiento de datos en tiempo real con Apache Kafka.<br>- Habilidad en orquestación y automatización de flujos con Apache Airflow.<br>-Nivel alto de inglés<br>Tendrás puntos extras si cuentas con experiencia o conocimientos en:<br>- Tecnologías de almacenamiento: HDFS y S3.<br>- Herramientas de integración continua: GitLab, Jenkins, etc.<br>- Contenedores y orquestación: Kubernetes.<br>-Bases de datos y análisis: Elasticsearch y Dremio.<br>¿Qué te podemos OFRECER?<br>- Contrato indefinido con Boycor para proyecto estable<br>- Modalidad de trabajo: hibrido<br>-Ubicación: Madrid<br>-Horario flexible: L-J 09:00 a 18:00 y V 08:00-15:00, jornada intensiva en verano<br>-Salario: 41.000€ brutos anuales (cifra orientativa abierta a negociación)<br>¿Te sientes identificado/a? No dudes en inscribirte.<br>Referencia<br>EPT02425<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Duración del contrato<br>Estable<br>Salario<br>Salario: 36.000€ - 41.000€ Bruto/año<br>Beneficios sociales<br>Teletrabajo<br>3 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "1",
            "porcentaje": "85",
            "skills_necesarias": [
                "PySpark",
                "Scala",
                "Kafka",
                "Airflow"
            ],
            "skills_valoradas": [
                "HDFS",
                "S3",
                "Git",
                "Jenkins",
                "Kubernetes",
                "Elasticsearch",
                "Dremio"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Prácticas Investigación Mercado Cuantitativa",
        "empresa": "GfK Retail and Technology España",
        "fecha_publicacion": "Publicada hace 3d (Publicada de nuevo)",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/practicas-investigacion-mercado-cuantitativa/of-ia0f2fb415844e0a8520b029176e3ae?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nNo Requerida\nRequisitos mínimos\nRequisitos vacante de Investigación de Mercados\n-Estudiantes universitarios de último año o cursando estudios post-universitarios relacionados con el entorno de empresa, ADE, comercio, investigación de mercados, publicidad, marketing, estadística, sociología.\n--Inglés - nivel mínimo B2/First\n---Incorporación inmediata\nRequisitos vacante de Data Science\nEstudiantes de Grado o licenciatura en Matemáticas, Estadística, Física, Computación, Ingeniería.\nLenguajes: Python y R.\nHerramientas de Office: Excel y PowerPoint.\nIdiomas: Inglés alto.\nRequisitos vacante de Data Engineer\nEstudiantes de Grado o licenciatura en Matemáticas, Estadística, Física, Computación, Ingeniería.\nLenguajes: Python y SQL.\nHerramientas de BI: Qlik y/o PowerBI.\nHerramientas de Office: Excel y PowerPoint.\nIdiomas: Inglés alto.\nLA COMUNICACIÓN DEL PROCESO SELECCIÓN SE REALIZA VÍA EMAIL.\nDescripción\nGfK, lleva más de 85 años de experiencia en market research proporcionando insights sobre el consumidor y el mercado a nivel mundial.\nUna de nuestras principales filosofías es valorar el talento apoyando el desarrollo personal dentro de sus equipos, por eso mismo, abrimos vacantes de prácticas para nuestra oficina de Madrid.\nVacante en Investigación de Mercados cuantitativos adhoc:\nFunciones: Apoyo al departamento en diseño de cuestionarios, revisión de informes de investigación, análisis de tablas y bases de datos, realización de gráficos, coordinación interna con otros departamentos...\nVacante en IA & Data Science:\n-Posición para el área Data Science\nFunciones: Integración de distintas fuentes de datos, limpieza, verificación y procesamiento de los datos. Análisis de datos aplicando las técnicas estadísticas más apropiadas. Elaboración de algoritmos utilizando inteligencia artificial y machine learning: análisis predictivo, modelos de clasificación, PLN, etc.\n-Posición para el área Data Engineer:\nFunciones: Diseñar, desarrollar y mantener pipelines de datos escalables y eficientes. Gestionar datos estructurados y no estructurados provenientes de diversas fuentes. Automatizar procesos de extracción, transformación y carga (ETL). Supervisar la integridad, seguridad y procesamiento de los datos. Diseñar y ofrecer soluciones web que ayuden en la toma de decisiones de nuestros clientes.\n¿Qué te ofrecemos en GfK?\n-Crecimiento laboral dentro de la compañía.\n-Ambiente de trabajo joven y agradable.\n-Prácticas en Jornada Completa y Verano jornada intensiva.\n-Modelo de trabajo híbrido (casa y remoto)\n-Prácticas remuneradas (600€-750€)\nTipo de industria de la oferta\nInvestigación de mercado\nCategoría\nMarketing y comunicación - Investigación de mercados\nNivel\nBecario/a - Prácticas\nNúmero de vacantes\n2\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n606 inscritos a esta oferta para 2 vacantes\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>No Requerida<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br><br><h3>Requisitos</h3> vacante de Investigación de Mercados<br>-Estudiantes universitarios de último año o cursando estudios post-universitarios relacionados con el entorno de empresa, ADE, comercio, investigación de mercados, publicidad, marketing, estadística, sociología.<br>--Inglés - nivel mínimo B2/First<br>---Incorporación inmediata<br><br><h3>Requisitos</h3> vacante de Data Science<br>Estudiantes de Grado o licenciatura en Matemáticas, Estadística, Física, Computación, Ingeniería.<br>Lenguajes: Python y R.<br>Herramientas de Office: Excel y PowerPoint.<br>Idiomas: Inglés alto.<br><br><h3>Requisitos</h3> vacante de Data Engineer<br>Estudiantes de Grado o licenciatura en Matemáticas, Estadística, Física, Computación, Ingeniería.<br>Lenguajes: Python y SQL.<br>Herramientas de BI: Qlik y/o PowerBI.<br>Herramientas de Office: Excel y PowerPoint.<br>Idiomas: Inglés alto.<br>LA COMUNICACIÓN DEL PROCESO SELECCIÓN SE REALIZA VÍA EMAIL.<br><br><h3>Descripción</h3><br>GfK, lleva más de 85 años de experiencia en market research proporcionando insights sobre el consumidor y el mercado a nivel mundial.<br>Una de nuestras principales filosofías es valorar el talento apoyando el desarrollo personal dentro de sus equipos, por eso mismo, abrimos vacantes de prácticas para nuestra oficina de Madrid.<br>Vacante en Investigación de Mercados cuantitativos adhoc:<br>Funciones: Apoyo al departamento en diseño de cuestionarios, revisión de informes de investigación, análisis de tablas y bases de datos, realización de gráficos, coordinación interna con otros departamentos...<br>Vacante en IA & Data Science:<br>-Posición para el área Data Science<br>Funciones: Integración de distintas fuentes de datos, limpieza, verificación y procesamiento de los datos. Análisis de datos aplicando las técnicas estadísticas más apropiadas. Elaboración de algoritmos utilizando inteligencia artificial y machine learning: análisis predictivo, modelos de clasificación, PLN, etc.<br>-Posición para el área Data Engineer:<br>Funciones: Diseñar, desarrollar y mantener pipelines de datos escalables y eficientes. Gestionar datos estructurados y no estructurados provenientes de diversas fuentes. Automatizar procesos de extracción, transformación y carga (ETL). Supervisar la integridad, seguridad y procesamiento de los datos. Diseñar y ofrecer soluciones web que ayuden en la toma de decisiones de nuestros clientes.<br>¿Qué te ofrecemos en GfK?<br>-Crecimiento laboral dentro de la compañía.<br>-Ambiente de trabajo joven y agradable.<br>-Prácticas en Jornada Completa y Verano jornada intensiva.<br>-Modelo de trabajo híbrido (casa y remoto)<br>-Prácticas remuneradas (600€-750€)<br>Tipo de industria de la oferta<br>Investigación de mercado<br>Categoría<br>Marketing y comunicación - Investigación de mercados<br>Nivel<br>Becario/a - Prácticas<br>Número de vacantes<br>2<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>606 inscritos a esta oferta para 2 vacantes<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B2",
            "anios_experiencia": "No especificado",
            "porcentaje": "75",
            "skills_necesarias": [
                "Python",
                "R",
                "Excel",
                "PowerPoint",
                "Machine Learning",
                "Análisis de datos",
                "ETL"
            ],
            "skills_valoradas": [
                "IA",
                "Análisis predictivo",
                "Modelos de clasificación",
                "Procesamiento de lenguaje natural (PLN)"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Specialist / MDM, REMOTO!!",
        "empresa": "Soltel",
        "fecha_publicacion": "Publicada hace 3d",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-specialist-mdm-remoto/of-ic66bbe642e410ea8ae1cd22a7f6c83?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nAl menos 2 años\nIdiomas requeridos\nInglés - Nivel Intermedio\nConocimientos necesarios\nMantenimiento\nPruebas\nAgile\nSupervisión\nMDM\nCLOUD\nAZURE\nSERVICENOW\nRequisitos mínimos\nRequisitos obligatorios\nGraduado universitario\nMínimo 2 años de experiencia\nExperiencia en Data Specialist MDM (o equivalente como Informatica MDM)\nConocimientos sólidos en Master Data Management (MDM)\nInglés B2 mínimo, con autonomía en sesiones de trabajo\nRequisitos deseados\nRequisitos valorables\nExperiencia en entornos Azure, incluyendo:\nMS FHIR Server, Event Hub, Event Topic, API Management, Application Gateway\nConocimientos en entornos Oracle (Data Integrator, Service Bus, Enterprise Manager)\nJava Backend con Spring Boot\nBases de datos: Oracle / SQL Server, se valorará experiencia con Cosmos DB\nManejo de herramientas como Azure DevOps, ServiceNow\nDescripción\nSOLTEL continúa creciendo. Somos una Compañía de IT con un sólido proyecto empresarial, con más de 800 profesionales especializados en Ingeniería de Sistemas, Ingeniería de Software, Soporte Tecnológico, Asistencia Técnica, I+D+i y Smart Cities.\nAbrimos nueva posición para trabajar como Data Specialist con experiencia en MDM para trabajar en un servicio de Application Management & Platform Modernization.\nEl rol incluye tareas de desarrollo, pruebas, mantenimiento y soporte, en un entorno Agile, con posible supervision de perfiles junior en caso de un rol senior.\nUbicación: 100% remoto en España (no se aceptan candidatos fuera del país)\nCondiciones adicionales:\nGuardias ocasionales\nTrabajo en equipo Agile\n¿Qué te ofrecemos?\nSOLTEL te da la oportunidad de trabajar con Tecnologías emergentes, con horarios flexibles, posibilidad de trabajar desde casa, valoramos tu dedicación y te recompensamos por ello, oportunidades de crecimiento a través de la formación.\nTodo ello con un trato cercano y profesional\nSi te encantan la tecnología y los retos, encajarás bien en SOLTEL, te esperamos.\nTipo de industria de la oferta\nProgramación, Consultoria y otras Activ. informaticas\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n2 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Idiomas requeridos<br>Inglés - Nivel Intermedio<br>Conocimientos necesarios<br>Mantenimiento<br>Pruebas<br>Agile<br>Supervisión<br>MDM<br>CLOUD<br>AZURE<br>SERVICENOW<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br><br><h3>Requisitos</h3> obligatorios<br>Graduado universitario<br>Mínimo 2 años de experiencia<br>Experiencia en Data Specialist MDM (o equivalente como Informatica MDM)<br>Conocimientos sólidos en Master Data Management (MDM)<br>Inglés B2 mínimo, con autonomía en sesiones de trabajo<br><br><h3>Requisitos</h3> deseados<br><br><h3>Requisitos</h3> valorables<br>Experiencia en entornos Azure, incluyendo:<br>MS FHIR Server, Event Hub, Event Topic, API Management, Application Gateway<br>Conocimientos en entornos Oracle (Data Integrator, Service Bus, Enterprise Manager)<br>Java Backend con Spring Boot<br>Bases de datos: Oracle / SQL Server, se valorará experiencia con Cosmos DB<br>Manejo de herramientas como Azure DevOps, ServiceNow<br><br><h3>Descripción</h3><br>SOLTEL continúa creciendo. Somos una Compañía de IT con un sólido proyecto empresarial, con más de 800 profesionales especializados en Ingeniería de Sistemas, Ingeniería de Software, Soporte Tecnológico, Asistencia Técnica, I+D+i y Smart Cities.<br>Abrimos nueva posición para trabajar como Data Specialist con experiencia en MDM para trabajar en un servicio de Application Management & Platform Modernization.<br>El rol incluye tareas de desarrollo, pruebas, mantenimiento y soporte, en un entorno Agile, con posible supervision de perfiles junior en caso de un rol senior.<br>Ubicación: 100% remoto en España (no se aceptan candidatos fuera del país)<br>Condiciones adicionales:<br>Guardias ocasionales<br>Trabajo en equipo Agile<br>¿Qué te ofrecemos?<br>SOLTEL te da la oportunidad de trabajar con Tecnologías emergentes, con horarios flexibles, posibilidad de trabajar desde casa, valoramos tu dedicación y te recompensamos por ello, oportunidades de crecimiento a través de la formación.<br>Todo ello con un trato cercano y profesional<br>Si te encantan la tecnología y los retos, encajarás bien en SOLTEL, te esperamos.<br>Tipo de industria de la oferta<br>Programación, Consultoria y otras Activ. informaticas<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>2 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B2",
            "anios_experiencia": "2",
            "porcentaje": "75",
            "skills_necesarias": [
                "Data Specialist MDM",
                "Master Data Management",
                "Agile",
                "Cloud",
                "Azure",
                "SERVICENOW"
            ],
            "skills_valoradas": [
                "Java",
                "Oracle",
                "SQL",
                "Cosmos DB",
                "Azure"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer // Remoto",
        "empresa": "BOYCOR",
        "fecha_publicacion": "Publicada hace 4d",
        "min_salario": "36.000€",
        "max_salario": "36.000€",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-remoto/of-i92e6acbc894d03959105da9ea88daa?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Medio\nExperiencia mínima\nAl menos 3 años\nIdiomas requeridos\nInglés - Nivel Avanzado\nConocimientos necesarios\nHadoop\nPython\nSCALA\nETL\nSQL\nSpark\nCloudera\nHive\nRequisitos mínimos\nConocimiento en tecnologías como Hadoop, Hive, Spark y herramientas de procesamiento distribuido\n· Experiencia sólida en Java, Python o Scala\n· Dominio de consultas SQL complejas para interactuar y extraer información de bases de datos distribuidas de manera eficiente.\n· Experiencia con AWS, Azure o GCP, especialmente con soluciones de Big Data nativas de la nube.\n· Nivel avanzado de Inglés para trabajar en un equipo internacional y participar activamente en reuniones y proyectos a nivel global.\nDescripción\n¿Eres Data Engineer y estás buscando un nuevo proyecto? Si además te gustaría trabajar desde cualquier parte de España en un entorno con profesionales internacionales de alto rendimiento donde poder perfeccionar tu nivel de inglés ¡Esta es tu oportunidad! Me encuentro buscando un Data Engineer para trabajar de la mano una de las principales multinacionales españolas del sector IT, en un proyecto para la que es considerada como una de las mayores entidades financieras a nivel mundial.\n¡Queremos conocerte!\n¿Cómo será tu DÍA A DÍA?\n· Trabajarás con arquitecturas de datos escalables y distribuidas, utilizando tecnologías como Hadoop, Hive y Spark, para garantizar que los datos se gestionen de manera eficiente y se puedan escalar con el crecimiento del negocio.\n· Participarás en la administración y mejora continua de clústeres de Big Data\n· Desarrollarás, optimizarás y mantendrás pipelines de datos\n· Implementarás y optimizarás procesos ETL avanzados utilizando Python, integrando múltiples fuentes de datos (bases de datos, APIs, archivos) y transformándolos para su posterior análisis y explotación.\n· Utilizarás SQL avanzado para realizar consultas complejas y obtener insights de grandes volúmenes de datos, optimizando las consultas para que se ejecuten de forma rápida y eficiente.\n· Trabajarás en plataformas en la nube, como AWS, Azure o GCP\n· Aplicarás prácticas de DevOps y trabajarás con herramientas de CI/CD para automatizar el ciclo de vida de las soluciones de datos, mejorando la eficiencia en el desarrollo, pruebas y despliegue de pipelines de datos.\n¿Cuál es la CLAVE de este puesto?\n· Conocimiento en tecnologías como Hadoop, Hive, Spark y herramientas de procesamiento distribuido\n· Experiencia sólida en Java, Python o Scala\n· Dominio de consultas SQL complejas para interactuar y extraer información de bases de datos distribuidas de manera eficiente.\n· Experiencia con AWS, Azure o GCP, especialmente con soluciones de Big Data nativas de la nube.\n· Nivel avanzado de Inglés para trabajar en un equipo internacional y participar activamente en reuniones y proyectos a nivel global.\n¿Qué podemos OFRECERTE?\n· Contrato indefinido con Boycor para proyecto estable\n· Modalidad de trabajo: 100% remota\n· Horario: L-J 09 a 18h y, los Viernes y en verano de 08 a 15h.\n·Condiciones económicas: 36.000€ B/A (cifra orientativa abierta a negociación según experiencia a aportar)\n¿Te sientes identificado/a? No dudes en inscribirte.\nReferencia\nEPT02125\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario: 36.000€ - 36.000€ Bruto/año\nBeneficios sociales\nTeletrabajo\n4 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Medio<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br>Conocimientos necesarios<br>Hadoop<br>Python<br>SCALA<br>ETL<br>SQL<br>Spark<br>Cloudera<br>Hive<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>Conocimiento en tecnologías como Hadoop, Hive, Spark y herramientas de procesamiento distribuido<br>· Experiencia sólida en Java, Python o Scala<br>· Dominio de consultas SQL complejas para interactuar y extraer información de bases de datos distribuidas de manera eficiente.<br>· Experiencia con AWS, Azure o GCP, especialmente con soluciones de Big Data nativas de la nube.<br>· Nivel avanzado de Inglés para trabajar en un equipo internacional y participar activamente en reuniones y proyectos a nivel global.<br><br><h3>Descripción</h3><br>¿Eres Data Engineer y estás buscando un nuevo proyecto? Si además te gustaría trabajar desde cualquier parte de España en un entorno con profesionales internacionales de alto rendimiento donde poder perfeccionar tu nivel de inglés ¡Esta es tu oportunidad! Me encuentro buscando un Data Engineer para trabajar de la mano una de las principales multinacionales españolas del sector IT, en un proyecto para la que es considerada como una de las mayores entidades financieras a nivel mundial.<br>¡Queremos conocerte!<br>¿Cómo será tu DÍA A DÍA?<br>· Trabajarás con arquitecturas de datos escalables y distribuidas, utilizando tecnologías como Hadoop, Hive y Spark, para garantizar que los datos se gestionen de manera eficiente y se puedan escalar con el crecimiento del negocio.<br>· Participarás en la administración y mejora continua de clústeres de Big Data<br>· Desarrollarás, optimizarás y mantendrás pipelines de datos<br>· Implementarás y optimizarás procesos ETL avanzados utilizando Python, integrando múltiples fuentes de datos (bases de datos, APIs, archivos) y transformándolos para su posterior análisis y explotación.<br>· Utilizarás SQL avanzado para realizar consultas complejas y obtener insights de grandes volúmenes de datos, optimizando las consultas para que se ejecuten de forma rápida y eficiente.<br>· Trabajarás en plataformas en la nube, como AWS, Azure o GCP<br>· Aplicarás prácticas de DevOps y trabajarás con herramientas de CI/CD para automatizar el ciclo de vida de las soluciones de datos, mejorando la eficiencia en el desarrollo, pruebas y despliegue de pipelines de datos.<br>¿Cuál es la CLAVE de este puesto?<br>· Conocimiento en tecnologías como Hadoop, Hive, Spark y herramientas de procesamiento distribuido<br>· Experiencia sólida en Java, Python o Scala<br>· Dominio de consultas SQL complejas para interactuar y extraer información de bases de datos distribuidas de manera eficiente.<br>· Experiencia con AWS, Azure o GCP, especialmente con soluciones de Big Data nativas de la nube.<br>· Nivel avanzado de Inglés para trabajar en un equipo internacional y participar activamente en reuniones y proyectos a nivel global.<br>¿Qué podemos OFRECERTE?<br>· Contrato indefinido con Boycor para proyecto estable<br>· Modalidad de trabajo: 100% remota<br>· Horario: L-J 09 a 18h y, los Viernes y en verano de 08 a 15h.<br>·Condiciones económicas: 36.000€ B/A (cifra orientativa abierta a negociación según experiencia a aportar)<br>¿Te sientes identificado/a? No dudes en inscribirte.<br>Referencia<br>EPT02125<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario: 36.000€ - 36.000€ Bruto/año<br>Beneficios sociales<br>Teletrabajo<br>4 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "3",
            "porcentaje": "90",
            "skills_necesarias": [
                "Hadoop",
                "Python",
                "Scala",
                "ETL",
                "SQL",
                "PySpark",
                "Cloudera",
                "Hive"
            ],
            "skills_valoradas": [
                "Java",
                "AWS",
                "Azure",
                "GCP (Google Cloud Platform)",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer- Datalake",
        "empresa": "COBSER CONSULTING",
        "fecha_publicacion": "Publicada hace 4d",
        "min_salario": "40.000€",
        "max_salario": "45.000€",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-datalake/of-i3c947653e148b49731b42bdd64f73c?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nAl menos 4 años\nRequisitos mínimos\n-Experiencia de 4 años en el rol.\n- Conocimiento y experiencia en entornos datalake como elemento clave.\n- Experiencia demostrable en desarrollos de ETL con Databricks/Spark, idealmente en Scala (Python valorable).\n- Conocimiento y experiencia en entornos datalake, específicamente en MS Azure (ADLS, Data Factory) y Databricks.\nDescripción\nDesde Cobser Consulting nos encontramos en la búsqueda de un Data Engineer Datalake para el desarrollo evolutivo de los data products de siniestros existentes, desarrollados en Databricks con Scala y coordinados con Data Factory. La información a incorporar en el data product ya se encuentra disponible en el datalake, por lo que se deberá integrarla según la lógica definida por el negocio y sus requisitos.\nfunciones:\nAnalizar la necesidad de información y mapearla a los datos de origen con la ayuda requerida.\nDesarrollar código en Scala Spark para evolucionar las tablas del data product de siniestros y los procesos ETL para enriquecerlo.\nDocumentar e integrar los desarrollos en el manual de operación/BAU correspondiente.\nSe ofrece\n-Trabajo en remoto\n- Salario acorde experiencia entre: *texto oculto*0 € b/a\n- Proyecto estable y de larga duración\n- Formación anual\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario: 40.000€ - 45.000€ Bruto/año\n18 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nAl inscribirte en esta oferta tendrás que aceptar que COBSER CONSULTING reciba y gestione tus datos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>Al menos 4 años<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Experiencia de 4 años en el rol.<br>- Conocimiento y experiencia en entornos datalake como elemento clave.<br>- Experiencia demostrable en desarrollos de ETL con Databricks/Spark, idealmente en Scala (Python valorable).<br>- Conocimiento y experiencia en entornos datalake, específicamente en MS Azure (ADLS, Data Factory) y Databricks.<br><br><h3>Descripción</h3><br>Desde Cobser Consulting nos encontramos en la búsqueda de un Data Engineer Datalake para el desarrollo evolutivo de los data products de siniestros existentes, desarrollados en Databricks con Scala y coordinados con Data Factory. La información a incorporar en el data product ya se encuentra disponible en el datalake, por lo que se deberá integrarla según la lógica definida por el negocio y sus requisitos.<br>funciones:<br>Analizar la necesidad de información y mapearla a los datos de origen con la ayuda requerida.<br>Desarrollar código en Scala Spark para evolucionar las tablas del data product de siniestros y los procesos ETL para enriquecerlo.<br>Documentar e integrar los desarrollos en el manual de operación/BAU correspondiente.<br>Se ofrece<br>-Trabajo en remoto<br>- Salario acorde experiencia entre: *texto oculto*0 € b/a<br>- Proyecto estable y de larga duración<br>- Formación anual<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario: 40.000€ - 45.000€ Bruto/año<br>18 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Al inscribirte en esta oferta tendrás que aceptar que COBSER CONSULTING reciba y gestione tus datos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "4",
            "porcentaje": "75",
            "skills_necesarias": [
                "ETL",
                "Databricks",
                "PySpark",
                "Scala",
                "Azure",
                "ADLS",
                "Data Factory"
            ],
            "skills_valoradas": [
                "Python"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Big Data Engineer - REMOTO",
        "empresa": "Digital Talent Agency Zona Oeste",
        "fecha_publicacion": "Publicada hace 4d (Publicada de nuevo)",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/big-data-engineer-remoto/of-ie99a778c37465ca4a1ac985bfa8f3b?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Medio\nExperiencia mínima\nAl menos 3 años\nConocimientos necesarios\nspark\npython\njava\njenkins\ngit\nkafka\nsonarqube\nopenshift\nagile\ndevops\nDescripción\nBig Data Engineer – Proyecto Tecnológico\n\nUbicación: 100% Remoto\n\nContrato: Indefinido con Zemsania para un proyecto en el sector financiero\n\n¿Qué ofrecemos en Zemsania?\n\nContrato indefinido desde el primer día.\n\nPlan de formación y certificaciones en tecnologías avanzadas.\n\nAcompañamiento personalizado con un People Partner.\n\nParticipación en proyectos tecnológicos innovadores.\n\nTrabajo con tecnologías punteras en un equipo de alto nivel.\n\nRequisitos mínimos:\n\nExperiencia de 3-5 años en entornos de Big Data.\n\nManejo de tecnologías clave:\n\n- Big Data & Spark\n- Java & Python\n- Kafka & Jenkins\n- Git & SonarQube\n- Openshift & Agile\n- Confluence\n\nSoft skills destacadas: Capacidad de comunicación y trabajo en equipo.\n\nRequisitos deseables:\n\nExperiencia previa en el sector financiero.\n\nConocimientos en arquitecturas de datos avanzadas.\n\nFunciones:\n\n- Incorporación al Squad de Data en un proyecto de alto impacto.\n- Desarrollo y mantenimiento de soluciones Big Data.\n- Implementación de arquitecturas basadas en Spark, Kafka y Java/Python.\n- Optimización y automatización de procesos en entornos de datos escalables.\n- Aplicación de metodologías Agile para la gestión eficiente de proyectos.\n\nSi te apasiona el Big Data y quieres formar parte de un equipo innovador, ¡te estamos buscando!\n\nEn Zemsania, creemos en la igualdad de oportunidades y en la diversidad como valores fundamentales para el éxito de nuestra organización. Por ello, garantizamos un proceso de selección basado en el mérito y sin discriminación por motivos de género, edad, discapacidad, orientación sexual, raza, religión o cualquier otra condición personal o social.\nReferencia\nnaYdfErpddqZ\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Administración de bases de datos\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n10 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Medio<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Conocimientos necesarios<br>spark<br>python<br>java<br>jenkins<br>git<br>kafka<br>sonarqube<br>openshift<br>agile<br>devops<br><br><h3>Descripción</h3><br>Big Data Engineer – Proyecto Tecnológico<br><br>Ubicación: 100% Remoto<br><br>Contrato: Indefinido con Zemsania para un proyecto en el sector financiero<br><br>¿Qué ofrecemos en Zemsania?<br><br>Contrato indefinido desde el primer día.<br><br>Plan de formación y certificaciones en tecnologías avanzadas.<br><br>Acompañamiento personalizado con un People Partner.<br><br>Participación en proyectos tecnológicos innovadores.<br><br>Trabajo con tecnologías punteras en un equipo de alto nivel.<br><br><br><h3><br><h3>Requisitos</h3> mínimos</h3>:<br><br>Experiencia de 3-5 años en entornos de Big Data.<br><br>Manejo de tecnologías clave:<br><br>- Big Data & Spark<br>- Java & Python<br>- Kafka & Jenkins<br>- Git & SonarQube<br>- Openshift & Agile<br>- Confluence<br><br>Soft skills destacadas: Capacidad de comunicación y trabajo en equipo.<br><br><br><h3>Requisitos</h3> deseables:<br><br>Experiencia previa en el sector financiero.<br><br>Conocimientos en arquitecturas de datos avanzadas.<br><br>Funciones:<br><br>- Incorporación al Squad de Data en un proyecto de alto impacto.<br>- Desarrollo y mantenimiento de soluciones Big Data.<br>- Implementación de arquitecturas basadas en Spark, Kafka y Java/Python.<br>- Optimización y automatización de procesos en entornos de datos escalables.<br>- Aplicación de metodologías Agile para la gestión eficiente de proyectos.<br><br>Si te apasiona el Big Data y quieres formar parte de un equipo innovador, ¡te estamos buscando!<br><br>En Zemsania, creemos en la igualdad de oportunidades y en la diversidad como valores fundamentales para el éxito de nuestra organización. Por ello, garantizamos un proceso de selección basado en el mérito y sin discriminación por motivos de género, edad, discapacidad, orientación sexual, raza, religión o cualquier otra condición personal o social.<br>Referencia<br>naYdfErpddqZ<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Administración de bases de datos<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>10 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "3",
            "porcentaje": "75",
            "skills_necesarias": [
                "PySpark",
                "Python",
                "Java",
                "Jenkins",
                "Git",
                "Kafka",
                "SonarQube",
                "Openshift",
                "Agile",
                "DevOps"
            ],
            "skills_valoradas": [
                "Confluence"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Consultor Data Analytics",
        "empresa": "MBD ANALYTICS",
        "fecha_publicacion": "Publicada hace 5d",
        "min_salario": "22.000€",
        "max_salario": "27.000€",
        "url_oferta": "https://www.infojobs.net/alcobendas/consultor-data-analytics/of-i95d2efece446749c8a3d0450125e44?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nLicenciatura\nExperiencia mínima\nNo Requerida\nIdiomas requeridos\nInglés - Nivel Intermedio\nConocimientos necesarios\nDiseño de bases de datos\nBase de datos relacional\nProgramación\nPower BI\nPython\nSQL\nTableau\nDescripción\nConsultor Data Analytics y Business Intelligence, para desarrollar carrera profesional en empresa Consultora especializada en el sector, con integración inmediata en equipo de trabajo.\nFunciones:\n- Ejecución de proyectos de Data Analytics, desarrollando tareas de manipulación de bases de datos, análisis cuantitativos de grandes volúmenes de información y uso de herramientas de visualización de datos.\n- Identificación de conclusiones de negocio relevantes en los análisis realizados y elaboración de presentaciones de resultados con recomendaciones para departamentos de marketing, comercial, clientes y CRM.\nRequisitos mínimos:\n- REQUISITOS MINIMOS\nLicenciatura en Carreras Técnicas (Ingenierías, Matemáticas,..) o ADE\nExperiencia en manejo de excel y powerpoint.\nConocimientos de programación (sql)\nCapacidad analítica y visión de negocio.\nFacilidad de relación y trabajo en equipo\nInglés hablado y escrito (B2)\nREQUISITOS DESEADOS\nSe valorará experiencia en sector Telecomunicaciones o en sector Seguros.\nExperiencia de al menos 6 meses en Consultoría de Business Intelligence o Departamentos de Análisis (analista).\nExperiencia en programación sql/Phyton y herramientas de visualización (PowerBI, Qlick).\nCategoría\nInformática y telecomunicaciones - ERP, CRM, Business Intelligence\nNivel\nEspecialista\nNúmero de vacantes\n3\nSalario\nSalario: 22.000€ - 27.000€ Bruto/año\n122 inscritos a esta oferta para 3 vacantes\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Licenciatura<br><h4>Experiencia mínima</h4><br>No Requerida<br>Idiomas requeridos<br>Inglés - Nivel Intermedio<br>Conocimientos necesarios<br>Diseño de bases de datos<br>Base de datos relacional<br>Programación<br>Power BI<br>Python<br>SQL<br>Tableau<br><br><h3>Descripción</h3><br>Consultor Data Analytics y Business Intelligence, para desarrollar carrera profesional en empresa Consultora especializada en el sector, con integración inmediata en equipo de trabajo.<br>Funciones:<br>- Ejecución de proyectos de Data Analytics, desarrollando tareas de manipulación de bases de datos, análisis cuantitativos de grandes volúmenes de información y uso de herramientas de visualización de datos.<br>- Identificación de conclusiones de negocio relevantes en los análisis realizados y elaboración de presentaciones de resultados con recomendaciones para departamentos de marketing, comercial, clientes y CRM.<br><br><h3><br><h3>Requisitos</h3> mínimos</h3>:<br>- REQUISITOS MINIMOS<br>Licenciatura en Carreras Técnicas (Ingenierías, Matemáticas,..) o ADE<br>Experiencia en manejo de excel y powerpoint.<br>Conocimientos de programación (sql)<br>Capacidad analítica y visión de negocio.<br>Facilidad de relación y trabajo en equipo<br>Inglés hablado y escrito (B2)<br>REQUISITOS DESEADOS<br>Se valorará experiencia en sector Telecomunicaciones o en sector Seguros.<br>Experiencia de al menos 6 meses en Consultoría de Business Intelligence o Departamentos de Análisis (analista).<br>Experiencia en programación sql/Phyton y herramientas de visualización (PowerBI, Qlick).<br>Categoría<br>Informática y telecomunicaciones - ERP, CRM, Business Intelligence<br>Nivel<br>Especialista<br>Número de vacantes<br>3<br>Salario<br>Salario: 22.000€ - 27.000€ Bruto/año<br>122 inscritos a esta oferta para 3 vacantes<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B2",
            "anios_experiencia": "0",
            "porcentaje": "75",
            "skills_necesarias": [
                "Bases de datos",
                "Base de datos relacional",
                "Power BI",
                "Python",
                "SQL",
                "Tableau"
            ],
            "skills_valoradas": [
                "Experiencia en sector Telecomunicaciones",
                "Experiencia en sector Seguros",
                "BI (Business Intelligence)",
                "Qlik"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Experto/a Big Data con Francés",
        "empresa": "Sopra Steria",
        "fecha_publicacion": "Publicada hace 5d",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/experto-big-data-con-frances/of-i6b3dbf7b184f16b2f7f0e7056af3b1?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=1&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Medio\nExperiencia mínima\nAl menos 4 años\nConocimientos necesarios\nBig data\nSpark\nSCALA\nRequisitos mínimos\n-Al menos 4 años de experiencia trabajando con Spark y Scala.\n- Nivel alto de francés.\n- Capacidad de liderazgo y comunicación.\nDescripción\nPorque trabajar en Sopra Steria, también es sentir Sopra Steria\nSomos un reconocido líder europeo en consultoría, servicios digitales y desarrollo de software, con cerca de 56.000 empleados en casi 30 países y más de 4.000 en España.\nNos enfocamos en las personas, en su formación y desarrollo profesional, lo que nos impulsa a crecer y mejorar constantemente.\nTenemos pasión por lo digital y al igual que tú, buscamos la mejor de las aventuras. Queremos que tu día a día se convierta en la mejor de tus inspiraciones. Que aprendas, aportes, te diviertas, crezcas y que, sobre todo, disfrutes al máximo.\nSi quieres formar parte de un equipo \"Great Place to Work\", ¡Sigue leyendo!\nDentro del plan de expansión y crecimiento de nuestro Centro de Servicios buscamos incorporar un/a Experto/a en Big Data con francés alto para trabajar en proyectos internacionales.\n¿Cuáles serán tus funciones?\n- Liderar técnicamente los proyectos BigData de la DataFactory.\n- Asumir un rol activo en los desarrollos complejos.\n- Desplegar la competencia de los colaboradores de la Data Factory (mentoring, formación).\n¿Qué tenemos para ti?\n· Contrato indefinido y jornada completa\n· 23 días de vacaciones\n· Formación continua: competencias técnicas, transversales y de idiomas. Contamos con acceso a certificaciones, formaciones de los principales Partners Tecnológicos, plataformas online y ¡mucho más!\n· Seguro de vida y de accidentes\n· Posibilidad de acogerte a nuestra retribución flexible (seguro médico, cheques guarderías, transporte, comida y formación)\n· Acceso a Privilege Club, donde encontrarás descuentos interesantes en las principales marcas\n· Onboarding personalizado y detallado. Te acompañamos en todo momento para que te sientas #soprano desde el primer momento.\n· Oficina con espacios reservados al ocio. ¡Trabajo y diversión unido!\n· Compañerismo y buen ambiente, el poder de la unión lo tenemos presente.\nY lo más importante...Tienes la posibilidad de desarrollar tu carrera profesional con nosotros: Crearemos juntos un plan de carrera personalizado. Te formarás, marcaremos objetivos y llevaremos a cabo un seguimiento para asegurarnos de que lo conseguimos juntos. Escuchamos tus prioridades y luchamos por ellas.\n¡Aquí tu voz importa! ¡Únete a nosotros y sé parte de algo más!\nThe world is how we shape it\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEspecialista\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\n1 inscrito a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Medio<br><h4>Experiencia mínima</h4><br>Al menos 4 años<br>Conocimientos necesarios<br>Big data<br>Spark<br>SCALA<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Al menos 4 años de experiencia trabajando con Spark y Scala.<br>- Nivel alto de francés.<br>- Capacidad de liderazgo y comunicación.<br><br><h3>Descripción</h3><br>Porque trabajar en Sopra Steria, también es sentir Sopra Steria<br>Somos un reconocido líder europeo en consultoría, servicios digitales y desarrollo de software, con cerca de 56.000 empleados en casi 30 países y más de 4.000 en España.<br>Nos enfocamos en las personas, en su formación y desarrollo profesional, lo que nos impulsa a crecer y mejorar constantemente.<br>Tenemos pasión por lo digital y al igual que tú, buscamos la mejor de las aventuras. Queremos que tu día a día se convierta en la mejor de tus inspiraciones. Que aprendas, aportes, te diviertas, crezcas y que, sobre todo, disfrutes al máximo.<br>Si quieres formar parte de un equipo \"Great Place to Work\", ¡Sigue leyendo!<br>Dentro del plan de expansión y crecimiento de nuestro Centro de Servicios buscamos incorporar un/a Experto/a en Big Data con francés alto para trabajar en proyectos internacionales.<br>¿Cuáles serán tus funciones?<br>- Liderar técnicamente los proyectos BigData de la DataFactory.<br>- Asumir un rol activo en los desarrollos complejos.<br>- Desplegar la competencia de los colaboradores de la Data Factory (mentoring, formación).<br>¿Qué tenemos para ti?<br>· Contrato indefinido y jornada completa<br>· 23 días de vacaciones<br>· Formación continua: competencias técnicas, transversales y de idiomas. Contamos con acceso a certificaciones, formaciones de los principales Partners Tecnológicos, plataformas online y ¡mucho más!<br>· Seguro de vida y de accidentes<br>· Posibilidad de acogerte a nuestra retribución flexible (seguro médico, cheques guarderías, transporte, comida y formación)<br>· Acceso a Privilege Club, donde encontrarás descuentos interesantes en las principales marcas<br>· Onboarding personalizado y detallado. Te acompañamos en todo momento para que te sientas #soprano desde el primer momento.<br>· Oficina con espacios reservados al ocio. ¡Trabajo y diversión unido!<br>· Compañerismo y buen ambiente, el poder de la unión lo tenemos presente.<br>Y lo más importante...Tienes la posibilidad de desarrollar tu carrera profesional con nosotros: Crearemos juntos un plan de carrera personalizado. Te formarás, marcaremos objetivos y llevaremos a cabo un seguimiento para asegurarnos de que lo conseguimos juntos. Escuchamos tus prioridades y luchamos por ellas.<br>¡Aquí tu voz importa! ¡Únete a nosotros y sé parte de algo más!<br>The world is how we shape it<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Especialista<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>1 inscrito a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "4",
            "porcentaje": "80",
            "skills_necesarias": [
                "Big Data",
                "PySpark",
                "Scala"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Brand Specialist (Data Expert), Spain Fresh",
        "empresa": "Amazon Europe Core",
        "fecha_publicacion": "Publicada hace 5d (Publicada de nuevo)",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/brand-specialist-data-expert-spain-fresh/of-ic021db729a468fac5130485890bd71?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nLicenciatura\nExperiencia mínima\nAl menos 1 año\nRequisitos mínimos\nBASIC QUALIFICATIONS - Bachelor's/Master degree in engineering, Business Administration/Economics with business analytics/Big data specialization, or similar program.\n- Experience using SQL.\n- Minimum of 12 months professional experience after graduation in Sales, Buying, Project Management, Supply Chain, Consulting, Finance, Account Management or Marketing.\n- Fluent written and verbal communication in English and Spanish (minimum C1 level)\n- Knowledge in MS Office programs (e.g. Excel, PowerPoint)\nPREFERRED QUALIFICATIONS - Programming language knowledge (i.e. C, C++, Python, R, VBA, or similar)\n- Knowledge of a 3rd language\n- Prior experience in the e-commerce industry\n- Previous experience in a related client-facing role\n- Experience using analytical specific tools such as Google Analytics or HTML is a plus\n- Basic knowledge of website content management systems\n- Confidence in communicating both, internally and externally\n- Planning, prioritization and time-management skills\nAmazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.\nOur inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you're applying in isn't listed, please contact your Recruiting Partner.\nDescripción\nDESCRIPTION At Amazon we're on the lookout for the curious, those who think big and accept challenges, willing to come build the future with us.\n\nAmazon Vendor Services (AVS) is a paid B2B service that aims to help strategic brands partner with Amazon to grow their business. As a Brand Specialist, you will gain 360-degree exposure to all areas of e-commerce at European level. You will be an Account Manager for our most strategic retail Vendors in one of our Product Categories, for example PC, Beauty, Toys or Kitchen. You will act as a consultant driving selection and promotional activities, monitor and work on success metrics and ensure that vendor and customer experience is at the highest level. Furthermore, you will be working together with external and internal stakeholders (e.g. external Key Account Managers and internal Vendor Managers) to implement new ideas and processes within Amazon EU, such as Supply chain management, Finance and Marketing while developing your skills and future career. Your role will focus on four crucial business areas:\n\nKey job responsibilities\nCore Service:\n\n- Use your analytical skills to identify opportunities for Retail Vendors and provide recommendations to improve overall business performance.\n- Cooperate with our Vendors to utilize Amazon programs (i.e.: Amazon business) for driving long term benefits.\n\nAvailability & Operational Excellence:\n\n- Drive supply-chain operational excellence initiatives by reducing costs, defects, lead times, and other KPIs.\n- Manage and monitor stock levels in our fulfilment centres by utilizing our ordering mechanisms.\n\nPromotion & Funding:\n\n- Provide recommendations for the Vendors marketing and advertising campaigns to promote new products, increase traffic and improve conversion.\n- Plan, implement and manage promotional activities for Amazon events such as Prime Day and Brand Weeks to help your vendor grow.\n\nSelection & IDQ (Item Data Quality):\n\n- Expand selection by managing the launch of new products and improving discoverability. Identify product gaps, onboard new products and ensure a smooth ramp-up.\n- Improve the customer journey on Amazon, e.g. by performing walk the store sessions, competitor benchmarking and creating enhanced content on detail pages.\n\nData and tools:\n\n- Develop new capabilities in the team based by creating and deploying new data analysis tools and processes.\n- Develop and maintain data analysis and reporting tools to elevate business insights produced by the team.\n- Improve team efficiency by developing and deploying new automation tools for streamlined data handling and analysis.\n\nA day in the life\nInterested in how a day in the life of a Brand Specialist looks like? Check out the following videos to gain more insight into the role and team.\n\n1) Brand Specialists at Amazon - Jump Right In - see video https://www.youtube.com/watch?v=C4wafOkhayA\n2) Brand Specialists at Amazon. What do they do? - see video https://www.youtube.com/watch?v=fYaySG_trNY\n\nAbout the team\nAre you looking for a diverse and international environment? Amazon offers you the chance to build up your own network at European level by participating in community events such as team activities, offsites in one of our EU countries or by joining some of our affinity groups. Come build the future with us!\nReferencia\n242076\nCategoría\nOtros - Sin especificar\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nNo disponemos de información del número de inscritos. Este proceso se gestiona desde la web de la empresa (fuera de InfoJobs).\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Licenciatura<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br><strong>BASIC QUALIFICATIONS</strong><br> - Bachelor's/Master degree in engineering, Business Administration/Economics with business analytics/Big data specialization, or similar program.<br>- Experience using SQL.<br>- Minimum of 12 months professional experience after graduation in Sales, Buying, Project Management, Supply Chain, Consulting, Finance, Account Management or Marketing.<br>- Fluent written and verbal communication in English and Spanish (minimum C1 level)<br>- Knowledge in MS Office programs (e.g. Excel, PowerPoint)<br><strong>PREFERRED QUALIFICATIONS</strong><br> - Programming language knowledge (i.e. C, C++, Python, R, VBA, or similar)<br>- Knowledge of a 3rd language<br>- Prior experience in the e-commerce industry<br>- Previous experience in a related client-facing role<br>- Experience using analytical specific tools such as Google Analytics or HTML is a plus<br>- Basic knowledge of website content management systems<br>- Confidence in communicating both, internally and externally<br>- Planning, prioritization and time-management skills<br>Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.<br>Our inclusive culture empowers Amazonians to deliver the best results for our customers. If you have a disability and need a workplace accommodation or adjustment during the application and hiring process, including support for the interview or onboarding process, please visit https://amazon.jobs/content/en/how-we-hire/accommodations for more information. If the country/region you're applying in isn't listed, please contact your Recruiting Partner.<br><br><h3>Descripción</h3><br>DESCRIPTION At Amazon we're on the lookout for the curious, those who think big and accept challenges, willing to come build the future with us.<br><br>Amazon Vendor Services (AVS) is a paid B2B service that aims to help strategic brands partner with Amazon to grow their business. As a Brand Specialist, you will gain 360-degree exposure to all areas of e-commerce at European level. You will be an Account Manager for our most strategic retail Vendors in one of our Product Categories, for example PC, Beauty, Toys or Kitchen. You will act as a consultant driving selection and promotional activities, monitor and work on success metrics and ensure that vendor and customer experience is at the highest level. Furthermore, you will be working together with external and internal stakeholders (e.g. external Key Account Managers and internal Vendor Managers) to implement new ideas and processes within Amazon EU, such as Supply chain management, Finance and Marketing while developing your skills and future career. Your role will focus on four crucial business areas:<br><br>Key job responsibilities<br>Core Service:<br><br>- Use your analytical skills to identify opportunities for Retail Vendors and provide recommendations to improve overall business performance.<br>- Cooperate with our Vendors to utilize Amazon programs (i.e.: Amazon business) for driving long term benefits.<br><br>Availability & Operational Excellence:<br><br>- Drive supply-chain operational excellence initiatives by reducing costs, defects, lead times, and other KPIs.<br>- Manage and monitor stock levels in our fulfilment centres by utilizing our ordering mechanisms.<br><br>Promotion & Funding:<br><br>- Provide recommendations for the Vendors marketing and advertising campaigns to promote new products, increase traffic and improve conversion.<br>- Plan, implement and manage promotional activities for Amazon events such as Prime Day and Brand Weeks to help your vendor grow.<br><br>Selection & IDQ (Item Data Quality):<br><br>- Expand selection by managing the launch of new products and improving discoverability. Identify product gaps, onboard new products and ensure a smooth ramp-up.<br>- Improve the customer journey on Amazon, e.g. by performing walk the store sessions, competitor benchmarking and creating enhanced content on detail pages.<br><br>Data and tools:<br><br>- Develop new capabilities in the team based by creating and deploying new data analysis tools and processes.<br>- Develop and maintain data analysis and reporting tools to elevate business insights produced by the team.<br>- Improve team efficiency by developing and deploying new automation tools for streamlined data handling and analysis.<br><br>A day in the life<br>Interested in how a day in the life of a Brand Specialist looks like? Check out the following videos to gain more insight into the role and team.<br><br>1) Brand Specialists at Amazon - Jump Right In - see video https://www.youtube.com/watch?v=C4wafOkhayA<br>2) Brand Specialists at Amazon. What do they do? - see video https://www.youtube.com/watch?v=fYaySG_trNY<br><br>About the team<br>Are you looking for a diverse and international environment? Amazon offers you the chance to build up your own network at European level by participating in community events such as team activities, offsites in one of our EU countries or by joining some of our affinity groups. Come build the future with us!<br>Referencia<br>242076<br>Categoría<br>Otros - Sin especificar<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>No disponemos de información del número de inscritos. Este proceso se gestiona desde la web de la empresa (fuera de InfoJobs).<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "1",
            "porcentaje": "70",
            "skills_necesarias": [
                "SQL",
                "MS Office",
                "C",
                "C++",
                "Python",
                "R",
                "VBA",
                "Google Analytics"
            ],
            "skills_valoradas": [
                "e-commerce",
                "contenido de gestión de sitios web"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer | 100% remote | Freelance",
        "empresa": "EKKIDEN",
        "fecha_publicacion": "Publicada hace 5d (Publicada de nuevo)",
        "min_salario": "3€",
        "max_salario": "4.200€",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-100-remote-freelance/of-i328c2399064942825bd9e8b1c21dcc?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nSin estudios\nExperiencia mínima\nAl menos 2 años\nRequisitos mínimos\nWhat we are looking for:\n-+3 years of experience in data engineering roles with expertise in Databricks, AWS Glue, or Apache Spark.\n-Strong programming skills in Python or similar languages.\n-Proficiency with SQL/NoSQL databases (MySQL, PostgreSQL, MongoDB) and data integration.\n-Experience working with ETL frameworks and building data pipelines.\n-Familiarity with Azure cloud environments and their data services (Databricks, Data Factory, etc.).\n-Knowledge of Agile/Scrum methodologies and experience with continuous delivery and deployment.\n-Demonstrated experience in greenfield development projects, driving innovative solutions from inception to completion\n-Strong problem-solving and communication skills, with the ability to collaborate across teams, including business and data analysts, to translate requirements into actionable solutions\n-High english level\nDescripción\nAbout the job :\nTo strengthen the clients experienced and motivated Data Platform team, the client is looking for a Data Engineer. In this role, you will be jointly responsible for exciting and challenging projects, participating in all phases from design to implementation. You will have the opportunity to work on cutting-edge technologies and processes while contributing to the organization's goals of data digitization and optimization.\nThey are focused on creating and maintaining scalable systems, supporting the collection, processing, and transformation of large datasets. A strong understanding of core engineering concepts, best practices such as testing, source control, and agile planning are essential, as well as an ability to take well-scoped components of larger projects and see them through to completion. This position is ideal for someone looking to grow as an engineer, mastering specific products or areas within our systems.\nData Engineer | 100% remote | Freelance\nReferencia\n240453\nCategoría\nInformática y telecomunicaciones - Sistemas\nNivel\nMando intermedio\nNúmero de vacantes\n1\nSalario\nSalario: 3€ - 4.200€ Bruto/mes\nNo disponemos de información del número de inscritos. Este proceso se gestiona desde la web de la empresa (fuera de InfoJobs).\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Sin estudios<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>What we are looking for:<br>-+3 years of experience in data engineering roles with expertise in Databricks, AWS Glue, or Apache Spark.<br>-Strong programming skills in Python or similar languages.<br>-Proficiency with SQL/NoSQL databases (MySQL, PostgreSQL, MongoDB) and data integration.<br>-Experience working with ETL frameworks and building data pipelines.<br>-Familiarity with Azure cloud environments and their data services (Databricks, Data Factory, etc.).<br>-Knowledge of Agile/Scrum methodologies and experience with continuous delivery and deployment.<br>-Demonstrated experience in greenfield development projects, driving innovative solutions from inception to completion<br>-Strong problem-solving and communication skills, with the ability to collaborate across teams, including business and data analysts, to translate requirements into actionable solutions<br>-High english level<br><br><h3>Descripción</h3><br>About the job :<br>To strengthen the clients experienced and motivated Data Platform team, the client is looking for a Data Engineer. In this role, you will be jointly responsible for exciting and challenging projects, participating in all phases from design to implementation. You will have the opportunity to work on cutting-edge technologies and processes while contributing to the organization's goals of data digitization and optimization.<br>They are focused on creating and maintaining scalable systems, supporting the collection, processing, and transformation of large datasets. A strong understanding of core engineering concepts, best practices such as testing, source control, and agile planning are essential, as well as an ability to take well-scoped components of larger projects and see them through to completion. This position is ideal for someone looking to grow as an engineer, mastering specific products or areas within our systems.<br>Data Engineer | 100% remote | Freelance<br>Referencia<br>240453<br>Categoría<br>Informática y telecomunicaciones - Sistemas<br>Nivel<br>Mando intermedio<br>Número de vacantes<br>1<br>Salario<br>Salario: 3€ - 4.200€ Bruto/mes<br>No disponemos de información del número de inscritos. Este proceso se gestiona desde la web de la empresa (fuera de InfoJobs).<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "3",
            "porcentaje": "80",
            "skills_necesarias": [
                "Databricks",
                "AWS",
                "Spark",
                "Python",
                "SQL",
                "NoSQL",
                "ETL",
                "Azure"
            ],
            "skills_valoradas": [
                "Agile",
                "Scrum"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer",
        "empresa": "Vipirsa",
        "fecha_publicacion": "Publicada hace 5d",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer/of-ia5cda316eb43d49aa56a4e819d7a01?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 3 años\nConocimientos necesarios\nAzure\nDatabricks\nSynapse\nData Factory\nPython\nSQL\nETL\nSpark\nJenkins\nTerraform\nDescripción\nDesde VIPIRSA, empresa especializada en proyectos de desarrollos tecnológicos en búsqueda de auténticos talentos, estamos buscando un Ingeniero de Datos en Azure con al menos 3-5 años de experiencia.\nLa modalidad de trabajo es en remoto 100% en horario de oficina.\nREQUISITOS:\n-Ingeniero de datos con al menos 3-5 experiencia en arquitecturas Azure: Databricks, Synapse, Datafactory, SQL Database.\n-Diseño y creación de modelos de datos (definición y creación de tablas, complejidad de relaciones y de queries, grandes volumetrías, procedimientos almacenados...)\n-Desarrollo de pipelines y transformaciones de datos complejas (ETLs).\n-Buen nivel de SQL e idealmente experiencia con python.\n-Experiencia en proyectos agile\n-Valorable conocimiento y experiencia con metodologías y herramientas para despliegue e integración continua (Azure DevOps, Github, Jenkins, Terraform, Docker, Ansible...)\n-Valorable conocimiento/experiencia en spark/pyspark.\n-Key words para búsquedas: Databricks, Synapse, Data Factory\n-Inglés B2\nSE OFRECE:\n-Contratación indefinida con Vipirsa.\n-Salario entre 35.000 y 37.000 euros brutos al año\nReferencia\n390586\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n10 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Conocimientos necesarios<br>Azure<br>Databricks<br>Synapse<br>Data Factory<br>Python<br>SQL<br>ETL<br>Spark<br>Jenkins<br>Terraform<br><br><h3>Descripción</h3><br>Desde VIPIRSA, empresa especializada en proyectos de desarrollos tecnológicos en búsqueda de auténticos talentos, estamos buscando un Ingeniero de Datos en Azure con al menos 3-5 años de experiencia.<br>La modalidad de trabajo es en remoto 100% en horario de oficina.<br>REQUISITOS:<br>-Ingeniero de datos con al menos 3-5 experiencia en arquitecturas Azure: Databricks, Synapse, Datafactory, SQL Database.<br>-Diseño y creación de modelos de datos (definición y creación de tablas, complejidad de relaciones y de queries, grandes volumetrías, procedimientos almacenados...)<br>-Desarrollo de pipelines y transformaciones de datos complejas (ETLs).<br>-Buen nivel de SQL e idealmente experiencia con python.<br>-Experiencia en proyectos agile<br>-Valorable conocimiento y experiencia con metodologías y herramientas para despliegue e integración continua (Azure DevOps, Github, Jenkins, Terraform, Docker, Ansible...)<br>-Valorable conocimiento/experiencia en spark/pyspark.<br>-Key words para búsquedas: Databricks, Synapse, Data Factory<br>-Inglés B2<br>SE OFRECE:<br>-Contratación indefinida con Vipirsa.<br>-Salario entre 35.000 y 37.000 euros brutos al año<br>Referencia<br>390586<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>10 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B2",
            "anios_experiencia": "3",
            "porcentaje": "85",
            "skills_necesarias": [
                "Azure",
                "Databricks",
                "Synapse",
                "Data Factory",
                "Python",
                "SQL",
                "ETL",
                "PySpark",
                "Jenkins",
                "Terraform"
            ],
            "skills_valoradas": [
                "Azure",
                "Git",
                "Docker",
                "Ansible",
                "PySpark"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Técnico/a Automoción (Mecánico/a)",
        "empresa": "Solera Global Data & Content",
        "fecha_publicacion": "Publicada el 31 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/alcobendas/tecnico-automocion-mecanico/of-if73285fc384953812b19607237e592?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior - Técnico Superior en Automoción\nExperiencia mínima\nAl menos 1 año\nIdiomas requeridos\nInglés - Nivel Intermedio\nConocimientos necesarios\nAutomóviles\nVehículos\nPiezas\nTalleres\nChapa\nDescripción\nFUNCIONES PRINCIPALES\nDesarrollo y volcado de datos en el programa Audatex para la valoración de daños en automóviles, motos y vehículos industriales:\nCodificación del despiece del vehículo según modelos y acabados de los países para los cuales se desarrolle la documentación, con las referencias y precios del fabricante.\nCálculo y codificación de tiempos de reparación (mecánica, electricidad, chapa y pintura) y de desmontaje y montaje de piezas.\nRealización y codificación de gráficos con los despieces de las distintas zonas del vehículo.\nCorrelación de tres bases de datos (gráficos, piezas y tiempos).\nCodificación de equipamientos y números de identificación de vehículos.\nRealización de notas técnicas de vehículos.\nGestión de documentación y novedades de varios fabricantes\nREQUISITOS\nIMPRESCINDIBLE:\nGrado Medio o Superior en Automoción\nExperiencia de aproximadamente 6 meses en talleres\nOTROS:\nInglés medio\nMicrosoft\nWindows\nConocimienot y manejo de EPCs (catálogos de piezas) y manueales de automóviles\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nProfesiones, artes y oficios - Automoción\nNivel\nEmpleado/a\nPersonal a cargo\n0\nNúmero de vacantes\n3\nSalario\nSalario no disponible\nBeneficios sociales\nFlexibilidad horaria\nSeguro médico\nCheque restaurante\n7 inscritos a esta oferta para 3 vacantes\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior - Técnico Superior en Automoción<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br>Idiomas requeridos<br>Inglés - Nivel Intermedio<br>Conocimientos necesarios<br>Automóviles<br>Vehículos<br>Piezas<br>Talleres<br>Chapa<br><br><h3>Descripción</h3><br>FUNCIONES PRINCIPALES<br>Desarrollo y volcado de datos en el programa Audatex para la valoración de daños en automóviles, motos y vehículos industriales:<br>Codificación del despiece del vehículo según modelos y acabados de los países para los cuales se desarrolle la documentación, con las referencias y precios del fabricante.<br>Cálculo y codificación de tiempos de reparación (mecánica, electricidad, chapa y pintura) y de desmontaje y montaje de piezas.<br>Realización y codificación de gráficos con los despieces de las distintas zonas del vehículo.<br>Correlación de tres bases de datos (gráficos, piezas y tiempos).<br>Codificación de equipamientos y números de identificación de vehículos.<br>Realización de notas técnicas de vehículos.<br>Gestión de documentación y novedades de varios fabricantes<br>REQUISITOS<br>IMPRESCINDIBLE:<br>Grado Medio o Superior en Automoción<br>Experiencia de aproximadamente 6 meses en talleres<br>OTROS:<br>Inglés medio<br>Microsoft<br>Windows<br>Conocimienot y manejo de EPCs (catálogos de piezas) y manueales de automóviles<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Profesiones, artes y oficios - Automoción<br>Nivel<br>Empleado/a<br>Personal a cargo<br>0<br>Número de vacantes<br>3<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Flexibilidad horaria<br>Seguro médico<br>Cheque restaurante<br>7 inscritos a esta oferta para 3 vacantes<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B1",
            "anios_experiencia": "1",
            "porcentaje": "35",
            "skills_necesarias": [
                "Automóviles",
                "Vehículos",
                "Piezas",
                "Talleres",
                "Chapa",
                "Microsoft",
                "EPCs"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Project Lead // Remoto",
        "empresa": "BOYCOR",
        "fecha_publicacion": "Publicada el 30 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-project-lead-remoto/of-ia5a4429f3b46b3b7dca179459bc4d8?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Medio\nExperiencia mínima\nAl menos 3 años\nConocimientos necesarios\nSnowflake\nBig data\nITIL\nInglés\nRequisitos mínimos\nExperiencia previa en gestión de proyectos de datos.\n· Experiencia en Snowflake.\n· Conocimientos en CI/CD y DevOps aplicados a entornos de datos.\n· Conocimientos en ITIL y buenas prácticas en la gestión de servicios de TI.\n· Nivel C1 de inglés (lo utilizarás en tu día a día)\nDescripción\n¿Eres Data Project Lead y estás pensado en un cambio profesional? Desde Boycor, buscamos un Líder de Proyecto para trabajar directamente en plantilla de multinacional francesa IT, en un proyecto internacional para modernizar la infraestructura y optimizar el rendimiento de las soluciones Big Data de compañía estadounidense.\n¡Queremos conocerte!\n¿Cómo SERÁ tu día a día?\n· Liderar la gestión y ejecución de proyectos de datos, asegurando el cumplimiento de plazos y objetivos.\n· Colaborar con stakeholders internos y externos para entender necesidades de negocio y traducirlas en soluciones basadas en datos.\n· Gestionar la entrega integral de los proyectos, garantizando que todos los servicios se entregan a tiempo, dentro del alcance y con los estándares de calidad esperados.\n· Supervisar y gestionar el rendimiento de los equipos, garantizando el cumplimiento de los SLA, los KPIs y las expectativas del cliente.\n· Coordinarse con equipos multidisciplinares, incluidos los de desarrollo, control de calidad, infraestructura y operaciones, para garantizar una correcta prestación de servicios.\n· Aplicar y mantener las mejores prácticas de ITIL para optimizar los procesos de gestión de incidentes, problemas, cambios y solicitudes.\n· Diseño y ejecución de estrategias innovadoras de Data.\n· Optimizar procesos de datos y recomendar mejoras basadas en insights analíticos.\n· Colaborar con equipos de DevOps e integrar procesos de CI/CD en proyectos de datos.\n· Implementar y asegurar el cumplimiento de buenas prácticas basadas en ITIL para la gestión de servicios de datos.\n· Implementación de metodologías ágiles.\n¿Cuál es la CLAVE de este puesto?\n· Experiencia previa en gestión de proyectos de datos.\n· Experiencia en Snowflake.\n· Conocimientos en CI/CD y DevOps aplicados a entornos de datos.\n· Conocimientos en ITIL y buenas prácticas en la gestión de servicios de TI.\n· Nivel C1 de inglés (lo utilizarás en tu día a día)\n¿Qué podemos OFRECERTE?\n· Contrato indefinido con cliente para puesto estable.\n· Modalidad de trabajo: 100% remoto.\n· Horario flexible: L-J 8:00-17:30H, V 8:00-15:00H. Jornada intensiva en verano.\n· Condiciones económicas: salario competitivo abierto a negociación según experiencia.\n¿Te sientes identificado/a? No dudes en inscribirte.\nReferencia\nEPT048-25\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Gestión de proyectos\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\n4 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Medio<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Conocimientos necesarios<br>Snowflake<br>Big data<br>ITIL<br>Inglés<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>Experiencia previa en gestión de proyectos de datos.<br>· Experiencia en Snowflake.<br>· Conocimientos en CI/CD y DevOps aplicados a entornos de datos.<br>· Conocimientos en ITIL y buenas prácticas en la gestión de servicios de TI.<br>· Nivel C1 de inglés (lo utilizarás en tu día a día)<br><br><h3>Descripción</h3><br>¿Eres Data Project Lead y estás pensado en un cambio profesional? Desde Boycor, buscamos un Líder de Proyecto para trabajar directamente en plantilla de multinacional francesa IT, en un proyecto internacional para modernizar la infraestructura y optimizar el rendimiento de las soluciones Big Data de compañía estadounidense.<br>¡Queremos conocerte!<br>¿Cómo SERÁ tu día a día?<br>· Liderar la gestión y ejecución de proyectos de datos, asegurando el cumplimiento de plazos y objetivos.<br>· Colaborar con stakeholders internos y externos para entender necesidades de negocio y traducirlas en soluciones basadas en datos.<br>· Gestionar la entrega integral de los proyectos, garantizando que todos los servicios se entregan a tiempo, dentro del alcance y con los estándares de calidad esperados.<br>· Supervisar y gestionar el rendimiento de los equipos, garantizando el cumplimiento de los SLA, los KPIs y las expectativas del cliente.<br>· Coordinarse con equipos multidisciplinares, incluidos los de desarrollo, control de calidad, infraestructura y operaciones, para garantizar una correcta prestación de servicios.<br>· Aplicar y mantener las mejores prácticas de ITIL para optimizar los procesos de gestión de incidentes, problemas, cambios y solicitudes.<br>· Diseño y ejecución de estrategias innovadoras de Data.<br>· Optimizar procesos de datos y recomendar mejoras basadas en insights analíticos.<br>· Colaborar con equipos de DevOps e integrar procesos de CI/CD en proyectos de datos.<br>· Implementar y asegurar el cumplimiento de buenas prácticas basadas en ITIL para la gestión de servicios de datos.<br>· Implementación de metodologías ágiles.<br>¿Cuál es la CLAVE de este puesto?<br>· Experiencia previa en gestión de proyectos de datos.<br>· Experiencia en Snowflake.<br>· Conocimientos en CI/CD y DevOps aplicados a entornos de datos.<br>· Conocimientos en ITIL y buenas prácticas en la gestión de servicios de TI.<br>· Nivel C1 de inglés (lo utilizarás en tu día a día)<br>¿Qué podemos OFRECERTE?<br>· Contrato indefinido con cliente para puesto estable.<br>· Modalidad de trabajo: 100% remoto.<br>· Horario flexible: L-J 8:00-17:30H, V 8:00-15:00H. Jornada intensiva en verano.<br>· Condiciones económicas: salario competitivo abierto a negociación según experiencia.<br>¿Te sientes identificado/a? No dudes en inscribirte.<br>Referencia<br>EPT048-25<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Gestión de proyectos<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>4 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "3",
            "porcentaje": "85",
            "skills_necesarias": [
                "Snowflake",
                "Big Data",
                "ITIL",
                "CI/CD",
                "DevOps"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer (remoto)",
        "empresa": "Infortec Consultores, S.A.U",
        "fecha_publicacion": "Publicada el 30 de ene (Publicada de nuevo)",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-remoto/of-i42b4004dd64e4a8076aeb520a55aa0?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 3 años\nConocimientos necesarios\nETL\nazure\nmicrosoft fabric\nDescripción\n¿Te apasiona el mundo de los datos y quieres darle un giro a tu carrera este 2025? ¡Este es el momento! En Infortec Consultores, estamos buscando un Data Engineer con al menos 3 años de experiencia en Microsoft Fabric y en la suite de Azure (Data Factory, Dataflow, y demás herramientas del ecosistema) para unirse a nuestro equipo de forma 100% remota.\nLo que buscamos en ti:\nExperiencia sólida en Microsoft Fabric, Data Factory y Dataflow.\nConocimientos en ETL, integración de datos, y modelado de datos.\nProactividad y capacidad para trabajar de manera autónoma (como buen remote worker).\nPasión por la tecnología y ganas de seguir aprendiendo y creciendo con nosotros.\nLo que ofrecemos:\nTrabajo remoto: ¿Por qué salir de casa cuando puedes quedarte en tu rincón favorito con una taza de café?\nDesarrollo profesional: Capacitación continua para que tu 2025 sea aún más exitoso.\nUn equipo increíble: Colaboración con otros cracks de la tecnología en un ambiente dinámico y flexible.\nSi este 2025 quieres dar un salto en tu carrera como Data Engineer y trabajar en proyectos emocionantes con tecnología de vanguardia, ¡esperamos saber de ti!\n¡Estamos listos para arrancar este nuevo año contigo!\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n4 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Conocimientos necesarios<br>ETL<br>azure<br>microsoft fabric<br><br><h3>Descripción</h3><br>¿Te apasiona el mundo de los datos y quieres darle un giro a tu carrera este 2025? ¡Este es el momento! En Infortec Consultores, estamos buscando un Data Engineer con al menos 3 años de experiencia en Microsoft Fabric y en la suite de Azure (Data Factory, Dataflow, y demás herramientas del ecosistema) para unirse a nuestro equipo de forma 100% remota.<br>Lo que buscamos en ti:<br>Experiencia sólida en Microsoft Fabric, Data Factory y Dataflow.<br>Conocimientos en ETL, integración de datos, y modelado de datos.<br>Proactividad y capacidad para trabajar de manera autónoma (como buen remote worker).<br>Pasión por la tecnología y ganas de seguir aprendiendo y creciendo con nosotros.<br>Lo que ofrecemos:<br>Trabajo remoto: ¿Por qué salir de casa cuando puedes quedarte en tu rincón favorito con una taza de café?<br>Desarrollo profesional: Capacitación continua para que tu 2025 sea aún más exitoso.<br>Un equipo increíble: Colaboración con otros cracks de la tecnología en un ambiente dinámico y flexible.<br>Si este 2025 quieres dar un salto en tu carrera como Data Engineer y trabajar en proyectos emocionantes con tecnología de vanguardia, ¡esperamos saber de ti!<br>¡Estamos listos para arrancar este nuevo año contigo!<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>4 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "3",
            "porcentaje": "70",
            "skills_necesarias": [
                "ETL",
                "Azure",
                "Microsoft Office",
                "Data Factory",
                "Dataflow"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Ingeniero de datos junior",
        "empresa": "Quental Technologies",
        "fecha_publicacion": "Publicada el 30 de ene (Publicada de nuevo)",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/ingeniero-datos-junior/of-iec2cb9359840af886853eacbcf7223?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nAl menos 1 año\nImprescindible residente en\nNo Requerido\nConocimientos necesarios\nBig data\nPython\nR\nSQL\nLaboratorio\nAnálisis de datos\nRequisitos mínimos\n¿Qué puedes aportarnos?\nIngeniería Informática, Telecomunicaciones o similar.\nExperiencia de al menos año/año y medio en desarrollo de funcionalidades con lenguajes Python y R para modelos de aprendizaje automático.\nDesarrollo y programación de preparación de datos (grandes volúmenes). Normalización y estructuración.\nExperiencia de al menos 1 año con SQL en aplicación de consultas no complejas.\nDescripción\n¿Eres una persona a la que le gustaría afrontar nuevos retos y buscas seguir desarrollando tu carrera profesional en el mundo de Ciencia del dato?\nEstamos seleccionando para nuestro laboratorio de Ciencia de Datos Ingenieros Informáticos o similar con experiencia en el desarrollo de las soluciones de análisis de datos y big data, participando en las tareas de programación Python y R para el desarrollo de los proyectos de Ciencia de datos (ML, IA DL) con tratamiento de grandes volúmenes de datos / Big Data.\n-Funciones de Programador Python y R con análisis y desarrollo de proyectos dentro del ámbito Data Science participando en la codificación de proyectos de manejo de grandes volúmenes desarrollando los programas para el tratamiento y cálculo de datos y el diseño y desarrollo de modelos de aprendizaje automático e Inteligencia artificial con uso de las librerías más actuales para modelos basados en soluciones de ciencia del dato.\n¿Qué podemos ofrecerte?\nContrato indefinido y plan de retribución flexible con interesantes beneficios sociales &#129534;\n-Conciliación entre la vida personal y profesional, apoyado en un modelo de teletrabajo total.\n-Desarrollo de carrera en un ambiente colaborativo y con bonificaciones a tu formación, para que siempre estés actualizado y a la última en cuanto a tecnología y tendencias en transformación digital.\n-Entorno salarial negociable en función de la experiencia aportada.\n-Inclusión en el programa de beneficios y descuentos, para disfrutar de tus eventos, vacaciones, compras diarias y caprichos, beneficiándote de todos los descuentos que aporta el Quental Club Benefits!\n¿Cómo son nuestros procesos de selección? Es primordial para nosotros mantener la coherencia en la toma de decisiones durante las distintas etapas de esta labor llevada a cabo por nuestro equipo. Nuestros procedimientos son inclusivos, sin sesgos ni prejuicios y buscando el objetivo: colaborar con el mejor talento.\n¡Te esperamos!\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Administración de bases de datos\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nMás de 10.000€\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\n149 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br>Imprescindible residente en<br>No Requerido<br>Conocimientos necesarios<br>Big data<br>Python<br>R<br>SQL<br>Laboratorio<br>Análisis de datos<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>¿Qué puedes aportarnos?<br>Ingeniería Informática, Telecomunicaciones o similar.<br>Experiencia de al menos año/año y medio en desarrollo de funcionalidades con lenguajes Python y R para modelos de aprendizaje automático.<br>Desarrollo y programación de preparación de datos (grandes volúmenes). Normalización y estructuración.<br>Experiencia de al menos 1 año con SQL en aplicación de consultas no complejas.<br><br><h3>Descripción</h3><br>¿Eres una persona a la que le gustaría afrontar nuevos retos y buscas seguir desarrollando tu carrera profesional en el mundo de Ciencia del dato?<br>Estamos seleccionando para nuestro laboratorio de Ciencia de Datos Ingenieros Informáticos o similar con experiencia en el desarrollo de las soluciones de análisis de datos y big data, participando en las tareas de programación Python y R para el desarrollo de los proyectos de Ciencia de datos (ML, IA DL) con tratamiento de grandes volúmenes de datos / Big Data.<br>-Funciones de Programador Python y R con análisis y desarrollo de proyectos dentro del ámbito Data Science participando en la codificación de proyectos de manejo de grandes volúmenes desarrollando los programas para el tratamiento y cálculo de datos y el diseño y desarrollo de modelos de aprendizaje automático e Inteligencia artificial con uso de las librerías más actuales para modelos basados en soluciones de ciencia del dato.<br>¿Qué podemos ofrecerte?<br>Contrato indefinido y plan de retribución flexible con interesantes beneficios sociales &#129534;<br>-Conciliación entre la vida personal y profesional, apoyado en un modelo de teletrabajo total.<br>-Desarrollo de carrera en un ambiente colaborativo y con bonificaciones a tu formación, para que siempre estés actualizado y a la última en cuanto a tecnología y tendencias en transformación digital.<br>-Entorno salarial negociable en función de la experiencia aportada.<br>-Inclusión en el programa de beneficios y descuentos, para disfrutar de tus eventos, vacaciones, compras diarias y caprichos, beneficiándote de todos los descuentos que aporta el Quental Club Benefits!<br>¿Cómo son nuestros procesos de selección? Es primordial para nosotros mantener la coherencia en la toma de decisiones durante las distintas etapas de esta labor llevada a cabo por nuestro equipo. Nuestros procedimientos son inclusivos, sin sesgos ni prejuicios y buscando el objetivo: colaborar con el mejor talento.<br>¡Te esperamos!<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Administración de bases de datos<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Más de 10.000€<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>149 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "1",
            "porcentaje": "75",
            "skills_necesarias": [
                "Big Data",
                "Python",
                "R",
                "SQL",
                "Análisis de datos"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer / Google Cloud / 100% Teletrabajo",
        "empresa": "AARON FORMACIÓN Y CONSULTORÍA",
        "fecha_publicacion": "Publicada el 30 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-google-cloud-100-teletrabajo/of-ida0d53ad6b4e3dae879b8ed6b3114c?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 2 años\nImprescindible residente en\nNo Requerido\nIdiomas requeridos\nInglés - Nivel Intermedio\nConocimientos necesarios\nETL\nSQL\nConstrucción\nPython\nSQL Server\nDescripción\nEstamos contratando: Senior Data Engineer - GCP Cloud\n¿Eres Senior Data Engineer con más de 2 años de experiencia en Google Cloud (GCP)? ¿Te apasiona el desarrollo de pipelines de datos y transformaciones ETL? Te estamos buscando.\n¿Qué buscamos?\n- Experiencia en la construcción de ETL pipelines con BigQuery\n- Buen nivel de SQL y Python\n- Valorable experiencia con SQL Server y Talend para ingestas\n- Conocimientos sólidos de buenas prácticas en ingeniería de datos\nTeletrabajo: Sí\nIdiomas: Inglés B2 mínimo\nSi estás interesado o conoces a alguien que encaje con el perfil, no dudes en aplicar o compartir.\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\nSeguro médico\nCheque restaurante\n7 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Imprescindible residente en<br>No Requerido<br>Idiomas requeridos<br>Inglés - Nivel Intermedio<br>Conocimientos necesarios<br>ETL<br>SQL<br>Construcción<br>Python<br>SQL Server<br><br><h3>Descripción</h3><br>Estamos contratando: Senior Data Engineer - GCP Cloud<br>¿Eres Senior Data Engineer con más de 2 años de experiencia en Google Cloud (GCP)? ¿Te apasiona el desarrollo de pipelines de datos y transformaciones ETL? Te estamos buscando.<br>¿Qué buscamos?<br>- Experiencia en la construcción de ETL pipelines con BigQuery<br>- Buen nivel de SQL y Python<br>- Valorable experiencia con SQL Server y Talend para ingestas<br>- Conocimientos sólidos de buenas prácticas en ingeniería de datos<br>Teletrabajo: Sí<br>Idiomas: Inglés B2 mínimo<br>Si estás interesado o conoces a alguien que encaje con el perfil, no dudes en aplicar o compartir.<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>Seguro médico<br>Cheque restaurante<br>7 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B1",
            "anios_experiencia": "2",
            "porcentaje": "75",
            "skills_necesarias": [
                "ETL",
                "SQL",
                "Python",
                "BigQuery"
            ],
            "skills_valoradas": [
                "Talend"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer",
        "empresa": "Sopra Steria",
        "fecha_publicacion": "Publicada el 29 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer/of-ib19a85a4b242ba94ab43e7d5ba9b1f?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 1 año\nDescripción\n¿Qué reto proponemos?\nNos gustaría incorporar un Data Engieneer para conocido cliente Bancario.\nUbicación: Sevilla, Valencia o Madrid.\nRequisitos:\n1-2 años de experiencia como Data Engineer\nIT TOOLS\n· Good knowledge of\no Spark on Scala; o CI/CD tools (Gitlab, Jenkins...); o HDFS and structured databases (SQL)\n· Full understanding of\no Apache Airflow; o Streaming process (Kafka, event steam...); o S3 storage; o Shell script\n· Some knowledge of: o Kubernetes\n· Optionally/ as a plus: o Elasticsearch and Kibana; o HVault; o Dremio as tool to virtualize data; o Dataiku\n¿Qué tenemos para ti?\nContrato indefinido y jornada completa\n23 días de vacaciones\nFormación continua: competencias técnicas, transversales y de idiomas. Contamos con acceso a certificaciones, formaciones de los principales Partners Tecnológicos, plataformas online y ¡mucho más!\nSeguro de vida y de accidentes\nPosibilidad de acogerte a nuestra retribución flexible (seguro médico, cheques guarderías, transporte, comida y formación)\nAcceso a Privilege Club, donde encontrarás descuentos interesantes en las principales marcas\nOnboarding personalizado y detallado. Te acompañamos en todo momento para que te sientas #soprano desde el primer momento.\nOficina con espacios reservados al ocio. ¡Trabajo y diversión unido!\nCompañerismo y buen ambiente, el poder de la unión lo tenemos presente.\nY lo más importante...Tienes la posibilidad de desarrollar tu carrera profesional con nosotros: Crearemos juntos un plan de carrera personalizado. Te formarás, marcaremos objetivos y llevaremos a cabo un seguimiento para asegurarnos de que lo conseguimos juntos. Escuchamos tus prioridades y luchamos por ellas.\n¡Aquí tu voz importa! ¡Únete a nosotros y sé parte de algo más!\nThe world is how we shape it\nAdquirimos el compromiso de respetar la diversidad, creando un ambiente de trabajo inclusivo y aplicando políticas que favorezcan la inclusión y promuevan el respeto social y cultural en cuestiones de género, edad, funcional, orientación sexual y religión con igualdad de oportunidades.\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n24 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br><br><h3>Descripción</h3><br>¿Qué reto proponemos?<br>Nos gustaría incorporar un Data Engieneer para conocido cliente Bancario.<br>Ubicación: Sevilla, Valencia o Madrid.<br><br><h3>Requisitos</h3>:<br>1-2 años de experiencia como Data Engineer<br>IT TOOLS<br>· Good knowledge of<br>o Spark on Scala; o CI/CD tools (Gitlab, Jenkins...); o HDFS and structured databases (SQL)<br>· Full understanding of<br>o Apache Airflow; o Streaming process (Kafka, event steam...); o S3 storage; o Shell script<br>· Some knowledge of: o Kubernetes<br>· Optionally/ as a plus: o Elasticsearch and Kibana; o HVault; o Dremio as tool to virtualize data; o Dataiku<br>¿Qué tenemos para ti?<br>Contrato indefinido y jornada completa<br>23 días de vacaciones<br>Formación continua: competencias técnicas, transversales y de idiomas. Contamos con acceso a certificaciones, formaciones de los principales Partners Tecnológicos, plataformas online y ¡mucho más!<br>Seguro de vida y de accidentes<br>Posibilidad de acogerte a nuestra retribución flexible (seguro médico, cheques guarderías, transporte, comida y formación)<br>Acceso a Privilege Club, donde encontrarás descuentos interesantes en las principales marcas<br>Onboarding personalizado y detallado. Te acompañamos en todo momento para que te sientas #soprano desde el primer momento.<br>Oficina con espacios reservados al ocio. ¡Trabajo y diversión unido!<br>Compañerismo y buen ambiente, el poder de la unión lo tenemos presente.<br>Y lo más importante...Tienes la posibilidad de desarrollar tu carrera profesional con nosotros: Crearemos juntos un plan de carrera personalizado. Te formarás, marcaremos objetivos y llevaremos a cabo un seguimiento para asegurarnos de que lo conseguimos juntos. Escuchamos tus prioridades y luchamos por ellas.<br>¡Aquí tu voz importa! ¡Únete a nosotros y sé parte de algo más!<br>The world is how we shape it<br>Adquirimos el compromiso de respetar la diversidad, creando un ambiente de trabajo inclusivo y aplicando políticas que favorezcan la inclusión y promuevan el respeto social y cultural en cuestiones de género, edad, funcional, orientación sexual y religión con igualdad de oportunidades.<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>24 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "1",
            "porcentaje": "75",
            "skills_necesarias": [
                "PySpark",
                "Scala",
                "CI/CD",
                "Git",
                "Jenkins",
                "HDFS",
                "SQL",
                "Airflow",
                "Kafka",
                "S3",
                "Shell"
            ],
            "skills_valoradas": [
                "Kubernetes",
                "Elasticsearch",
                "Kibana",
                "HVault",
                "Dremio",
                "Dataiku"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer",
        "empresa": "Capgemini Engineering - Consultores/as",
        "fecha_publicacion": "Publicada el 29 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer/of-i8551f307fa47f2a977ef6cdc6f014b?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nIngeniería Superior\nExperiencia mínima\nAl menos 3 años\nIdiomas requeridos\nInglés - Nivel Avanzado\nConocimientos necesarios\nTableau\nAWS\nSnowflake\nDescripción\nCapgemini Engineering, líder mundial en servicios de ingeniería, reúne equipos de ingenieros/as, científicos/as y arquitectos/as para ayudar a las empresas más innovadoras del mundo a liberar su potencial y contribuir a un futuro mejor. Desde coches autónomos hasta robots que salvan vidas, nuestro/as expertos/as en tecnologías digitales y software se salen de lo convencional proporcionando servicios únicos de I+D e ingeniería en todos los sectores de actividad. ¡Únete al equipo y continua tu carrera en una compañía con oportunidades de crecimiento, donde puedes marcar la diferencia y donde ningún día es igual al anterior!\nTu perfil:\n- Experiencia en Snowflake y arquitecturas de datos en la nube.\n- Conocimientos en AWS (S3, Lambda, Glue, Redshift, etc.).\n- Dominio de herramientas de visualización como Tableau.\n¿Qué te gustará de trabajar aquí?\nTenemos un catálogo de medidas de Desarrollo y Conciliación muy completo, como son, por ejemplo y entre otras:\n· Acompañamiento en tus inicios con el programa de Buddies.\n· 24 días de vacaciones + 2 asuntos propios + 24 y 31 de diciembre + opción a comprar hasta 7 días de vacaciones al año.\n· Formación continua, podrás disfrutar de Mylearning y de Capgemini University y de nuestros Campus Digitales. Tendrás acceso a plataformas como: Coursera, Udemy, Pluralsight, Harvard Manager Mentor, Education First para idiomas (inglés francés, alemán...) ¡entre otras!\n· Comunidad Internacional de DATA & AI, donde podrás colaborar con expertos de todo el mundo.\n· FlexAbroad: posibilidad de trabajar en remoto desde otro país durante 45 días.\n¿Por qué Capgemini?\nCapgemini es líder global en transformar y gestionar los negocios de los clientes aprovechando todo el poder de la tecnología. Nos guía el propósito de lograr un futuro inclusivo y sostenible a través de la tecnología y de la energía de quienes la desarrollamos. Somos una compañía responsable y diversa, líder internacional en servicios de IT e Ingeniería con más de 360.000 profesionales en más de 50 países. Con una sólida herencia de 55 años y una amplia experiencia en la industria, los clientes confían en Capgemini para abordar la totalidad de sus necesidades comerciales, desde la estrategia y el diseño hasta las operaciones, impulsadas por el rápido y novedoso mundo de la nube, los datos, la IA, la conectividad, el software, las plataformas e ingeniería digitales. El Grupo reportó en 2022 ingresos globales de €22 mil millones.\nReescribe tu futuro. ¡Únete al equipo!\nTipo de industria de la oferta\nIngeniería\nCategoría\nInformática y telecomunicaciones - Administración de bases de datos\nNivel\nMando intermedio\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\nSeguro médico\n6 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ingeniería Superior<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br>Conocimientos necesarios<br>Tableau<br>AWS<br>Snowflake<br><br><h3>Descripción</h3><br>Capgemini Engineering, líder mundial en servicios de ingeniería, reúne equipos de ingenieros/as, científicos/as y arquitectos/as para ayudar a las empresas más innovadoras del mundo a liberar su potencial y contribuir a un futuro mejor. Desde coches autónomos hasta robots que salvan vidas, nuestro/as expertos/as en tecnologías digitales y software se salen de lo convencional proporcionando servicios únicos de I+D e ingeniería en todos los sectores de actividad. ¡Únete al equipo y continua tu carrera en una compañía con oportunidades de crecimiento, donde puedes marcar la diferencia y donde ningún día es igual al anterior!<br>Tu perfil:<br>- Experiencia en Snowflake y arquitecturas de datos en la nube.<br>- Conocimientos en AWS (S3, Lambda, Glue, Redshift, etc.).<br>- Dominio de herramientas de visualización como Tableau.<br>¿Qué te gustará de trabajar aquí?<br>Tenemos un catálogo de medidas de Desarrollo y Conciliación muy completo, como son, por ejemplo y entre otras:<br>· Acompañamiento en tus inicios con el programa de Buddies.<br>· 24 días de vacaciones + 2 asuntos propios + 24 y 31 de diciembre + opción a comprar hasta 7 días de vacaciones al año.<br>· Formación continua, podrás disfrutar de Mylearning y de Capgemini University y de nuestros Campus Digitales. Tendrás acceso a plataformas como: Coursera, Udemy, Pluralsight, Harvard Manager Mentor, Education First para idiomas (inglés francés, alemán...) ¡entre otras!<br>· Comunidad Internacional de DATA & AI, donde podrás colaborar con expertos de todo el mundo.<br>· FlexAbroad: posibilidad de trabajar en remoto desde otro país durante 45 días.<br>¿Por qué Capgemini?<br>Capgemini es líder global en transformar y gestionar los negocios de los clientes aprovechando todo el poder de la tecnología. Nos guía el propósito de lograr un futuro inclusivo y sostenible a través de la tecnología y de la energía de quienes la desarrollamos. Somos una compañía responsable y diversa, líder internacional en servicios de IT e Ingeniería con más de 360.000 profesionales en más de 50 países. Con una sólida herencia de 55 años y una amplia experiencia en la industria, los clientes confían en Capgemini para abordar la totalidad de sus necesidades comerciales, desde la estrategia y el diseño hasta las operaciones, impulsadas por el rápido y novedoso mundo de la nube, los datos, la IA, la conectividad, el software, las plataformas e ingeniería digitales. El Grupo reportó en 2022 ingresos globales de €22 mil millones.<br>Reescribe tu futuro. ¡Únete al equipo!<br>Tipo de industria de la oferta<br>Ingeniería<br>Categoría<br>Informática y telecomunicaciones - Administración de bases de datos<br>Nivel<br>Mando intermedio<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>Seguro médico<br>6 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "3",
            "porcentaje": "85",
            "skills_necesarias": [
                "Tableau",
                "AWS",
                "Snowflake"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Responsable de Proyectos de Analítica y Gestión de Datos",
        "empresa": "Soltel",
        "fecha_publicacion": "Publicada el 29 de ene (Publicada de nuevo)",
        "min_salario": "45.000€",
        "max_salario": "54.000€",
        "url_oferta": "https://www.infojobs.net/madrid/responsable-proyectos-analitica-gestion-datos/of-if2c5258f784694b40d053e560108e1?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nIngeniería Superior\nExperiencia mínima\nMás de 5 años\nConocimientos necesarios\nJava\nJSON\nREST\nHL7\nKanban\nGestión de proyectos\nFHIR\nOPENEHR\nRequisitos mínimos\nIngeniería o grado en Informática o disciplinas afines.\nDisponibilidad para viajar puntualmente a Canarias.\nExperiencia amplia en gestión de proyectos de Data complejos.\nExperiencia en metodologías y frameworks ágiles (Scrum, Kanban, Safe...)\nCertificación en gestión de proyectos (PMP)\nAunque no son conocimientos imprescindibles para el desarrollo del puesto, valoramos positivamente\nExperiencia en gestión de proyectos tecnológicos en el ámbito de sanitario.\nConocimiento de estándares sanitarios: HL7, FHIR, OpenEHR.\nConocimientos técnicos de desarrollo (Java, servicios REST, JSON, Angular, Postman).\nDescripción\nAbrimos nueva posición para trabajar como Director/a de proyecto con amplia experiencia en la gestión de proyectos de analítica avanzada de datos, preferiblemente en el ámbito sanitario.\nSe trabajará para el Sistema de Salud de una Comunidad Autónoma, por lo que será necesario realizar viajes puntuales a este territorio.\nUbicaciones: Cualquier ubicación en España, especialmente en aquellas que tengamos sedes como Madrid/Barcelona/Valencia...).\nModalidad de trabajo: Híbrida\nFunciones:\nToma y análisis de requisitos.\nMedición, seguimiento, evaluación y comunicación de progresos.\nAsegurar el cumplimiento de los estándares de calidad y la entrega en tiempo y forma.\nFacilitar el trabajo en equipo y la comunicación constante entre la parte técnico y los stakeholders del proyecto.\nIdentificar y gestionar riesgos y problemas relacionados con el proyecto o el equipo.\n¿Qué ofrecemos?\nContrato indefinido con cliente.\nFlexibilidad horaria\nModalidad híbrida con predominancia de teletrabajo\nSalario acorde a la experiencia y conocimientos aportados\nY mucho mas!!\nTipo de industria de la oferta\nProgramación, Consultoria y otras Activ. informaticas\nCategoría\nInformática y telecomunicaciones - Gestión de proyectos\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario: 45.000€ - 54.000€ Bruto/año\nBeneficios sociales\nTeletrabajo\n8 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ingeniería Superior<br><h4>Experiencia mínima</h4><br>Más de 5 años<br>Conocimientos necesarios<br>Java<br>JSON<br>REST<br>HL7<br>Kanban<br>Gestión de proyectos<br>FHIR<br>OPENEHR<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>Ingeniería o grado en Informática o disciplinas afines.<br>Disponibilidad para viajar puntualmente a Canarias.<br>Experiencia amplia en gestión de proyectos de Data complejos.<br>Experiencia en metodologías y frameworks ágiles (Scrum, Kanban, Safe...)<br>Certificación en gestión de proyectos (PMP)<br>Aunque no son conocimientos imprescindibles para el desarrollo del puesto, valoramos positivamente<br>Experiencia en gestión de proyectos tecnológicos en el ámbito de sanitario.<br>Conocimiento de estándares sanitarios: HL7, FHIR, OpenEHR.<br>Conocimientos técnicos de desarrollo (Java, servicios REST, JSON, Angular, Postman).<br><br><h3>Descripción</h3><br>Abrimos nueva posición para trabajar como Director/a de proyecto con amplia experiencia en la gestión de proyectos de analítica avanzada de datos, preferiblemente en el ámbito sanitario.<br>Se trabajará para el Sistema de Salud de una Comunidad Autónoma, por lo que será necesario realizar viajes puntuales a este territorio.<br>Ubicaciones: Cualquier ubicación en España, especialmente en aquellas que tengamos sedes como Madrid/Barcelona/Valencia...).<br>Modalidad de trabajo: Híbrida<br>Funciones:<br>Toma y análisis de requisitos.<br>Medición, seguimiento, evaluación y comunicación de progresos.<br>Asegurar el cumplimiento de los estándares de calidad y la entrega en tiempo y forma.<br>Facilitar el trabajo en equipo y la comunicación constante entre la parte técnico y los stakeholders del proyecto.<br>Identificar y gestionar riesgos y problemas relacionados con el proyecto o el equipo.<br>¿Qué ofrecemos?<br>Contrato indefinido con cliente.<br>Flexibilidad horaria<br>Modalidad híbrida con predominancia de teletrabajo<br>Salario acorde a la experiencia y conocimientos aportados<br>Y mucho mas!!<br>Tipo de industria de la oferta<br>Programación, Consultoria y otras Activ. informaticas<br>Categoría<br>Informática y telecomunicaciones - Gestión de proyectos<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario: 45.000€ - 54.000€ Bruto/año<br>Beneficios sociales<br>Teletrabajo<br>8 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "5",
            "porcentaje": "50",
            "skills_necesarias": [
                "Java",
                "JSON",
                "REST",
                "HL7",
                "Kanban",
                "FHIR",
                "OPENEHR"
            ],
            "skills_valoradas": [
                "Angular",
                "Postman"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data engineer Python y Scala.",
        "empresa": "Grupo ICA",
        "fecha_publicacion": "Publicada el 27 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-python-scala./of-i007edae67149d69935e70902dda93a?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 3 años\nConocimientos necesarios\nPython\nJenkins\nControl-M\nSQL\nSCALA\nSVN\nHadoop\nspark\nDescripción\nDesde ICA Informática y Comunicaciones Avanzadas nos encontramos en búsqueda de un Ingeniero/a Datos.\nFunciones:\nLenguajes de desarrollo: Scala y Python.\nBases de datos: lenguaje SQL para consultar bases de datos distribuidas (Impala).\nProcesamiento: procesos distribuidos sobre Spark con lenguaje Scala y con lenguaje Python usando la librería PySpark. Es importante conocer Spark y el paradigma map-reduce. También procesado tradicional mediante programas Python.\nCoordinación de los procesos mediante scripts bash ejecutados en servidores con sistema operativo Linux.\nSe utiliza Cloudera, una distribución privada de servicios Big Data.\nHerramientas del entorno de desarrollo: editor de código Visual Studio Code, repositorio de código fuente SVN, integración continua con Jenkins, calidad de código con Sonar y planificación de procesos con Control-M.\nGestión de proyectos y tareas: Redmine.\nPuesto de trabajo: Windows.\nOfrecemos:\n-Proyección profesional.\n-Horario: oficina.\n-Salario competitivo\n-Plan de Formación\n-Plan de Retribución flexible\n-Plan de Conciliación\n¿Quiénes Somos?\nI.C.A Informática y Comunicaciones Avanzadas S.L. somos una empresa líder en consultoría tecnológica con sede en Madrid y con una trayectoria de más de 40 años en el sector. Desde nuestra fundación en 1983, hemos evolucionado constantemente para ofrecer soluciones innovadoras y servicios de alta calidad en el ámbito de la tecnología.\nContamos con un equipo de más de 250 profesionales altamente capacitados y especializados en el desarrollo de software y la implementación de sistemas avanzados, brindando soluciones personalizadas a clientes de diversos sectores.\nEn I.C.A estamos comprometidos con la responsabilidad empresarial, y nos enorgullece haber obtenido la certificación como Empresa Familiarmente Responsable. Esta distinción refleja nuestro compromiso con el bienestar de nuestros empleados, promoviendo un equilibrio armonioso entre la vida laboral, personal y familiar.\n¡Únete a nuestro equipo!\nTipo de industria de la oferta\nProgramación, Consultoria y otras Activ. informaticas\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n20 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Conocimientos necesarios<br>Python<br>Jenkins<br>Control-M<br>SQL<br>SCALA<br>SVN<br>Hadoop<br>spark<br><br><h3>Descripción</h3><br>Desde ICA Informática y Comunicaciones Avanzadas nos encontramos en búsqueda de un Ingeniero/a Datos.<br>Funciones:<br>Lenguajes de desarrollo: Scala y Python.<br>Bases de datos: lenguaje SQL para consultar bases de datos distribuidas (Impala).<br>Procesamiento: procesos distribuidos sobre Spark con lenguaje Scala y con lenguaje Python usando la librería PySpark. Es importante conocer Spark y el paradigma map-reduce. También procesado tradicional mediante programas Python.<br>Coordinación de los procesos mediante scripts bash ejecutados en servidores con sistema operativo Linux.<br>Se utiliza Cloudera, una distribución privada de servicios Big Data.<br>Herramientas del entorno de desarrollo: editor de código Visual Studio Code, repositorio de código fuente SVN, integración continua con Jenkins, calidad de código con Sonar y planificación de procesos con Control-M.<br>Gestión de proyectos y tareas: Redmine.<br>Puesto de trabajo: Windows.<br>Ofrecemos:<br>-Proyección profesional.<br>-Horario: oficina.<br>-Salario competitivo<br>-Plan de Formación<br>-Plan de Retribución flexible<br>-Plan de Conciliación<br>¿Quiénes Somos?<br>I.C.A Informática y Comunicaciones Avanzadas S.L. somos una empresa líder en consultoría tecnológica con sede en Madrid y con una trayectoria de más de 40 años en el sector. Desde nuestra fundación en 1983, hemos evolucionado constantemente para ofrecer soluciones innovadoras y servicios de alta calidad en el ámbito de la tecnología.<br>Contamos con un equipo de más de 250 profesionales altamente capacitados y especializados en el desarrollo de software y la implementación de sistemas avanzados, brindando soluciones personalizadas a clientes de diversos sectores.<br>En I.C.A estamos comprometidos con la responsabilidad empresarial, y nos enorgullece haber obtenido la certificación como Empresa Familiarmente Responsable. Esta distinción refleja nuestro compromiso con el bienestar de nuestros empleados, promoviendo un equilibrio armonioso entre la vida laboral, personal y familiar.<br>¡Únete a nuestro equipo!<br>Tipo de industria de la oferta<br>Programación, Consultoria y otras Activ. informaticas<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>20 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "3",
            "porcentaje": "85",
            "skills_necesarias": [
                "Python",
                "Jenkins",
                "Control-M",
                "SQL",
                "Scala",
                "SVN",
                "Hadoop",
                "PySpark"
            ],
            "skills_valoradas": [
                "PySpark",
                "Bash",
                "Cloudera",
                "Visual Studio Code",
                "Sonar",
                "Redmine"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Visualization Engineer",
        "empresa": "INETUM Centro",
        "fecha_publicacion": "Publicada el 27 de ene (Publicada de nuevo)",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-visualization-engineer/of-if0095c078246448261f06ed0ee8b24?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Medio\nExperiencia mínima\nAl menos 2 años\nConocimientos necesarios\nSAP Business Objects\nPower BI\nSnowflake\nDescripción\nABOUT INETUM\nWe are a digital, international, and agile consulting firm. In the era of post-digital transformation, we strive to ensure that each of our 28,000 professionals can continuously renew themselves, positively experiencing their own digital flow.\nEach of them can design their career path according to their preferences, partner with clients to practically build a more positive world, innovate in each of the 27 countries, and balance their professional career with their personal well-being.\nOur 28,000 digital athletes are proud to have been certified as a Top Employer Europe 2024\nABOUT THE ROLE:\nAre you a data enthusiast with a passion for data Visualization? In this key role, you'll be a crucial part of our data squads, responsible for developing and maintaining Power BI and SAP Business Objects reports.\nMANDATORY:\nProficiency in SAP Business Objects and Control-M.\nExperience with Power BI for report development and data visualization.\nFamiliarity with Snowflake for advanced reporting integration.\nExperience with Azure DataFactory.\nFluent in English (C1 or higher) to effectively collaborate with business users and stakeholders.\nPREFERRED:\nExperience with ITSM methodologies.\nA strong growth mindset to quickly adapt to new technologies.\nIMPORTANT: Remote work, provided you have a work and residency permit and are based in Spain.\nJoin us!\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n7 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Medio<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Conocimientos necesarios<br>SAP Business Objects<br>Power BI<br>Snowflake<br><br><h3>Descripción</h3><br>ABOUT INETUM<br>We are a digital, international, and agile consulting firm. In the era of post-digital transformation, we strive to ensure that each of our 28,000 professionals can continuously renew themselves, positively experiencing their own digital flow.<br>Each of them can design their career path according to their preferences, partner with clients to practically build a more positive world, innovate in each of the 27 countries, and balance their professional career with their personal well-being.<br>Our 28,000 digital athletes are proud to have been certified as a Top Employer Europe 2024<br>ABOUT THE ROLE:<br>Are you a data enthusiast with a passion for data Visualization? In this key role, you'll be a crucial part of our data squads, responsible for developing and maintaining Power BI and SAP Business Objects reports.<br>MANDATORY:<br>Proficiency in SAP Business Objects and Control-M.<br>Experience with Power BI for report development and data visualization.<br>Familiarity with Snowflake for advanced reporting integration.<br>Experience with Azure DataFactory.<br>Fluent in English (C1 or higher) to effectively collaborate with business users and stakeholders.<br>PREFERRED:<br>Experience with ITSM methodologies.<br>A strong growth mindset to quickly adapt to new technologies.<br>IMPORTANT: Remote work, provided you have a work and residency permit and are based in Spain.<br>Join us!<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>7 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "2",
            "porcentaje": "80",
            "skills_necesarias": [
                "SAP",
                "Power BI",
                "Snowflake",
                "Azure"
            ],
            "skills_valoradas": [
                "ITSM methodologies"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Feed Engineer",
        "empresa": "INETUM Centro",
        "fecha_publicacion": "Publicada el 27 de ene (Publicada de nuevo)",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-feed-engineer/of-icec869cb9948c8bd6594552feafd02?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Medio\nExperiencia mínima\nAl menos 3 años\nConocimientos necesarios\nSnowflake\nAzure Data Factory\nControl-M\nManaged File Transfer\nApplication Programming Interfaces\nSQL Server\nDB2\nDescripción\nABOUT INETUM:\nWe are a digital, international, and agile consulting firm. In the era of post-digital transformation, we strive to ensure that each of our 28,000 professionals can continuously renew themselves, positively experiencing their own digital flow. Each of them can design their career path according to their preferences, partner with clients to practically build a more positive world, innovate in each of the 27 countries, and balance their professional career with their personal well-being. Our 28,000 digital athletes are proud to have been certified as a Top Employer Europe 2024\nABOUT THE ROLE:\nAre you a data enthusiast with a passion for big data and data engineering? In this key role, you'll be a crucial part of our data squads, responsible for developing and maintaining new big data platforms and data products.\nYOUR MISSION?: To build data pipelines that ingest, transform, and prepare data from various sources into our datahub platform and data products.\nSKILLS:\n* 2 - 4 years of experience. Prior experience in ITSM or Data Engineer roles i.e. ETL developer, API developer\n* Prior experience working with both modern and legacy tech stack\n* Modern:\n-Snowflake (required)\n-Azure Data Factory (preferred)\n-Control-M (preferred)\n-Managed File Transfer (preferred)\n-Application Programming Interfaces (required)\n*Legacy:\n-SQL Server (preferred)\n-IBM DB2 (preferred)\n*Prior experience working with relevant programming languages including SQL, Python\n*Intermediate English proficiency\nIMPORTANT: Remote work, provided you have a work and residency permit and are based in Spain.\nJoin us!\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n6 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Medio<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Conocimientos necesarios<br>Snowflake<br>Azure Data Factory<br>Control-M<br>Managed File Transfer<br>Application Programming Interfaces<br>SQL Server<br>DB2<br><br><h3>Descripción</h3><br>ABOUT INETUM:<br>We are a digital, international, and agile consulting firm. In the era of post-digital transformation, we strive to ensure that each of our 28,000 professionals can continuously renew themselves, positively experiencing their own digital flow. Each of them can design their career path according to their preferences, partner with clients to practically build a more positive world, innovate in each of the 27 countries, and balance their professional career with their personal well-being. Our 28,000 digital athletes are proud to have been certified as a Top Employer Europe 2024<br>ABOUT THE ROLE:<br>Are you a data enthusiast with a passion for big data and data engineering? In this key role, you'll be a crucial part of our data squads, responsible for developing and maintaining new big data platforms and data products.<br>YOUR MISSION?: To build data pipelines that ingest, transform, and prepare data from various sources into our datahub platform and data products.<br>SKILLS:<br>* 2 - 4 years of experience. Prior experience in ITSM or Data Engineer roles i.e. ETL developer, API developer<br>* Prior experience working with both modern and legacy tech stack<br>* Modern:<br>-Snowflake (required)<br>-Azure Data Factory (preferred)<br>-Control-M (preferred)<br>-Managed File Transfer (preferred)<br>-Application Programming Interfaces (required)<br>*Legacy:<br>-SQL Server (preferred)<br>-IBM DB2 (preferred)<br>*Prior experience working with relevant programming languages including SQL, Python<br>*Intermediate English proficiency<br>IMPORTANT: Remote work, provided you have a work and residency permit and are based in Spain.<br>Join us!<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>6 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B1",
            "anios_experiencia": "3",
            "porcentaje": "75",
            "skills_necesarias": [
                "Snowflake",
                "Application Programming Interfaces",
                "SQL",
                "Python"
            ],
            "skills_valoradas": [
                "Azure",
                "Control-M",
                "Managed File Transfer",
                "SQL",
                "DB2"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Ingeniero/a de Datos. TELETRABAJO 100%. (10524)",
        "empresa": "novanotio",
        "fecha_publicacion": "Publicada el 23 de ene",
        "min_salario": "40.000€",
        "max_salario": "46.000€",
        "url_oferta": "https://www.infojobs.net/madrid/ingeniero-datos.-teletrabajo-100-.-10524/of-ia3e3e6b5dc4c6f846e5e0c4681675b?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nIngeniería Superior - Ingeniero en Informática\nExperiencia mínima\nAl menos 2 años\nImprescindible residente en\nEspaña\nIdiomas requeridos\nInglés - Nivel Avanzado\nConocimientos necesarios\nPython\nBases de datos\nC++\nClearCase\nGit\nETL\nLinux\nAnálisis de datos\nBig data\nModelado de datos\nRequisitos mínimos\n-Cloud u Open Source.\n-PowerBI\n-Python: Avanzado\n-C++: Medio\n-ClearCase: Medio\n-Git: Medio\n-Linux: Medio\nDescripción\n¡Hola, profesionales de la tecnología!\nSomos NOVANOTIO, una consultora de RRHH con más de 28 años de experiencia especializada en la selección de perfiles tecnológicos IT para los mejores clientes del sector tecnológico.\n¿Aún no nos conoces? Visita nuestra página web para conocernos y ver nuestras ofertas de empleo: https://novanotio.es/ofertas/ También puedes seguirnos en LinkedIn para estar informado de todas nuestras novedades.\nEn NOVANOTIO estamos seleccionando un INGENIERO/A DE DATOS con al menos 2 años.\nFORMACION: Grado en Ingeniería Informática/Telecomunicaciones, Programación, Matemáticas, Estadística + Máster Data Science, Big Data o en un campo relacionado.\nHERRAMIENTAS MINIMAS:\n-Python: Avanzado\n-C++: Medio\n-ClearCase: Medio\n-Git: Medio\n-Linux: Medio\nRESPONSABILIDADES EN PROYECTO:\n-Participación en el proceso de diseño y creación de pipelines con herramientas Cloud u Open Source.\n-Programación en Python: conocimiento de programación Orientada a Objetos, diseño y creación de transformaciones de datos, optimización flujos, análisis de datos.\n-Modelado de Datos: physical data modelling y logical data modelling Migración de tecnología de ETL a stack Cloud u Open Source Hard Skills\n-Imprescindible tener experiencia en: Linux y bash scripting.\n-Destreza con bases de datos relacionales y no relacionales.\n-Analítica de datos usando Python Analítica de datos usando herramientas de Business Intelligence como Power BI.\nDESEABLE:\n-Control y conocimiento para el almacenamiento eficiente de grandes volúmenes de datos.\n-Experiencia en optimización de sistemas de procesamiento.\n-Experiencia con herramientas de procesamiento como Spark o Kafka.\n-Manejo con herramientas de orquestación como Airflow o similares.\n- Conocimiento de arquitecturas cloud como Azure o AWS.\n¿QUÉ OFRECEMOS?\n- Contrato INDEFINIDO.\n- SALARIO A NEGOCIAR en función de experiencia y formación.\n-¿TIENES VACACIONES PROGRAMADAS? No te preocupes, te las respetamos.\n- Posibilidad de RETRIBUCIÓN FLEXIBLE (seguro médico, cheque guardería, tarjeta transporte, tickets restaurante)\n- FORMACIÓN ADAPTADA a tu puesto e intereses personales y profesionales.\n- MENTORING de liderazgo tecnológico. NOVANOTIO CERTIFIED es un mapa del mundo de la tecnología y una brújula personal. Te permitirá orientar tu carrera, crecer con tus éxitos y aprender de tus errores.\nReferencia\n10524(MA)\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Administración de bases de datos\nNivel\nEmpleado/a\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario: 40.000€ - 46.000€ Bruto/año\nBeneficios sociales\nTeletrabajo\n103 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ingeniería Superior - Ingeniero en Informática<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Imprescindible residente en<br>España<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br>Conocimientos necesarios<br>Python<br>Bases de datos<br>C++<br>ClearCase<br>Git<br>ETL<br>Linux<br>Análisis de datos<br>Big data<br>Modelado de datos<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Cloud u Open Source.<br>-PowerBI<br>-Python: Avanzado<br>-C++: Medio<br>-ClearCase: Medio<br>-Git: Medio<br>-Linux: Medio<br><br><h3>Descripción</h3><br>¡Hola, profesionales de la tecnología!<br>Somos NOVANOTIO, una consultora de RRHH con más de 28 años de experiencia especializada en la selección de perfiles tecnológicos IT para los mejores clientes del sector tecnológico.<br>¿Aún no nos conoces? Visita nuestra página web para conocernos y ver nuestras ofertas de empleo: https://novanotio.es/ofertas/ También puedes seguirnos en LinkedIn para estar informado de todas nuestras novedades.<br>En NOVANOTIO estamos seleccionando un INGENIERO/A DE DATOS con al menos 2 años.<br>FORMACION: Grado en Ingeniería Informática/Telecomunicaciones, Programación, Matemáticas, Estadística + Máster Data Science, Big Data o en un campo relacionado.<br>HERRAMIENTAS MINIMAS:<br>-Python: Avanzado<br>-C++: Medio<br>-ClearCase: Medio<br>-Git: Medio<br>-Linux: Medio<br>RESPONSABILIDADES EN PROYECTO:<br>-Participación en el proceso de diseño y creación de pipelines con herramientas Cloud u Open Source.<br>-Programación en Python: conocimiento de programación Orientada a Objetos, diseño y creación de transformaciones de datos, optimización flujos, análisis de datos.<br>-Modelado de Datos: physical data modelling y logical data modelling Migración de tecnología de ETL a stack Cloud u Open Source Hard Skills<br>-Imprescindible tener experiencia en: Linux y bash scripting.<br>-Destreza con bases de datos relacionales y no relacionales.<br>-Analítica de datos usando Python Analítica de datos usando herramientas de Business Intelligence como Power BI.<br>DESEABLE:<br>-Control y conocimiento para el almacenamiento eficiente de grandes volúmenes de datos.<br>-Experiencia en optimización de sistemas de procesamiento.<br>-Experiencia con herramientas de procesamiento como Spark o Kafka.<br>-Manejo con herramientas de orquestación como Airflow o similares.<br>- Conocimiento de arquitecturas cloud como Azure o AWS.<br>¿QUÉ OFRECEMOS?<br>- Contrato INDEFINIDO.<br>- SALARIO A NEGOCIAR en función de experiencia y formación.<br>-¿TIENES VACACIONES PROGRAMADAS? No te preocupes, te las respetamos.<br>- Posibilidad de RETRIBUCIÓN FLEXIBLE (seguro médico, cheque guardería, tarjeta transporte, tickets restaurante)<br>- FORMACIÓN ADAPTADA a tu puesto e intereses personales y profesionales.<br>- MENTORING de liderazgo tecnológico. NOVANOTIO CERTIFIED es un mapa del mundo de la tecnología y una brújula personal. Te permitirá orientar tu carrera, crecer con tus éxitos y aprender de tus errores.<br>Referencia<br>10524(MA)<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Administración de bases de datos<br>Nivel<br>Empleado/a<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario: 40.000€ - 46.000€ Bruto/año<br>Beneficios sociales<br>Teletrabajo<br>103 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "2",
            "porcentaje": "85",
            "skills_necesarias": [
                "Python",
                "C++",
                "ClearCase",
                "Git",
                "Linux",
                "ETL",
                "Power BI",
                "Análisis de datos"
            ],
            "skills_valoradas": [
                "Cloud",
                "Big Data",
                "PySpark",
                "Kafka",
                "Airflow",
                "Azure",
                "AWS"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer (Híbrido Madrid)",
        "empresa": "Sopra Steria",
        "fecha_publicacion": "Publicada el 23 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-hibrido-madrid/of-i98532c7c7143f69bc79263db129532?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 4 años\nConocimientos necesarios\nControl de Calidad\nAnálisis\nInteligencia artificial\nETL Extract/Transform/Load\nModelado de datos\nRequisitos mínimos\n¿Qué buscamos?\nExperiencia de al menos 4 años en funciones de análisis y gestión de grandes volúmenes de datos.\nExperiencia en ETL y modelado de datos\nValorable interés o experiencia previa en Inteligencia Artificial (AI)\nPreferiblemente experiencia en cloud Azure\nDescripción\n¿Qué reto proponemos?\nNos gustaría incorporar a nuestro equipo a 3 Data Engineer con mínimo 4 años de experiencia, para colaborar en un importante proyecto dentro del área de Data, Analytics & AI de uno de nuestros clientes. Las funciones del puesto serían:\nDiseñar y gestionar la infraestructura tecnológica necesaria para almacenar, procesar y analizar grandes volúmenes de datos. Esto implica trabajar con sistemas de almacenamiento, bases de datos, herramientas de procesamiento distribuido y tecnologías de la nube.\nSupervisar el desarrollo de pipelines de datos eficientes y escalables.\nAsegurar que los datos utilizados en la organización sean precisos, confiables y estén disponibles en el formato adecuado. Esto implica aplicar técnicas de validación y saneamiento de datos, así como establecer políticas y procedimientos para el control de calidad de los datos.\nColaborar estrechamente con equipos de análisis y ciencia de datos para entender sus necesidades y proporcionarles los datos y la infraestructura adecuados.\nGarantizar la seguridad de los datos y cumplir con las regulaciones y políticas de privacidad aplicables. Esto implica implementar medidas de seguridad adecuadas, como cifrado de datos y control de acceso, y asegurarse de que los datos se utilicen de acuerdo con la regulación pertinente.\nHorario: de lunes a jueves de 8:00h a 17:30h y viernes de 08:00h a 14:00h\nModelo de trabajo híbrido en oficinas de cliente - 3 días presenciales y 2 de teletrabajo\nUbicación Madrid, zona Delicias\n¿Qué tenemos para ti?\nContrato indefinido y jornada completa\n- 23 días de vacaciones\n- Formación continua: competencias técnicas, transversales y de idiomas. Contamos con acceso a certificaciones, formaciones de los principales Partners Tecnológicos, plataformas online y ¡mucho más!\n- Seguro de vida y de accidentes\n- Posibilidad de acogerte a nuestra retribución flexible (seguro médico, cheques guarderías, transporte, comida y formación)\n- Acceso a Privilege Club, donde encontrarás descuentos interesantes en las principales marcas\n- Onboarding personalizado y detallado. Te acompañamos en todo momento para que te sientas #soprano desde el primer momento.\n- Oficina con espacios reservados al ocio. ¡Trabajo y diversión unido!\n- Compañerismo y buen ambiente, el poder de la unión lo tenemos presente.\nY lo más importante...Tienes la posibilidad de desarrollar tu carrera profesional con nosotros: Crearemos juntos un plan de carrera personalizado. Te formarás, marcaremos objetivos y llevaremos a cabo un seguimiento para asegurarnos de que lo conseguimos juntos. Escuchamos tus prioridades y luchamos por ellas.\n¡Aquí tu voz importa! ¡Únete a nosotros y sé parte de algo más!\nThe world is how we shape it\nAdquirimos el compromiso de respetar la diversidad, creando un ambiente de trabajo inclusivo y aplicando políticas que favorezcan la inclusión y promuevan el respeto social y cultural en cuestiones de género, edad, funcional, orientación sexual y religión con igualdad de oportunidades.\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\nCheque restaurante\n23 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 4 años<br>Conocimientos necesarios<br>Control de Calidad<br>Análisis<br>Inteligencia artificial<br>ETL Extract/Transform/Load<br>Modelado de datos<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>¿Qué buscamos?<br>Experiencia de al menos 4 años en funciones de análisis y gestión de grandes volúmenes de datos.<br>Experiencia en ETL y modelado de datos<br>Valorable interés o experiencia previa en Inteligencia Artificial (AI)<br>Preferiblemente experiencia en cloud Azure<br><br><h3>Descripción</h3><br>¿Qué reto proponemos?<br>Nos gustaría incorporar a nuestro equipo a 3 Data Engineer con mínimo 4 años de experiencia, para colaborar en un importante proyecto dentro del área de Data, Analytics & AI de uno de nuestros clientes. Las funciones del puesto serían:<br>Diseñar y gestionar la infraestructura tecnológica necesaria para almacenar, procesar y analizar grandes volúmenes de datos. Esto implica trabajar con sistemas de almacenamiento, bases de datos, herramientas de procesamiento distribuido y tecnologías de la nube.<br>Supervisar el desarrollo de pipelines de datos eficientes y escalables.<br>Asegurar que los datos utilizados en la organización sean precisos, confiables y estén disponibles en el formato adecuado. Esto implica aplicar técnicas de validación y saneamiento de datos, así como establecer políticas y procedimientos para el control de calidad de los datos.<br>Colaborar estrechamente con equipos de análisis y ciencia de datos para entender sus necesidades y proporcionarles los datos y la infraestructura adecuados.<br>Garantizar la seguridad de los datos y cumplir con las regulaciones y políticas de privacidad aplicables. Esto implica implementar medidas de seguridad adecuadas, como cifrado de datos y control de acceso, y asegurarse de que los datos se utilicen de acuerdo con la regulación pertinente.<br>Horario: de lunes a jueves de 8:00h a 17:30h y viernes de 08:00h a 14:00h<br>Modelo de trabajo híbrido en oficinas de cliente - 3 días presenciales y 2 de teletrabajo<br>Ubicación Madrid, zona Delicias<br>¿Qué tenemos para ti?<br>Contrato indefinido y jornada completa<br>- 23 días de vacaciones<br>- Formación continua: competencias técnicas, transversales y de idiomas. Contamos con acceso a certificaciones, formaciones de los principales Partners Tecnológicos, plataformas online y ¡mucho más!<br>- Seguro de vida y de accidentes<br>- Posibilidad de acogerte a nuestra retribución flexible (seguro médico, cheques guarderías, transporte, comida y formación)<br>- Acceso a Privilege Club, donde encontrarás descuentos interesantes en las principales marcas<br>- Onboarding personalizado y detallado. Te acompañamos en todo momento para que te sientas #soprano desde el primer momento.<br>- Oficina con espacios reservados al ocio. ¡Trabajo y diversión unido!<br>- Compañerismo y buen ambiente, el poder de la unión lo tenemos presente.<br>Y lo más importante...Tienes la posibilidad de desarrollar tu carrera profesional con nosotros: Crearemos juntos un plan de carrera personalizado. Te formarás, marcaremos objetivos y llevaremos a cabo un seguimiento para asegurarnos de que lo conseguimos juntos. Escuchamos tus prioridades y luchamos por ellas.<br>¡Aquí tu voz importa! ¡Únete a nosotros y sé parte de algo más!<br>The world is how we shape it<br>Adquirimos el compromiso de respetar la diversidad, creando un ambiente de trabajo inclusivo y aplicando políticas que favorezcan la inclusión y promuevan el respeto social y cultural en cuestiones de género, edad, funcional, orientación sexual y religión con igualdad de oportunidades.<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>Cheque restaurante<br>23 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "4",
            "porcentaje": "80",
            "skills_necesarias": [
                "Control de Calidad",
                "Análisis de datos",
                "ETL"
            ],
            "skills_valoradas": [
                "IA",
                "Azure"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "ANALISTA DE DATOS / DATA ENGINEER",
        "empresa": "ColaVoro",
        "fecha_publicacion": "Publicada el 22 de ene (Publicada de nuevo)",
        "min_salario": "40.000€",
        "max_salario": "48.000€",
        "url_oferta": "https://www.infojobs.net/madrid/analista-datos-data-engineer/of-ic79f8806f4483a9b27ae4dd71415c6?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nAl menos 2 años\nConocimientos necesarios\nPython\nAnálisis de datos\nRequisitos mínimos\n-Experiencia en Linux y Bash Scripting\n- Experiencia en procesamiento de datos con Python\n- Experiencia en diseño de modelo de datos\n- Destreza con bases de datos relacionales y no relacionales\n- Experiencia en analítica de datos usando Python\n- Experiencia en analítica de datos usando herramientas de Business Intelligence como Power BI\n- Nivel avanzado de Python\n- Nivel medio de C++. ClearCase, Git y Linux\n- Nivel medio - alto de inglés\nDeseable:\n- Control y conocimientos para el almacenamiento eficiente de grandes volúmenes de datos\n- Experiencia en optimización de sistemas de procesamiento\n- Experiencia con herramientas de procesamiento como Spark o Kafka\n- Manejo con herramientas de orquestación como Airflow o similares\n- Conocimientos de arquitecturas Cloud como Azure o AWS\nDescripción\nPrecisamos Analista de Datos para incorporarse en uno de nuestros clientes. Trabajo 100% remoto.\nFunciones:\n- Participación en el proceso de diseño y creación de pipelines con herramientas Cloud u Open Source.\n- Programación en Python: conocimientos de programación orientada a objetos, diseño y creación de transformaciones de datos, optimización de flujos y análisis de datos.\n- Modelado de datos: physical data modelling y logical data modelling.\n- Migración de tecnología de ETL a stack Cloud y Open Source Hard.\nSe Ofrece:\n- Puesto estable (contrato indefinido a través de Colavoro)\n- Jornada completa, de Lunes a Viernes\n- Trabajo 100% remoto\n- Salario acorde a la formación y experiencia aportada\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEspecialista\nNúmero de vacantes\n1\nSalario\nSalario: 40.000€ - 48.000€ Bruto/año\nBeneficios sociales\nTeletrabajo\n64 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Conocimientos necesarios<br>Python<br>Análisis de datos<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Experiencia en Linux y Bash Scripting<br>- Experiencia en procesamiento de datos con Python<br>- Experiencia en diseño de modelo de datos<br>- Destreza con bases de datos relacionales y no relacionales<br>- Experiencia en analítica de datos usando Python<br>- Experiencia en analítica de datos usando herramientas de Business Intelligence como Power BI<br>- Nivel avanzado de Python<br>- Nivel medio de C++. ClearCase, Git y Linux<br>- Nivel medio - alto de inglés<br>Deseable:<br>- Control y conocimientos para el almacenamiento eficiente de grandes volúmenes de datos<br>- Experiencia en optimización de sistemas de procesamiento<br>- Experiencia con herramientas de procesamiento como Spark o Kafka<br>- Manejo con herramientas de orquestación como Airflow o similares<br>- Conocimientos de arquitecturas Cloud como Azure o AWS<br><br><h3>Descripción</h3><br>Precisamos Analista de Datos para incorporarse en uno de nuestros clientes. Trabajo 100% remoto.<br>Funciones:<br>- Participación en el proceso de diseño y creación de pipelines con herramientas Cloud u Open Source.<br>- Programación en Python: conocimientos de programación orientada a objetos, diseño y creación de transformaciones de datos, optimización de flujos y análisis de datos.<br>- Modelado de datos: physical data modelling y logical data modelling.<br>- Migración de tecnología de ETL a stack Cloud y Open Source Hard.<br>Se Ofrece:<br>- Puesto estable (contrato indefinido a través de Colavoro)<br>- Jornada completa, de Lunes a Viernes<br>- Trabajo 100% remoto<br>- Salario acorde a la formación y experiencia aportada<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Especialista<br>Número de vacantes<br>1<br>Salario<br>Salario: 40.000€ - 48.000€ Bruto/año<br>Beneficios sociales<br>Teletrabajo<br>64 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B2",
            "anios_experiencia": "2",
            "porcentaje": "80",
            "skills_necesarias": [
                "Python",
                "Linux",
                "Bash",
                "SQL",
                "NoSQL",
                "Analítica de datos",
                "Power BI"
            ],
            "skills_valoradas": [
                "C++",
                "ClearCase",
                "Git",
                "PySpark",
                "Kafka",
                "Airflow",
                "Azure",
                "AWS"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer",
        "empresa": "MAHOU SAN MIGUEL",
        "fecha_publicacion": "Publicada el 22 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer/of-i6e6a2045fb4175944c92dec20f2638?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nAl menos 2 años\nDescripción\n\nSobre nosotros\nSomos una compañía familiar, líder de bebidas en España. Contamos con 10 centros de elaboración de cerveza –ocho en España y dos en Estados Unidos–, cuatro manantiales de agua y un equipo cercano a los 4.000 profesionales. Estamos presentes en más de 70 países.\nNuestro compromiso con el empleo de calidad y el bienestar de las personas, nuestros valores, nuestro propósito y nuestro espíritu innovador y transformador, desde hace más de 130 años, definen una forma única de hacer las cosas que nos permite avanzar hacia el futuro.\n\n¿Por qué te estamos buscando?\nTu misión será desarrollar e integrar diferentes fuentes de datos creando nuevos modelos de datos y evolucionando la arquitectura tecnológica actual para garantizar la consistencia, integridad y calidad de los datos.\nTu día a día en Mahou San Miguel\n- Diseñar, definir y desarrollar los procesos de tratamiento e integración de datos asegurando la consistencia, completitud y calidad de los mismos.\n- Evolucionar los procesos e infraestructura actuales para una óptima extracción, transformación y carga de datos.\n- Estructurar y consolidar datos de diferentes fuentes para su explotación.\n- Establecer los procesos de limpieza, validación y calidad de datos necesarios para desarrollar diferentes modelos de datos.\n- Definir y desarrollar nuevos modelos de datos que permitan la explotación de la información a diferentes niveles.\n- Desarrollar proyectos relacionados de evolución de tecnológica de casos de uso actuales y futuros dentro del área de Delivery, principalmente enfocados a procesos financieros y operacionales.\n- Trabajar coordinadamente en el equipo de Delivery de EPM y Finanzas, junto Data & Analytics para asegurar el entendimiento y aplicación de los estándares de gobierno y calidad de datos en los proyectos.\n¿Qué requisitos debes cumplir?\n- Grado / Máster / Licenciatura Informática, Ciencias de la Computación o carreras afines.\n- Nivel alto de inglés\n- Al menos 4 años de experiencia en funciones de tratamiento e integración de datos. Se valorará positivamente experiencia en consultoría.\n- Experiencia con lenguajes SQL, herramientas ETL y modelado de datos.\n- Experiencia en entornos Big Data (Spark, Hadoop, Cassandra).\n- Conocimiento de infraestructura en entornos Cloud y Big Data (Azure, AWS), e integración en arquitecturas híbridas.\n- Conocimiento en otros lenguajes como: Phyton, R, Scala.\n- Se valorará conocimiento en herramientas de explotación de información (Tableau, Qlikview… y otros) y en herramientas de EPM (Board y Onestream).\n- Habilidades Interpersonales: Habilidades de comunicación efectiva y capacidad para trabajar en equipo. La capacidad de adaptarse a entornos cambiantes y gestionar múltiples tareas simultáneamente.\nLa diversidad, clave en nuestra estrategia\nNuestro compromiso con la diversidad, la inclusión y la igualdad de oportunidades está presente desde nuestro nacimiento en 1890. Nuestra visión, en este sentido, es “construir el futuro a través de la suma de personas únicas, impulsando la diversidad de forma activa como fuente de riqueza en la sociedad”.\nPor eso, esta oferta está dirigida a cualquier persona que reúna los requisitos exigidos para el puesto, independientemente de sus características.\nReferencia\n244\nCategoría\nInformática y telecomunicaciones - Administración de bases de datos\nNúmero de vacantes\n1\nSalario\nSalario no disponible\n79 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nAl inscribirte en esta oferta tendrás que aceptar que MAHOU SAN MIGUEL reciba y gestione tus datos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br><br><h3>Descripción</h3><br><br>Sobre nosotros<br>Somos una compañía familiar, líder de bebidas en España. Contamos con 10 centros de elaboración de cerveza –ocho en España y dos en Estados Unidos–, cuatro manantiales de agua y un equipo cercano a los 4.000 profesionales. Estamos presentes en más de 70 países.<br>Nuestro compromiso con el empleo de calidad y el bienestar de las personas, nuestros valores, nuestro propósito y nuestro espíritu innovador y transformador, desde hace más de 130 años, definen una forma única de hacer las cosas que nos permite avanzar hacia el futuro.<br><br>¿Por qué te estamos buscando?<br>Tu misión será desarrollar e integrar diferentes fuentes de datos creando nuevos modelos de datos y evolucionando la arquitectura tecnológica actual para garantizar la consistencia, integridad y calidad de los datos.<br>Tu día a día en Mahou San Miguel<br>- Diseñar, definir y desarrollar los procesos de tratamiento e integración de datos asegurando la consistencia, completitud y calidad de los mismos.<br>- Evolucionar los procesos e infraestructura actuales para una óptima extracción, transformación y carga de datos.<br>- Estructurar y consolidar datos de diferentes fuentes para su explotación.<br>- Establecer los procesos de limpieza, validación y calidad de datos necesarios para desarrollar diferentes modelos de datos.<br>- Definir y desarrollar nuevos modelos de datos que permitan la explotación de la información a diferentes niveles.<br>- Desarrollar proyectos relacionados de evolución de tecnológica de casos de uso actuales y futuros dentro del área de Delivery, principalmente enfocados a procesos financieros y operacionales.<br>- Trabajar coordinadamente en el equipo de Delivery de EPM y Finanzas, junto Data & Analytics para asegurar el entendimiento y aplicación de los estándares de gobierno y calidad de datos en los proyectos.<br>¿Qué requisitos debes cumplir?<br>- Grado / Máster / Licenciatura Informática, Ciencias de la Computación o carreras afines.<br>- Nivel alto de inglés<br>- Al menos 4 años de experiencia en funciones de tratamiento e integración de datos. Se valorará positivamente experiencia en consultoría.<br>- Experiencia con lenguajes SQL, herramientas ETL y modelado de datos.<br>- Experiencia en entornos Big Data (Spark, Hadoop, Cassandra).<br>- Conocimiento de infraestructura en entornos Cloud y Big Data (Azure, AWS), e integración en arquitecturas híbridas.<br>- Conocimiento en otros lenguajes como: Phyton, R, Scala.<br>- Se valorará conocimiento en herramientas de explotación de información (Tableau, Qlikview… y otros) y en herramientas de EPM (Board y Onestream).<br>- Habilidades Interpersonales: Habilidades de comunicación efectiva y capacidad para trabajar en equipo. La capacidad de adaptarse a entornos cambiantes y gestionar múltiples tareas simultáneamente.<br>La diversidad, clave en nuestra estrategia<br>Nuestro compromiso con la diversidad, la inclusión y la igualdad de oportunidades está presente desde nuestro nacimiento en 1890. Nuestra visión, en este sentido, es “construir el futuro a través de la suma de personas únicas, impulsando la diversidad de forma activa como fuente de riqueza en la sociedad”.<br>Por eso, esta oferta está dirigida a cualquier persona que reúna los requisitos exigidos para el puesto, independientemente de sus características.<br>Referencia<br>244<br>Categoría<br>Informática y telecomunicaciones - Administración de bases de datos<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>79 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Al inscribirte en esta oferta tendrás que aceptar que MAHOU SAN MIGUEL reciba y gestione tus datos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "4",
            "porcentaje": "85",
            "skills_necesarias": [
                "SQL",
                "ETL",
                "PySpark",
                "Hadoop",
                "Cassandra",
                "Azure",
                "AWS",
                "Python",
                "R",
                "Scala"
            ],
            "skills_valoradas": [
                "Tableau",
                "Qlik",
                "Board",
                "Onestream"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data engineer AWS + TELETRABAJO",
        "empresa": "Luca TIC",
        "fecha_publicacion": "Publicada el 22 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-aws-teletrabajo/of-ife09adfd1e4378803e6d0615a87572?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=2&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 2 años\nIdiomas requeridos\nInglés - Nivel Intermedio\nConocimientos necesarios\nSQL\nDesarrollador\nPorgramador\nSCALA\nPython\nHadoop\nControl-M\nAWS\nPySpark\nremoto\nRequisitos mínimos\n-Experiencia en AWS.\n-Experiencia con alguna de las siguientes tecnologías: Python, Scala, Java o PySpark.\n-Nivel avanzado de inglés.\nRequisitos deseados\n-Experiencia con Hadoop o Hive.\n-Experiencia con Control M.\n-Experiencia con CI/CD\nDescripción\n¿Tienes más de 2 años de experiencia en el mundo de la programación? Desde Luca TIC estamos buscando a un ingeniero/a de datos.\nRequisitos mínimos:\n-Experiencia en AWS.\n-Experiencia con alguna de las siguientes tecnologías: Python, Scala, Java o PySpark.\n-Nivel avanzado de inglés.\nSerá un plus:\n-Experiencia con Hadoop o Hive.\n-Experiencia con Control M.\n-Experiencia con CI/CD\nOfrecemos:\n-Contrato Indefinido\n-Seguro Médico\n-Modalidad de trabajo híbrido.\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEspecialista\nNúmero de vacantes\n1\nDuración del contrato\nESTABLE\nHorario\nFlexible\nSalario\nSalario no disponible\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\nOtros beneficios:\nCesta de navidad\n5 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Idiomas requeridos<br>Inglés - Nivel Intermedio<br>Conocimientos necesarios<br>SQL<br>Desarrollador<br>Porgramador<br>SCALA<br>Python<br>Hadoop<br>Control-M<br>AWS<br>PySpark<br>remoto<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Experiencia en AWS.<br>-Experiencia con alguna de las siguientes tecnologías: Python, Scala, Java o PySpark.<br>-Nivel avanzado de inglés.<br><br><h3>Requisitos</h3> deseados<br>-Experiencia con Hadoop o Hive.<br>-Experiencia con Control M.<br>-Experiencia con CI/CD<br><br><h3>Descripción</h3><br>¿Tienes más de 2 años de experiencia en el mundo de la programación? Desde Luca TIC estamos buscando a un ingeniero/a de datos.<br><br><h3><br><h3>Requisitos</h3> mínimos</h3>:<br>-Experiencia en AWS.<br>-Experiencia con alguna de las siguientes tecnologías: Python, Scala, Java o PySpark.<br>-Nivel avanzado de inglés.<br>Será un plus:<br>-Experiencia con Hadoop o Hive.<br>-Experiencia con Control M.<br>-Experiencia con CI/CD<br>Ofrecemos:<br>-Contrato Indefinido<br>-Seguro Médico<br>-Modalidad de trabajo híbrido.<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Especialista<br>Número de vacantes<br>1<br>Duración del contrato<br>ESTABLE<br>Horario<br>Flexible<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>Otros beneficios:<br>Cesta de navidad<br>5 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "2",
            "porcentaje": "75",
            "skills_necesarias": [
                "SQL",
                "Python",
                "Scala",
                "AWS",
                "PySpark",
                "Hadoop"
            ],
            "skills_valoradas": [
                "Control-M",
                "CI/CD",
                "Hive"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Ingeniero/a de Datos Python Sql Remoto 100%",
        "empresa": "Quental Technologies",
        "fecha_publicacion": "Publicada el 21 de ene (Publicada de nuevo)",
        "min_salario": "18.000€",
        "max_salario": "28.000€",
        "url_oferta": "https://www.infojobs.net/madrid/ingeniero-datos-python-sql-remoto-100/of-iea7b81578a481aa8bc0655063f9c08?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado - Grado en Ingeniería Informática\nExperiencia mínima\nAl menos 1 año\nConocimientos necesarios\nPython\nBig data\nSQL\nETL Extract/Transform/Load\nETL\nRequisitos mínimos\n¿Qué puedes aportarnos?\n- Ingeniería Informática, Telecomunicaciones o similar.\n- Experiencia acreditada desde 6 meses colaborando en las fases de desarrollo y automatización de extracción, transformación, carga y creación de algoritmos desde infraestructuras Big Data.\n- Requisitos Técnicos: SQL, PYTHON\nDescripción\n¿Eres una persona a la que le gustaría afrontar nuevos retos y buscas seguir desarrollando tu carrera profesional en el mundo de los grandes entornos de Datos?\nEstamos seleccionando para nuestro laboratorio de Ciencia de Datos Ingenieros Informáticos o similar con experiencia en el desarrollo de las soluciones big data, participando en las tareas de programación Python, SQL para el desarrollo de las soluciones de data mining con tratamiento de grandes volúmenes de datos / Big Data. y desarrollo de algoritmos para herramientas de reporting a la decisión.\nFunciones de codificación de proyectos con manejo de grandes volúmenes:\n- Diseño y programación de procesos ETL (Python, Sql)\n- Diseño de modelos y programación de los procesos de extracción de los lagos de información y fuentes heterogéneas.\n- Desarrollo de algoritmos para herramientas de reporting a la decisión.\n¿Qué podemos ofrecerte?\n- Contrato indefinido y plan de retribución flexible con interesantes beneficios sociales.\n- Conciliación entre la vida personal y profesional, apoyado en un modelo de trabajo total, pudiendo organizarnos el día sin pérdidas de tiempo en desplazamientos largos y tediosos.\n- Desarrollo de carrera en un ambiente colaborativo y con bonificaciones a tu formación, para que siempre estés actualizado y a la última en cuanto a tecnología y tendencias en transformación digital.\n- Entorno salarial negociable en función de la experiencia aportada.\n- Inclusión en el programa de beneficios y descuentos, para disfrutar de tus eventos, vacaciones, compras diarias y caprichos, beneficiándote de todos los descuentos que aporta el Quental Club Benefits!\n¿Cómo son nuestros procesos de selección? Es primordial para nosotros mantener la coherencia en la toma de decisiones durante las distintas etapas de esta labor llevada a cabo por nuestro equipo. Nuestros procedimientos son inclusivos, sin sesgos ni prejuicios y buscando el objetivo: colaborar con el mejor talento.\n¡Te esperamos!\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario: 18.000€ - 28.000€ Bruto/año\nBeneficios sociales\nTeletrabajo\n128 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado - Grado en Ingeniería Informática<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br>Conocimientos necesarios<br>Python<br>Big data<br>SQL<br>ETL Extract/Transform/Load<br>ETL<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>¿Qué puedes aportarnos?<br>- Ingeniería Informática, Telecomunicaciones o similar.<br>- Experiencia acreditada desde 6 meses colaborando en las fases de desarrollo y automatización de extracción, transformación, carga y creación de algoritmos desde infraestructuras Big Data.<br>- <br><h3>Requisitos</h3> Técnicos: SQL, PYTHON<br><br><h3>Descripción</h3><br>¿Eres una persona a la que le gustaría afrontar nuevos retos y buscas seguir desarrollando tu carrera profesional en el mundo de los grandes entornos de Datos?<br>Estamos seleccionando para nuestro laboratorio de Ciencia de Datos Ingenieros Informáticos o similar con experiencia en el desarrollo de las soluciones big data, participando en las tareas de programación Python, SQL para el desarrollo de las soluciones de data mining con tratamiento de grandes volúmenes de datos / Big Data. y desarrollo de algoritmos para herramientas de reporting a la decisión.<br>Funciones de codificación de proyectos con manejo de grandes volúmenes:<br>- Diseño y programación de procesos ETL (Python, Sql)<br>- Diseño de modelos y programación de los procesos de extracción de los lagos de información y fuentes heterogéneas.<br>- Desarrollo de algoritmos para herramientas de reporting a la decisión.<br>¿Qué podemos ofrecerte?<br>- Contrato indefinido y plan de retribución flexible con interesantes beneficios sociales.<br>- Conciliación entre la vida personal y profesional, apoyado en un modelo de trabajo total, pudiendo organizarnos el día sin pérdidas de tiempo en desplazamientos largos y tediosos.<br>- Desarrollo de carrera en un ambiente colaborativo y con bonificaciones a tu formación, para que siempre estés actualizado y a la última en cuanto a tecnología y tendencias en transformación digital.<br>- Entorno salarial negociable en función de la experiencia aportada.<br>- Inclusión en el programa de beneficios y descuentos, para disfrutar de tus eventos, vacaciones, compras diarias y caprichos, beneficiándote de todos los descuentos que aporta el Quental Club Benefits!<br>¿Cómo son nuestros procesos de selección? Es primordial para nosotros mantener la coherencia en la toma de decisiones durante las distintas etapas de esta labor llevada a cabo por nuestro equipo. Nuestros procedimientos son inclusivos, sin sesgos ni prejuicios y buscando el objetivo: colaborar con el mejor talento.<br>¡Te esperamos!<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario: 18.000€ - 28.000€ Bruto/año<br>Beneficios sociales<br>Teletrabajo<br>128 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "1",
            "porcentaje": "70",
            "skills_necesarias": [
                "Python",
                "SQL",
                "Big Data",
                "ETL"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer Madrid",
        "empresa": "Ioon Technologies SLU",
        "fecha_publicacion": "Publicada el 21 de ene",
        "min_salario": "39.000€",
        "max_salario": "42.000€",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-madrid/of-ic566a510b24a85877512543bb4d5fd?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nIngeniería Técnica\nExperiencia mínima\nAl menos 4 años\nImprescindible residente en\nProvincia Puesto Vacante\nIdiomas requeridos\nInglés - Nivel Avanzado\nConocimientos necesarios\nPowerBI\nModelado de datos\nArquitectura\nDescripción\nEn Ioon estamos convencidos de que la tecnología será el eje de la transformación de nuestras vidas,\n¿Te animas a ser parte de esta revolución?\nTe proponemos esta posición por si te quieres sumar a un nuevo reto profesional\nData Consultant\nRef 1777\nEstamos buscando un Business Analyst con experiencia en el liderazgo de proyectos de análisis y visualización de datos, para dirigir nuestro servicio de Power BI.\nEsta posición combina la capacidad analítica, la experiencia técnica y las habilidades de liderazgo necesarias para traducir necesidades de negocio en soluciones efectivas, optimizando el uso de datos y mejorando la toma de decisiones.\nIdentificar y documentar necesidades de negocio y objetivos de análisis.\nTraducir requerimientos funcionales en especificaciones técnicas claras.\nDiseñar modelos de datos escalables y optimizados para Power BI.\nAsegurar la integración de diferentes fuentes de datos, implementando flujos de ETL eficientes.\nSupervisar la calidad, consistencia y seguridad de los datos utilizados.\nImplementación de Power BI:\nLiderar el diseño y desarrollo de dashboards y reportes interactivos en Power BI.\nGarantizar la adopción de las mejores prácticas en visualización y modelado de datos.\nOptimizar la performance de los informes, asegurando tiempos de carga rápidos y usabilidad.\nGestión y Liderazgo:\nActuar como enlace entre equipos técnicos y de negocio para garantizar el alineamiento de objetivos.\nCapacitar y liderar al equipo en el uso avanzado de Power BI y herramientas relacionadas.\nFomentar una cultura de toma de decisiones basada en datos en toda la organización.\n5Innovación y Mejora Continua:\nEvaluar y recomendar nuevas tecnologías o metodologías relacionadas con análisis de datos.\nMantenerse actualizado en tendencias y avances en herramientas BI y arquitecturas de datos.\nDeseable: Certificaciones en Power BI, Azure Data Engineer, o similares.\nExperiencia:\nMínimo 5 años en roles relacionados con análisis de negocio, arquitectura de datos o liderazgo de proyectos BI.\nExperiencia comprobable liderando implementaciones de Power BI.\nDominio de procesos ETL, modelado de datos, y diseño de bases de datos relacionales y multidimensionales.\nHabilidades Técnicas:\nSólidos conocimientos en Power BI (DAX, Power Query, diseño de dashboards).\nFamiliaridad con herramientas y tecnologías de datos: SQL, Azure Data Factory, Synapse Analytics, o similares.\nExperiencia en metodologías ágiles (Scrum, Kanban).\nConocimientos básicos de seguridad y gobernanza de datos.\nIdiomas: inglés alto\nModalidad: Presencial 100% en Ifema / Madrid al inicio\nMás adelante híbrido\nProceso ágil:\nParticipación en entrevista telefónica y entrevista online\nContrato indefinido\nSueldo bruto / año 38.000 - €45.000 (12 pagas)\nVentajas Ioon:\n23 días laborables de vacaciones al año\nPrograma de Retribución Flexible (cheques guardería, tarjeta transporte, seguro médico).\nFormación continua:\nAcceso gratuito a plataforma openwebinars y €350 de presupuesto para tu propia formación (no canjeable, no acumulable)\nMedidas de conciliación (horario flexible, teletrabajo, jornada intensiva los viernes y en verano según proyecto).\nReferencia\nRef 1777\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - ERP, CRM, Business Intelligence\nNivel\nEmpleado/a\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario: 39.000€ - 42.000€ Bruto/año\nBeneficios sociales\nFlexibilidad horaria\n12 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ingeniería Técnica<br><h4>Experiencia mínima</h4><br>Al menos 4 años<br>Imprescindible residente en<br>Provincia Puesto Vacante<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br>Conocimientos necesarios<br>PowerBI<br>Modelado de datos<br>Arquitectura<br><br><h3>Descripción</h3><br>En Ioon estamos convencidos de que la tecnología será el eje de la transformación de nuestras vidas,<br>¿Te animas a ser parte de esta revolución?<br>Te proponemos esta posición por si te quieres sumar a un nuevo reto profesional<br>Data Consultant<br>Ref 1777<br>Estamos buscando un Business Analyst con experiencia en el liderazgo de proyectos de análisis y visualización de datos, para dirigir nuestro servicio de Power BI.<br>Esta posición combina la capacidad analítica, la experiencia técnica y las habilidades de liderazgo necesarias para traducir necesidades de negocio en soluciones efectivas, optimizando el uso de datos y mejorando la toma de decisiones.<br>Identificar y documentar necesidades de negocio y objetivos de análisis.<br>Traducir requerimientos funcionales en especificaciones técnicas claras.<br>Diseñar modelos de datos escalables y optimizados para Power BI.<br>Asegurar la integración de diferentes fuentes de datos, implementando flujos de ETL eficientes.<br>Supervisar la calidad, consistencia y seguridad de los datos utilizados.<br>Implementación de Power BI:<br>Liderar el diseño y desarrollo de dashboards y reportes interactivos en Power BI.<br>Garantizar la adopción de las mejores prácticas en visualización y modelado de datos.<br>Optimizar la performance de los informes, asegurando tiempos de carga rápidos y usabilidad.<br>Gestión y Liderazgo:<br>Actuar como enlace entre equipos técnicos y de negocio para garantizar el alineamiento de objetivos.<br>Capacitar y liderar al equipo en el uso avanzado de Power BI y herramientas relacionadas.<br>Fomentar una cultura de toma de decisiones basada en datos en toda la organización.<br>5Innovación y Mejora Continua:<br>Evaluar y recomendar nuevas tecnologías o metodologías relacionadas con análisis de datos.<br>Mantenerse actualizado en tendencias y avances en herramientas BI y arquitecturas de datos.<br>Deseable: Certificaciones en Power BI, Azure Data Engineer, o similares.<br>Experiencia:<br>Mínimo 5 años en roles relacionados con análisis de negocio, arquitectura de datos o liderazgo de proyectos BI.<br>Experiencia comprobable liderando implementaciones de Power BI.<br>Dominio de procesos ETL, modelado de datos, y diseño de bases de datos relacionales y multidimensionales.<br>Habilidades Técnicas:<br>Sólidos conocimientos en Power BI (DAX, Power Query, diseño de dashboards).<br>Familiaridad con herramientas y tecnologías de datos: SQL, Azure Data Factory, Synapse Analytics, o similares.<br>Experiencia en metodologías ágiles (Scrum, Kanban).<br>Conocimientos básicos de seguridad y gobernanza de datos.<br>Idiomas: inglés alto<br>Modalidad: Presencial 100% en Ifema / Madrid al inicio<br>Más adelante híbrido<br>Proceso ágil:<br>Participación en entrevista telefónica y entrevista online<br>Contrato indefinido<br>Sueldo bruto / año 38.000 - €45.000 (12 pagas)<br>Ventajas Ioon:<br>23 días laborables de vacaciones al año<br>Programa de Retribución Flexible (cheques guardería, tarjeta transporte, seguro médico).<br>Formación continua:<br>Acceso gratuito a plataforma openwebinars y €350 de presupuesto para tu propia formación (no canjeable, no acumulable)<br>Medidas de conciliación (horario flexible, teletrabajo, jornada intensiva los viernes y en verano según proyecto).<br>Referencia<br>Ref 1777<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - ERP, CRM, Business Intelligence<br>Nivel<br>Empleado/a<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario: 39.000€ - 42.000€ Bruto/año<br>Beneficios sociales<br>Flexibilidad horaria<br>12 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "4",
            "porcentaje": "85",
            "skills_necesarias": [
                "Power BI",
                "ETL",
                "SQL",
                "Azure",
                "Synapse Analytics"
            ],
            "skills_valoradas": [
                "Power BI",
                "Azure",
                "Agile"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer (Hibrido, Madrid)",
        "empresa": "PSS",
        "fecha_publicacion": "Publicada el 21 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-hibrido-madrid/of-id090af3ff14152a1e1326eb3376e51?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 3 años\nConocimientos necesarios\nMicrosoft Azure\nPython\nScripting\nDescripción\n¿Te apetece formar parte de una compañía del sector IT? Si estás buscando un proyecto estable y quieres seguir evolucionando en tu carrera profesional acompañado del mejor talento, en PSS queremos conocerte.\nActualmente estamos seleccionando un Data Engineer para un importante proyecto del sector retail en Madrid.\n¿Qué necesitamos?\nExperiencia técnica de 3-5 años en integración de datos y scripting.\nConocimientos en:\nPython y Shell scripting.\nAPIs REST.\nHerramientas de integración de datos como Informática Cloud, Talend o similares.\nEntornos de nube (Microsoft Azure).\nY llegados a este punto... ¿qué te ofrecemos?\nContrato indefinido con PSS, brindándote estabilidad laboral.\nSalario acorde a tu experiencia y habilidades.\nModelo de trabajo: híbrido (3 días de teletrabajo por semana)\nUn proyecto sólido y estable de larga duración.\nPlan de carrera y formación continua, impulsando tu crecimiento profesional.\nRetribución flexible con ventajas fiscales: seguro médico privado, ticket restaurante, ticket guardería y/o ticket transporte.\nCampaña de referenciados: invita a tus amigos a trabajar contigo y gana un premio especial.\nPortal de Descuentos exclusivo: tecnología, viajes, moda y mucho más.\nEn PSS estamos comprometidos con la igualdad\nReferencia\nGM\nTipo de industria de la oferta\nTelecomunicaciones\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n15 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Conocimientos necesarios<br>Microsoft Azure<br>Python<br>Scripting<br><br><h3>Descripción</h3><br>¿Te apetece formar parte de una compañía del sector IT? Si estás buscando un proyecto estable y quieres seguir evolucionando en tu carrera profesional acompañado del mejor talento, en PSS queremos conocerte.<br>Actualmente estamos seleccionando un Data Engineer para un importante proyecto del sector retail en Madrid.<br>¿Qué necesitamos?<br>Experiencia técnica de 3-5 años en integración de datos y scripting.<br>Conocimientos en:<br>Python y Shell scripting.<br>APIs REST.<br>Herramientas de integración de datos como Informática Cloud, Talend o similares.<br>Entornos de nube (Microsoft Azure).<br>Y llegados a este punto... ¿qué te ofrecemos?<br>Contrato indefinido con PSS, brindándote estabilidad laboral.<br>Salario acorde a tu experiencia y habilidades.<br>Modelo de trabajo: híbrido (3 días de teletrabajo por semana)<br>Un proyecto sólido y estable de larga duración.<br>Plan de carrera y formación continua, impulsando tu crecimiento profesional.<br>Retribución flexible con ventajas fiscales: seguro médico privado, ticket restaurante, ticket guardería y/o ticket transporte.<br>Campaña de referenciados: invita a tus amigos a trabajar contigo y gana un premio especial.<br>Portal de Descuentos exclusivo: tecnología, viajes, moda y mucho más.<br>En PSS estamos comprometidos con la igualdad<br>Referencia<br>GM<br>Tipo de industria de la oferta<br>Telecomunicaciones<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>15 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "3",
            "porcentaje": "75",
            "skills_necesarias": [
                "Azure",
                "Python",
                "Scripting",
                "REST",
                "Cloud",
                "Talend"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "DATA ENGINEER (Pyspark) - Híbrido (Madrid, Granada, Jaén, Córdoba)",
        "empresa": "Ad4Octogono S.L.",
        "fecha_publicacion": "Publicada el 21 de ene",
        "min_salario": "24.000€",
        "max_salario": "25.000€",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-pyspark-hibrido-madrid-granada-jaen-cordoba/of-idc216fd8134a1491e70c94c00bdb2b?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 1 año\nImprescindible residente en\nEspaña\nIdiomas requeridos\nInglés - Nivel Intermedio\nConocimientos necesarios\nPython\nPyspark\nSQL\nAWS\nGlue\nLambda\nS3\nControl M\nQliksense\nDescripción\nEn Ad4 Octogono estamos contratando, buscamos una persona Data Engineer, con al menos 1 año de experiencia, apasionada y comprometida, para unirse a nuestro equipo.\nRequisitos:\n- Pyspark: nivel alto\n- Python: nivel alto\n- SQL: nivel medio\n- AWS Services: GLUE, EMR, Lambda, Athena, S3, ControlM: nivel medio/alto (con experiencia práctica)\n- Qliksense: nivel medio\nHabilidades:\n- Capacidad para ofrecer soluciones a problemas planteados por el negocio, enfocándose en la optimización y automatización de procesos.\n- Implementación de scripts para agilizar cálculos.\n- Flexibilidad y habilidad para trabajar en equipo.\n- Adaptabilidad ante cambios.\n- Aprendizaje rápido y continuo.\n- Experiencia mínima: 2 años\nNivel de inglés: B2\nUbicación: Jaén, Córdoba, Granada, Madrid\nModalidad de trabajo: de lunes a jueves presencial en alguna de las oficinas indicadas. Todos los viernes, Semana Santa, Julio y Agosto, y Navidades con 100% teletrabajo.\nSi tienes la experiencia y las habilidades necesarias y te entusiasma formar parte de un equipo dinámico, ¡queremos conocerte!\nReferencia\nmros\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - ERP, CRM, Business Intelligence\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario: 24.000€ - 25.000€ Bruto/año\nBeneficios sociales\nTeletrabajo\n6 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br>Imprescindible residente en<br>España<br>Idiomas requeridos<br>Inglés - Nivel Intermedio<br>Conocimientos necesarios<br>Python<br>Pyspark<br>SQL<br>AWS<br>Glue<br>Lambda<br>S3<br>Control M<br>Qliksense<br><br><h3>Descripción</h3><br>En Ad4 Octogono estamos contratando, buscamos una persona Data Engineer, con al menos 1 año de experiencia, apasionada y comprometida, para unirse a nuestro equipo.<br><br><h3>Requisitos</h3>:<br>- Pyspark: nivel alto<br>- Python: nivel alto<br>- SQL: nivel medio<br>- AWS Services: GLUE, EMR, Lambda, Athena, S3, ControlM: nivel medio/alto (con experiencia práctica)<br>- Qliksense: nivel medio<br>Habilidades:<br>- Capacidad para ofrecer soluciones a problemas planteados por el negocio, enfocándose en la optimización y automatización de procesos.<br>- Implementación de scripts para agilizar cálculos.<br>- Flexibilidad y habilidad para trabajar en equipo.<br>- Adaptabilidad ante cambios.<br>- Aprendizaje rápido y continuo.<br>- <h4>Experiencia mínima</h4>: 2 años<br>Nivel de inglés: B2<br>Ubicación: Jaén, Córdoba, Granada, Madrid<br>Modalidad de trabajo: de lunes a jueves presencial en alguna de las oficinas indicadas. Todos los viernes, Semana Santa, Julio y Agosto, y Navidades con 100% teletrabajo.<br>Si tienes la experiencia y las habilidades necesarias y te entusiasma formar parte de un equipo dinámico, ¡queremos conocerte!<br>Referencia<br>mros<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - ERP, CRM, Business Intelligence<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario: 24.000€ - 25.000€ Bruto/año<br>Beneficios sociales<br>Teletrabajo<br>6 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B2",
            "anios_experiencia": "1",
            "porcentaje": "70",
            "skills_necesarias": [
                "Python",
                "PySpark",
                "SQL",
                "AWS",
                "Control M",
                "Qlik"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Ingeniero/a de datos",
        "empresa": "Grupo Diusframi",
        "fecha_publicacion": "Publicada el 20 de ene (Publicada de nuevo)",
        "min_salario": "25.000€",
        "max_salario": "33.000€",
        "url_oferta": "https://www.infojobs.net/madrid/ingeniero-datos/of-ib32b85ae28400aaa3fb2dccdaa9b07?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nAl menos 3 años\nRequisitos mínimos\n-Experiencia de al menos 3 años como desarrollador de BI o científico de datos.\n- Experiencia de al menos 3 años en diseño de almacenes de datos y minería de datos.\n- Muy valorable experiencia en el entorno financiero y experiencia en medios de pago.\n- Conocimiento nivel avanzado en consultas SQL y lenguajes de programación de analítica de datos: Python.\n- Conocimiento de bases de datos no relacionales (MongoDB).\n- Valorable conocimientos en Spark o Databricks.\nRequisitos deseados\nSe valorará la posesión de certificado de discapacidad\nDescripción\nDesde netOlympus, empresa perteneciente al Grupo Diusframi, estamos en búsqueda de un/a Ingeniero/a de datos que se encargue de la mejora de los procesos y de los sistemas de inteligencia empresarial para ayudar a la compañía y a nuestros clientes a tomar mejores decisiones en sus negocios.\nLas funciones que llevará a cabo son:\n- Traducir las necesidades internas, y de nuestros clientes, a especificaciones técnicas.\n- Diseñar, construir e implementar arquitecturas de analítica de datos.\n- Diseñar, construir e implementar soluciones de BI (a través de herramientas de informes y de procesos ETL/ELT).\n- Desarrollar y ejecutar consultas de bases de datos y realizar análisis.\n- Creación de visualizaciones e informes para los proyectos solicitados.\n- Realizar pruebas de unidad y resolución de problemas.\n- Desarrollar y actualizar la documentación técnica.\n- Colaborar con equipos para integrar sistemas.\n- Evaluar y mejorar de forma continua, los sistemas de BI existentes.\nSe ofrece:\n- Contrato indefinido.\n- Horario de lunes a jueves de 8:00 a 17:15 y viernes de 8:00 a 15:00.\n- Modalidad híbrida: 50% teletrabajo.\n- Salario: entre 25.000€ y 32.000€ brutos/anuales, en función del ajuste del candidato.\nGrupo Diusframi promueve activamente la igualdad de oportunidades entre hombres y mujeres.\nSe valorará positivamente encontrarse en posesión del certificado de discapacidad.\nTipo de industria de la oferta\nServicios financieros\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario: 25.000€ - 33.000€ Bruto/año\nBeneficios sociales\nTeletrabajo\nOtros beneficios:\nRetribución flexible\n56 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Experiencia de al menos 3 años como desarrollador de BI o científico de datos.<br>- Experiencia de al menos 3 años en diseño de almacenes de datos y minería de datos.<br>- Muy valorable experiencia en el entorno financiero y experiencia en medios de pago.<br>- Conocimiento nivel avanzado en consultas SQL y lenguajes de programación de analítica de datos: Python.<br>- Conocimiento de bases de datos no relacionales (MongoDB).<br>- Valorable conocimientos en Spark o Databricks.<br><br><h3>Requisitos</h3> deseados<br>Se valorará la posesión de certificado de discapacidad<br><br><h3>Descripción</h3><br>Desde netOlympus, empresa perteneciente al Grupo Diusframi, estamos en búsqueda de un/a Ingeniero/a de datos que se encargue de la mejora de los procesos y de los sistemas de inteligencia empresarial para ayudar a la compañía y a nuestros clientes a tomar mejores decisiones en sus negocios.<br>Las funciones que llevará a cabo son:<br>- Traducir las necesidades internas, y de nuestros clientes, a especificaciones técnicas.<br>- Diseñar, construir e implementar arquitecturas de analítica de datos.<br>- Diseñar, construir e implementar soluciones de BI (a través de herramientas de informes y de procesos ETL/ELT).<br>- Desarrollar y ejecutar consultas de bases de datos y realizar análisis.<br>- Creación de visualizaciones e informes para los proyectos solicitados.<br>- Realizar pruebas de unidad y resolución de problemas.<br>- Desarrollar y actualizar la documentación técnica.<br>- Colaborar con equipos para integrar sistemas.<br>- Evaluar y mejorar de forma continua, los sistemas de BI existentes.<br>Se ofrece:<br>- Contrato indefinido.<br>- Horario de lunes a jueves de 8:00 a 17:15 y viernes de 8:00 a 15:00.<br>- Modalidad híbrida: 50% teletrabajo.<br>- Salario: entre 25.000€ y 32.000€ brutos/anuales, en función del ajuste del candidato.<br>Grupo Diusframi promueve activamente la igualdad de oportunidades entre hombres y mujeres.<br>Se valorará positivamente encontrarse en posesión del certificado de discapacidad.<br>Tipo de industria de la oferta<br>Servicios financieros<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario: 25.000€ - 33.000€ Bruto/año<br>Beneficios sociales<br>Teletrabajo<br>Otros beneficios:<br>Retribución flexible<br>56 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "3",
            "porcentaje": "80",
            "skills_necesarias": [
                "BI (Business Intelligence)",
                "Diseño de almacenes de datos",
                "Minería de datos",
                "SQL",
                "Python",
                "NoSQL",
                "ETL"
            ],
            "skills_valoradas": [
                "PySpark",
                "Databricks",
                "Experiencia en el entorno financiero",
                "Experiencia en medios de pago"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Técnico Data Science",
        "empresa": "IRYO",
        "fecha_publicacion": "Publicada el 20 de ene (Publicada de nuevo)",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/tecnico-data-science/of-i64d9ff62e2468fb99732a91aa16039?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nIngeniería Superior - Industrial\nExperiencia mínima\nAl menos 3 años\nImprescindible residente en\nEspaña\nIdiomas requeridos\nInglés - Nivel Avanzado\nConocimientos necesarios\nAnálisis\nRevenue Management\nOptimización\nGestión\nAnálisis de datos\nPython\nSQL\nRequisitos mínimos\n¿Qué buscamos?\n- Licenciado en Matemáticas, Ingeniería, Económicas, Computer Science o similar.\n- Habilidades en programación, preferible en Python.\n- Habilidades en estadística descriptiva, regresión lineal y modelos de optimización (lineal, dinámica,...)\n- Conocimiento de herramientas de Business Inteligent, preferiblemente Qlik.\n- Trabajo en equipo.\n- Nivel avanzado de inglés.\nRequisitos deseados\n- Conocimientos en estadística.\n- Manejo con hojas Excel.\n- Conocimiento de los canales de distribución en alta velocidad, líneas aéreas, hoteles, etc.\n- Deseable experiencia en el sector turístico.\nLos requisitos deseables son un plus, pero no son obligatorios para solicitar el puesto.\nDescripción\nEnmarcado en el proceso de crecimiento de la compañía, necesitamos incorporar una persona dentro del área de Network Planning, Revenue Management y Distribution, con un perfil de técnico en Data Science, para apoyar los desarrollos tanto de algoritmos de optimización y personalización de clientes como de reporting del área.\nResponsabilidades:\n- Colaborar con el equipo de Data Science en la recopilación, limpieza y análisis de datos.\n- Desarrollar y mantener modelos predictivos y analíticos.\n- Contribuir al diseño y ejecución de experimentos para validar hipótesis y mejorar los modelos existentes.\n- Realizar investigaciones de mercado y análisis competitivo para identificar tendencias y oportunidades.\n¿Te interesa?\nSi quieres asumir un nuevo desafío y formar parte de nuestro equipo, envíanos tu CV ¡te estamos buscando!\nTipo de industria de la oferta\nTransporte (mercancías y pasajeros) y mensajeria\nCategoría\nTurismo y restauración - Turismo\nDepartamento\nComercial\nNivel\nEmpleado/a\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nPorcentaje sobre objetivos\nFlexibilidad horaria\nTeletrabajo\nSeguro médico\nCheque restaurante\n39 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ingeniería Superior - Industrial<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Imprescindible residente en<br>España<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br>Conocimientos necesarios<br>Análisis<br>Revenue Management<br>Optimización<br>Gestión<br>Análisis de datos<br>Python<br>SQL<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>¿Qué buscamos?<br>- Licenciado en Matemáticas, Ingeniería, Económicas, Computer Science o similar.<br>- Habilidades en programación, preferible en Python.<br>- Habilidades en estadística descriptiva, regresión lineal y modelos de optimización (lineal, dinámica,...)<br>- Conocimiento de herramientas de Business Inteligent, preferiblemente Qlik.<br>- Trabajo en equipo.<br>- Nivel avanzado de inglés.<br><br><h3>Requisitos</h3> deseados<br>- Conocimientos en estadística.<br>- Manejo con hojas Excel.<br>- Conocimiento de los canales de distribución en alta velocidad, líneas aéreas, hoteles, etc.<br>- Deseable experiencia en el sector turístico.<br>Los requisitos deseables son un plus, pero no son obligatorios para solicitar el puesto.<br><br><h3>Descripción</h3><br>Enmarcado en el proceso de crecimiento de la compañía, necesitamos incorporar una persona dentro del área de Network Planning, Revenue Management y Distribution, con un perfil de técnico en Data Science, para apoyar los desarrollos tanto de algoritmos de optimización y personalización de clientes como de reporting del área.<br>Responsabilidades:<br>- Colaborar con el equipo de Data Science en la recopilación, limpieza y análisis de datos.<br>- Desarrollar y mantener modelos predictivos y analíticos.<br>- Contribuir al diseño y ejecución de experimentos para validar hipótesis y mejorar los modelos existentes.<br>- Realizar investigaciones de mercado y análisis competitivo para identificar tendencias y oportunidades.<br>¿Te interesa?<br>Si quieres asumir un nuevo desafío y formar parte de nuestro equipo, envíanos tu CV ¡te estamos buscando!<br>Tipo de industria de la oferta<br>Transporte (mercancías y pasajeros) y mensajeria<br>Categoría<br>Turismo y restauración - Turismo<br>Departamento<br>Comercial<br>Nivel<br>Empleado/a<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Porcentaje sobre objetivos<br>Flexibilidad horaria<br>Teletrabajo<br>Seguro médico<br>Cheque restaurante<br>39 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "3",
            "porcentaje": "85",
            "skills_necesarias": [
                "Python",
                "SQL",
                "Análisis de datos",
                "Revenue Management"
            ],
            "skills_valoradas": [
                "Qlik",
                "Excel"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Senior Big Data Developer",
        "empresa": "SOFTTEK",
        "fecha_publicacion": "Publicada el 20 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/senior-big-data-developer/of-i61ac5a56384a729f41b39b306bf664?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nFormación Profesional Grado Superior\nExperiencia mínima\nAl menos 3 años\nIdiomas requeridos\nInglés - Nivel Avanzado\nConocimientos necesarios\nBig data\nHadoop\nSpark\nHive\nJava\nPython\nSCALA\nSQL Server\nAWS\nAzure\nRequisitos mínimos\n-Experiencia comprobada como desarrollador de Big Data o en puestos similares.\n- Competencia en marcos de Big Data como Hadoop, Spark, Hive, etc.\n- Sólida experiencia en lenguajes de programación como Java, Python o Scala.\n- Experiencia en SQL avanzado.\n- Sólida comprensión de los principios y algoritmos de computación distribuida.\n- Familiaridad con plataformas en la nube (AWS, Azure, GCP) y experiencia con soluciones de Big Data nativas Cloud (p. ej., AWS EMR, GCP Dataproc).\n- Sólidas habilidades analíticas y de resolución de problemas con un enfoque en la optimización y el rendimiento.\n- Inglés alto (B2+/C1).\nRequisitos deseados\n- Familiaridad con las prácticas de gobernanza de datos y estándares de seguridad.\n- Experiencia con prácticas de DevOps y canalizaciones de CI/CD para soluciones de Big Data.\n- El conocimiento de marcos de aprendizaje automático (p. ej., TensorFlow, PyTorch) es un plus.\nDescripción\n¿Qué buscamos?\nEstamos buscamos un/a Big Data Developer con nivel de inglés alto para unirse al equipo de UK dentro de un importante cliente del sector bancario. La persona seleccionada será responsable del desarrollo, implementación y optimización de soluciones de Big Data en AWS Cloud, trabajando en estrecha colaboración con ingenieros de datos y analistas comerciales para crear canales de datos escalables e implementar soluciones para procesar y analizar grandes conjuntos de datos de manera eficiente en la plataforma AWS. Este puesto implica aprovechar los servicios de AWS como EMR, S3, Glue y Lambda para diseñar y optimizar flujos de trabajo de Big Data en un entorno Cloud.\n¿Por qué ser Softtekian?\n· Contrato indefinido.\n· 24 días de vacaciones.\n· Seguro médico.\n· Retribución flexible: tarjeta transporte, tarjeta restaurante, cheque guardería o seguro médico familiares.\n· Tarde de cumpleaños libre (también por el cumple de tus hijos).\n· Club del empleado: ofertas y promociones exclusivas por ser Softtekian.\n· Planes de formación: idiomas, tecnologías y soft skills.\n· Oportunidad de movilidad interna: contamos con presencia internacional y diversas sedes en España.\n¿Quiénes somos?\nSomos Softtek, un grupo tecnológico global que integra una cultura única, beneficios y un gran desarrollo, tanto profesional como humano, con presencia en más de 20 países y 14 sedes en España. Generamos valor a través de la tecnología y nuestro objetivo es dejar huella y trascender en el ámbito de la transformación digital. Ya sumamos más 16.000 softtekians alrededor del mundo y seguimos creciendo.\nEn 2024 hemos sido reconocidos por la Lista Forbes como una de las 100 mejores empresas para trabajar en España, destacando por la flexibilidad y la personalización de la experiencia de nuestros colaboradores. Creemos que las personas con talento y autodeterminación son capaces de crear cosas asombrosas. ¿Nos acompañas en esta aventura? #FutureTogether\nValoraremos especialmente la candidatura de personas que posean habilidades y capacidades únicas y diversas, reconociendo la importancia de facilitar su integración plena en el mercado laboral. Cada individuo, con sus capacidades singulares, aporta una riqueza invaluable a nuestra comunidad, y nuestro compromiso es asegurar que todos tengan la oportunidad de demostrar su valía y contribuir al crecimiento y la diversidad de nuestro equipo.\nReferencia\n14839\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\nSeguro médico\n4 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Formación Profesional Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br>Conocimientos necesarios<br>Big data<br>Hadoop<br>Spark<br>Hive<br>Java<br>Python<br>SCALA<br>SQL Server<br>AWS<br>Azure<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Experiencia comprobada como desarrollador de Big Data o en puestos similares.<br>- Competencia en marcos de Big Data como Hadoop, Spark, Hive, etc.<br>- Sólida experiencia en lenguajes de programación como Java, Python o Scala.<br>- Experiencia en SQL avanzado.<br>- Sólida comprensión de los principios y algoritmos de computación distribuida.<br>- Familiaridad con plataformas en la nube (AWS, Azure, GCP) y experiencia con soluciones de Big Data nativas Cloud (p. ej., AWS EMR, GCP Dataproc).<br>- Sólidas habilidades analíticas y de resolución de problemas con un enfoque en la optimización y el rendimiento.<br>- Inglés alto (B2+/C1).<br><br><h3>Requisitos</h3> deseados<br>- Familiaridad con las prácticas de gobernanza de datos y estándares de seguridad.<br>- Experiencia con prácticas de DevOps y canalizaciones de CI/CD para soluciones de Big Data.<br>- El conocimiento de marcos de aprendizaje automático (p. ej., TensorFlow, PyTorch) es un plus.<br><br><h3>Descripción</h3><br>¿Qué buscamos?<br>Estamos buscamos un/a Big Data Developer con nivel de inglés alto para unirse al equipo de UK dentro de un importante cliente del sector bancario. La persona seleccionada será responsable del desarrollo, implementación y optimización de soluciones de Big Data en AWS Cloud, trabajando en estrecha colaboración con ingenieros de datos y analistas comerciales para crear canales de datos escalables e implementar soluciones para procesar y analizar grandes conjuntos de datos de manera eficiente en la plataforma AWS. Este puesto implica aprovechar los servicios de AWS como EMR, S3, Glue y Lambda para diseñar y optimizar flujos de trabajo de Big Data en un entorno Cloud.<br>¿Por qué ser Softtekian?<br>· Contrato indefinido.<br>· 24 días de vacaciones.<br>· Seguro médico.<br>· Retribución flexible: tarjeta transporte, tarjeta restaurante, cheque guardería o seguro médico familiares.<br>· Tarde de cumpleaños libre (también por el cumple de tus hijos).<br>· Club del empleado: ofertas y promociones exclusivas por ser Softtekian.<br>· Planes de formación: idiomas, tecnologías y soft skills.<br>· Oportunidad de movilidad interna: contamos con presencia internacional y diversas sedes en España.<br>¿Quiénes somos?<br>Somos Softtek, un grupo tecnológico global que integra una cultura única, beneficios y un gran desarrollo, tanto profesional como humano, con presencia en más de 20 países y 14 sedes en España. Generamos valor a través de la tecnología y nuestro objetivo es dejar huella y trascender en el ámbito de la transformación digital. Ya sumamos más 16.000 softtekians alrededor del mundo y seguimos creciendo.<br>En 2024 hemos sido reconocidos por la Lista Forbes como una de las 100 mejores empresas para trabajar en España, destacando por la flexibilidad y la personalización de la experiencia de nuestros colaboradores. Creemos que las personas con talento y autodeterminación son capaces de crear cosas asombrosas. ¿Nos acompañas en esta aventura? #FutureTogether<br>Valoraremos especialmente la candidatura de personas que posean habilidades y capacidades únicas y diversas, reconociendo la importancia de facilitar su integración plena en el mercado laboral. Cada individuo, con sus capacidades singulares, aporta una riqueza invaluable a nuestra comunidad, y nuestro compromiso es asegurar que todos tengan la oportunidad de demostrar su valía y contribuir al crecimiento y la diversidad de nuestro equipo.<br>Referencia<br>14839<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>Seguro médico<br>4 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "3",
            "porcentaje": "90",
            "skills_necesarias": [
                "Big Data",
                "Hadoop",
                "PySpark",
                "Hive",
                "Java",
                "Python",
                "Scala",
                "SQL",
                "AWS",
                "Azure"
            ],
            "skills_valoradas": [
                "TensorFlow",
                "PyTorch",
                "DevOps",
                "CI/CD"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Proceso online",
        "empresa": "Coordinador/a Oficina de Analítica - Indefinido",
        "fecha_publicacion": "Publicada el 16 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/coordinador-oficina-analitica-indefinido/of-ib407d56afa462c8e581bfcf55f0d5c?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nIngeniería Superior - Ingeniero en Informática\nExperiencia mínima\nMás de 5 años\nImprescindible residente en\nProvincia Puesto Vacante\nIdiomas requeridos\nInglés - Nivel Intermedio\nRequisitos deseados\n·Titulación: Titulación Universitaria Superior Ingeniería.\n·Titulación valorable: Gestión de proyectos y metodologías ágiles (Scrum, Kanban, Lean...)\n·Experiencia de trabajo relevante: 7 años de experiencia en gestión de proyectos con visión tecnológica y al menos 5 años de ellos en las funciones detalladas relacionados con el ámbito de datos. Habilidades de comunicación y negociación a nivel transversal.\n·Conocimiento específico del negocio/sector/función: Valorable conocimiento del sector seguros/banca, gestión de siniestros y/o call center.\n·Idiomas, nivel hablado y escrito: inglés nivel medio\n·Conocimientos de informática: Office 365, SQL, SAS, Power BI, Looker, Qlik, Azure, Databricks, ETLs, herramientas de gestión de proyectos (Jira, Confluence, ServiceNow)\n·Frecuencia de viaje: poco frecuente\nDescripción\nMISIÓN\nSu misión será de coordinación de proyectos e iniciativas de analítica de datos desde el origen hasta la implantación en la plataforma de analítica avanzada. Este rol es clave para garantizar la entrega exitosa de soluciones de datos, asegurando el cumplimiento de plazos, presupuesto y estándares de calidad. Se encargará de coordinar la oficina de analítica con los procesos, proyectos, evolutivos e incidencias que esto conlleva.\n¿CÓMO SERÁ TU DÍA A DÍA? Tus principales responsabilidades serán:\n·Alineado con la estrategia de datos de IRIS Global, estará enfocado a la visibilidad y seguimiento de la automatización de datos con visión completa, liderando el diseño e implantación de soluciones que permitan alcanzar los objetivos estratégicos y desarrollo de proyectos siguiendo el ciclo de vida analítico del dato.\n·Será el responsable funcional del seguimiento y gestión de los proyectos del área, reportando la situación de avance de hitos relevantes.\n·Liderará la creación de procedimientos y modelos de relación del área de datos con el resto de áreas (TI, negocio, corporativo...): como los procesos de gestión de la demanda, calidad, operativización del dato.\n·Recopilará, creará y controlará el versionado de la documentación que recoja la visión completa del proyecto, desde los requerimientos, análisis y preparación de datos hasta su aprovisionamiento y explotación.\n·A nivel arquitectónico colaborará en el diseño del modelo de datos empresarial, así como en las mejores integraciones de las aplicaciones acorde a los conceptos de la compañía.\n·Diseñará soluciones y objetos de explotación orientados a la toma de decisiones, asegurando la disposición de la data necesaria, la integración con la arquitectura y herramientas de IRIS y del grupo Santalucía, la definición de características y funcionalidades prioritarias para negocio, así como el diseño de las visualizaciones.\n·Gestionará la calidad, asegurando el cumplimiento de estándares y requerimientos en los entregables, así como la aplicación de las mejores prácticas en la gestión de proyectos.\n·Identificará, analizará y presentará mediciones del impacto de las actividades del equipo de datos para facilitar la toma de decisiones\n·Colaborará en la definición y divulgación de políticas, procedimientos y documentación del departamento\n·Participará en el diseño de programas de capacitación internos y/o workshops específicos.\n·Gestión de equipo interno y externo (proveedores).\nERES NUESTRO CANDIDATO/A SI CUENTAS CON:\n·Titulación: Titulación Universitaria Superior Ingeniería.\n·Titulación valorable: Gestión de proyectos y metodologías ágiles (Scrum, Kanban, Lean...)\n·Experiencia de trabajo relevante: 7 años de experiencia en gestión de proyectos con visión tecnológica y al menos 5 años de ellos en las funciones detalladas relacionados con el ámbito de datos. Habilidades de comunicación y negociación a nivel transversal.\n·Conocimiento específico del negocio/sector/función: Valorable conocimiento del sector seguros/banca, gestión de siniestros y/o call center.\n·Idiomas, nivel hablado y escrito: inglés nivel medio\n·Conocimientos de informática: Office 365, SQL, SAS, Power BI, Looker, Qlik, Azure, Databricks, ETLs, herramientas de gestión de proyectos (Jira, Confluence, ServiceNow)\n·Frecuencia de viaje: poco frecuente\nTipo de industria de la oferta\nSeguros\nCategoría\nFinanzas y banca - Seguros\nNivel\nMando intermedio\nPersonal a cargo\n1 - 5\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\nOtros beneficios:\nRetribución flexible\n20 inscritos a esta oferta\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ingeniería Superior - Ingeniero en Informática<br><h4>Experiencia mínima</h4><br>Más de 5 años<br>Imprescindible residente en<br>Provincia Puesto Vacante<br>Idiomas requeridos<br>Inglés - Nivel Intermedio<br><br><h3>Requisitos</h3> deseados<br>·Titulación: Titulación Universitaria Superior Ingeniería.<br>·Titulación valorable: Gestión de proyectos y metodologías ágiles (Scrum, Kanban, Lean...)<br>·Experiencia de trabajo relevante: 7 años de experiencia en gestión de proyectos con visión tecnológica y al menos 5 años de ellos en las funciones detalladas relacionados con el ámbito de datos. Habilidades de comunicación y negociación a nivel transversal.<br>·Conocimiento específico del negocio/sector/función: Valorable conocimiento del sector seguros/banca, gestión de siniestros y/o call center.<br>·Idiomas, nivel hablado y escrito: inglés nivel medio<br>·Conocimientos de informática: Office 365, SQL, SAS, Power BI, Looker, Qlik, Azure, Databricks, ETLs, herramientas de gestión de proyectos (Jira, Confluence, ServiceNow)<br>·Frecuencia de viaje: poco frecuente<br><br><h3>Descripción</h3><br>MISIÓN<br>Su misión será de coordinación de proyectos e iniciativas de analítica de datos desde el origen hasta la implantación en la plataforma de analítica avanzada. Este rol es clave para garantizar la entrega exitosa de soluciones de datos, asegurando el cumplimiento de plazos, presupuesto y estándares de calidad. Se encargará de coordinar la oficina de analítica con los procesos, proyectos, evolutivos e incidencias que esto conlleva.<br>¿CÓMO SERÁ TU DÍA A DÍA? Tus principales responsabilidades serán:<br>·Alineado con la estrategia de datos de IRIS Global, estará enfocado a la visibilidad y seguimiento de la automatización de datos con visión completa, liderando el diseño e implantación de soluciones que permitan alcanzar los objetivos estratégicos y desarrollo de proyectos siguiendo el ciclo de vida analítico del dato.<br>·Será el responsable funcional del seguimiento y gestión de los proyectos del área, reportando la situación de avance de hitos relevantes.<br>·Liderará la creación de procedimientos y modelos de relación del área de datos con el resto de áreas (TI, negocio, corporativo...): como los procesos de gestión de la demanda, calidad, operativización del dato.<br>·Recopilará, creará y controlará el versionado de la documentación que recoja la visión completa del proyecto, desde los requerimientos, análisis y preparación de datos hasta su aprovisionamiento y explotación.<br>·A nivel arquitectónico colaborará en el diseño del modelo de datos empresarial, así como en las mejores integraciones de las aplicaciones acorde a los conceptos de la compañía.<br>·Diseñará soluciones y objetos de explotación orientados a la toma de decisiones, asegurando la disposición de la data necesaria, la integración con la arquitectura y herramientas de IRIS y del grupo Santalucía, la definición de características y funcionalidades prioritarias para negocio, así como el diseño de las visualizaciones.<br>·Gestionará la calidad, asegurando el cumplimiento de estándares y requerimientos en los entregables, así como la aplicación de las mejores prácticas en la gestión de proyectos.<br>·Identificará, analizará y presentará mediciones del impacto de las actividades del equipo de datos para facilitar la toma de decisiones<br>·Colaborará en la definición y divulgación de políticas, procedimientos y documentación del departamento<br>·Participará en el diseño de programas de capacitación internos y/o workshops específicos.<br>·Gestión de equipo interno y externo (proveedores).<br>ERES NUESTRO CANDIDATO/A SI CUENTAS CON:<br>·Titulación: Titulación Universitaria Superior Ingeniería.<br>·Titulación valorable: Gestión de proyectos y metodologías ágiles (Scrum, Kanban, Lean...)<br>·Experiencia de trabajo relevante: 7 años de experiencia en gestión de proyectos con visión tecnológica y al menos 5 años de ellos en las funciones detalladas relacionados con el ámbito de datos. Habilidades de comunicación y negociación a nivel transversal.<br>·Conocimiento específico del negocio/sector/función: Valorable conocimiento del sector seguros/banca, gestión de siniestros y/o call center.<br>·Idiomas, nivel hablado y escrito: inglés nivel medio<br>·Conocimientos de informática: Office 365, SQL, SAS, Power BI, Looker, Qlik, Azure, Databricks, ETLs, herramientas de gestión de proyectos (Jira, Confluence, ServiceNow)<br>·Frecuencia de viaje: poco frecuente<br>Tipo de industria de la oferta<br>Seguros<br>Categoría<br>Finanzas y banca - Seguros<br>Nivel<br>Mando intermedio<br>Personal a cargo<br>1 - 5<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>Otros beneficios:<br>Retribución flexible<br>20 inscritos a esta oferta<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B1",
            "anios_experiencia": "5",
            "porcentaje": "75",
            "skills_necesarias": [
                "SQL",
                "SAS",
                "Power BI",
                "Looker",
                "Qlik",
                "Azure",
                "Databricks",
                "ETL",
                "Jira",
                "Confluence",
                "ServiceNow"
            ],
            "skills_valoradas": [
                "Scrum",
                "Kanban",
                "Lean"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Beca Data IT",
        "empresa": "Burger King Spain S. L. U.",
        "fecha_publicacion": "Publicada el 16 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/pozuelo-de-alarcon/beca-data-it/of-ibc8a4e19324eda9a441b277b70cb18?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nNo Requerida\nRequisitos mínimos\n¿Cómo imaginamos a nuestro/a nuevo/a compañero/a?\n- Formación en ingeniería, tecnología o estudios a fines.\n- Perfil proactivo y dinámico.\n- Creatividad y mucha pasión por tu trabajo.\n- Posibilidad de realizar un convenio en prácticas.\n- Y disponibilidad para trabajar presencialmente en Pozuelo de Alarcón.\n- Conocimientos de bases de datos (SQL)\n- Familiaridad con lenguajes como Python, SSIS, Data Factory, Pentaho\n- Deseable: Conocimientos en herramientas de visualización (Power BI, Tableau)\nDescripción\n¡En Burger King ® seguimos incorporando talento!\n\n\n\nSi quieres contribuir a que el fuego de nuestras parrillas no cese, ¡ahora es tu oportunidad!\n\n\n\nBuscamos a un nuevo/a compañero/a para sumarse a nuestro equipo de IT como Becario/a.\n\n\n\n¿Cómo sería tu día a día en Burger King ®?- Apoyar en la construcción y optimización de procesos ETL.\n\n- Participar en la creación de dashboards para facilitar la toma de decisiones.\n\n- Asegurar la calidad y la integridad de los datos.\n\n¿Cómo es ser parte de nuestro equipo?\n\n\n\n- Formar parte de la compañía líder de restauración organizada de nuestro país es tener un crecimiento constante.\n\n- Entorno de trabajo colaborativo en el que tus ideas serán valoradas y que servirán para aportar valor\n\n- Modalidad de trabajo: Presencial\n\n- Ayuda al estudio de 600 por jornada completa\n\n- Ubicación: Pozuelo de Alarcón\n\n- Horario: 8:30 a 18:00 con jornada intensiva los viernes y los meses de julio y agosto.\n\n\n\nSi eres un auténtico fan del Whopper® y quieres formar parte de un proyecto laboral retador, ¡no dudes más y envíanos tu solicitud!\n\n\n\n¡Conviértete en un auténtico King!\nReferencia\n388465932\nCategoría\nInformática y telecomunicaciones - Programación\nDepartamento\nInformática\nNivel\nBecario/a - Prácticas\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario no disponible\n177 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>No Requerida<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>¿Cómo imaginamos a nuestro/a nuevo/a compañero/a?<br>- Formación en ingeniería, tecnología o estudios a fines.<br>- Perfil proactivo y dinámico.<br>- Creatividad y mucha pasión por tu trabajo.<br>- Posibilidad de realizar un convenio en prácticas.<br>- Y disponibilidad para trabajar presencialmente en Pozuelo de Alarcón.<br>- Conocimientos de bases de datos (SQL)<br>- Familiaridad con lenguajes como Python, SSIS, Data Factory, Pentaho<br>- Deseable: Conocimientos en herramientas de visualización (Power BI, Tableau)<br><br><h3>Descripción</h3><br>¡En Burger King ® seguimos incorporando talento!<br><br><br><br>Si quieres contribuir a que el fuego de nuestras parrillas no cese, ¡ahora es tu oportunidad!<br><br><br><br>Buscamos a un nuevo/a compañero/a para sumarse a nuestro equipo de IT como Becario/a.<br><br><br><br>¿Cómo sería tu día a día en Burger King ®?- Apoyar en la construcción y optimización de procesos ETL.<br><br>- Participar en la creación de dashboards para facilitar la toma de decisiones.<br><br>- Asegurar la calidad y la integridad de los datos.<br><br>¿Cómo es ser parte de nuestro equipo?<br><br><br><br>- Formar parte de la compañía líder de restauración organizada de nuestro país es tener un crecimiento constante.<br><br>- Entorno de trabajo colaborativo en el que tus ideas serán valoradas y que servirán para aportar valor<br><br>- Modalidad de trabajo: Presencial<br><br>- Ayuda al estudio de 600 por jornada completa<br><br>- Ubicación: Pozuelo de Alarcón<br><br>- Horario: 8:30 a 18:00 con jornada intensiva los viernes y los meses de julio y agosto.<br><br><br><br>Si eres un auténtico fan del Whopper® y quieres formar parte de un proyecto laboral retador, ¡no dudes más y envíanos tu solicitud!<br><br><br><br>¡Conviértete en un auténtico King!<br>Referencia<br>388465932<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Departamento<br>Informática<br>Nivel<br>Becario/a - Prácticas<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>177 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "No Requerida",
            "porcentaje": "60",
            "skills_necesarias": [
                "SQL",
                "Python",
                "SSIS",
                "Data Factory",
                "Pentaho"
            ],
            "skills_valoradas": [
                "Power BI",
                "Tableau"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "DATA ENGINEER - Inglés avanzado (M/H/X)",
        "empresa": "Experis IT",
        "fecha_publicacion": "Publicada el 16 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-ingles-avanzado-m-h-x/of-i949838adb1466ca69ccde47cdc44b8?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nFormación Profesional Grado Superior\nExperiencia mínima\nAl menos 2 años\nImprescindible residente en\nEspaña\nRequisitos mínimos\nVer descripción\nDescripción\nSeleccionamos para incorporar en la plantilla de uno de nuestros clientes, un perfil de DATA ENGINEER con al menos 3 años de experiencia, para formar parte de un servicio ubicado en Madrid de alcance internacional.\n\nRESPONSABILIDADES:\n\n- Ayudar a crear la arquitectura, los pipelines y el modelo de datos adecuados que servirán los datos finales a los usuarios negocio/analistas de los clientes. Funciones concretas:\n\n• Exponer datos de diferentes sistemas\n\n• Trabajar con tecnologías multicloud (principalmente sobre Azure) punteras como Databricks, ADF, Synapse, Apache Airflow, Redshift, Kubernetes, MongoDB, entre otras y utilizando Python como lenguaje de programación principal.\n\n• Desarrollar, mantener y optimizar pipelines de datos de alta calidad, fiables y robustos que conviertan los flujos de datos en un valor añadido para nuestros clientes.\n\n• Modelar y arquitecturar la infraestructura de datos construyendo soluciones de streaming (tiempo real) y procesamiento por batches.\n\n• Diseñar y desplegar microservicios para el desarrollo y productivización de modelos de Machine Learning y herramientas de datos.\n\n• Creación y mantenimiento de procesos ETL y ELT. • Garantizar que la solución de cloud big data puede escalar para satisfacer las crecientes necesidades de datos de nuestros clientes.\n\n• Garantizar que la solución de cloud big data es segura y cumple las normativas y estándares pertinentes\n\n\n\nREQUISITOS:\n\n- Al menos 2 / 3 años de experiencia en un rol similar\n\n- Sql\n\n- Spark\n\n- Python\n\n- Conocimientos en soluciones cloud (preferiblemente AWS y/o Azure)\n\n- Inglés avanzado\n\n\n\nEn Experis, compañía de ManpowerGroup, trabajamos seleccionando el mejor Talento tecnológico para conectarlo con todo tipo de organizaciones, desde grandes corporaciones hasta start-ups.\n\nSomos una compañía especializada en consultoría IT y en selección de profesionales del sector Tecnológico asociados a nuestras 3 prácticas: Business Transformation, Cloud & Infrastructure y Enterprise Applications.\n\nContamos con una plantilla de más de 1.800 profesionales especializados en IT en España y presencia internacional en 54 países.\n\nSi eres un profesional del área de la Tecnología, nos gustaría ayudarte a encontrar esa nueva oportunidad que estás buscando, la que te impulse a dar el salto en tu carrera profesional.\n\n?Encuentra tu próxima oportunidad con nosotros. ¡Pasa al siguiente nivel con Experis!\nReferencia\n605391\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEspecialista\nNúmero de vacantes\n1\nSalario\nMás de 45.000€\n46 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Formación Profesional Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Imprescindible residente en<br>España<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>Ver descripción<br><br><h3>Descripción</h3><br>Seleccionamos para incorporar en la plantilla de uno de nuestros clientes, un perfil de DATA ENGINEER con al menos 3 años de experiencia, para formar parte de un servicio ubicado en Madrid de alcance internacional.<br><br>RESPONSABILIDADES:<br><br>- Ayudar a crear la arquitectura, los pipelines y el modelo de datos adecuados que servirán los datos finales a los usuarios negocio/analistas de los clientes. Funciones concretas:<br><br>• Exponer datos de diferentes sistemas<br><br>• Trabajar con tecnologías multicloud (principalmente sobre Azure) punteras como Databricks, ADF, Synapse, Apache Airflow, Redshift, Kubernetes, MongoDB, entre otras y utilizando Python como lenguaje de programación principal.<br><br>• Desarrollar, mantener y optimizar pipelines de datos de alta calidad, fiables y robustos que conviertan los flujos de datos en un valor añadido para nuestros clientes.<br><br>• Modelar y arquitecturar la infraestructura de datos construyendo soluciones de streaming (tiempo real) y procesamiento por batches.<br><br>• Diseñar y desplegar microservicios para el desarrollo y productivización de modelos de Machine Learning y herramientas de datos.<br><br>• Creación y mantenimiento de procesos ETL y ELT. • Garantizar que la solución de cloud big data puede escalar para satisfacer las crecientes necesidades de datos de nuestros clientes.<br><br>• Garantizar que la solución de cloud big data es segura y cumple las normativas y estándares pertinentes<br><br><br><br>REQUISITOS:<br><br>- Al menos 2 / 3 años de experiencia en un rol similar<br><br>- Sql<br><br>- Spark<br><br>- Python<br><br>- Conocimientos en soluciones cloud (preferiblemente AWS y/o Azure)<br><br>- Inglés avanzado<br><br><br><br>En Experis, compañía de ManpowerGroup, trabajamos seleccionando el mejor Talento tecnológico para conectarlo con todo tipo de organizaciones, desde grandes corporaciones hasta start-ups.<br><br>Somos una compañía especializada en consultoría IT y en selección de profesionales del sector Tecnológico asociados a nuestras 3 prácticas: Business Transformation, Cloud & Infrastructure y Enterprise Applications.<br><br>Contamos con una plantilla de más de 1.800 profesionales especializados en IT en España y presencia internacional en 54 países.<br><br>Si eres un profesional del área de la Tecnología, nos gustaría ayudarte a encontrar esa nueva oportunidad que estás buscando, la que te impulse a dar el salto en tu carrera profesional.<br><br>?Encuentra tu próxima oportunidad con nosotros. ¡Pasa al siguiente nivel con Experis!<br>Referencia<br>605391<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Especialista<br>Número de vacantes<br>1<br>Salario<br>Más de 45.000€<br>46 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "3",
            "porcentaje": "85",
            "skills_necesarias": [
                "SQL",
                "PySpark",
                "Python",
                "Azure",
                "Databricks",
                "Airflow",
                "Redshift",
                "NoSQL",
                "ETL"
            ],
            "skills_valoradas": [
                "AWS",
                "Microservicios",
                "Machine Learning"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Engineer Google Cloud Data / 100% Teletrabajo",
        "empresa": "AARON FORMACIÓN Y CONSULTORÍA",
        "fecha_publicacion": "Publicada el 15 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/engineer-google-cloud-data-100-teletrabajo/of-i9fbfa6caee4dd1bcf13e3b15805cfe?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior\nExperiencia mínima\nAl menos 2 años\nImprescindible residente en\nNo Requerido\nIdiomas requeridos\nInglés - Nivel Intermedio\nConocimientos necesarios\nSQL\nPython\nSQL Server\nIndustrial\nDescripción\nBuscamos un Senior Data Engineer Cloud GCP para un proyecto en el sector industrial. La persona seleccionada se incorporará a un equipo que trabaja con tecnologías punteras en entornos cloud, con posibilidad de teletrabajo.\nRequisitos del puesto:\n- Experiencia mínima de 2 años trabajando en entornos cloud GCP, aplicando Best Practices.\n- Experiencia en el desarrollo de pipelines y transformaciones de datos (ETLs) con BigQuery.\n- Buen nivel de SQL y Python.\n- Se valorará experiencia con SQL Server y Talend para ingestas.\n- Nivel de inglés B2 mínimo.\nUbicación y modalidad de trabajo:\n- Lugar de residencia: Madrid, Barcelona, Zaragoza o Sevilla.\n- Modalidad: Teletrabajo con posibilidad de acudir a las oficinas si es necesario.\nSi cumples con los requisitos y te interesa participar en un proyecto de larga duración en el sector industrial, no dudes en enviarnos tu candidatura.\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Programación\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\nSeguro médico\nCheque restaurante\n5 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Imprescindible residente en<br>No Requerido<br>Idiomas requeridos<br>Inglés - Nivel Intermedio<br>Conocimientos necesarios<br>SQL<br>Python<br>SQL Server<br>Industrial<br><br><h3>Descripción</h3><br>Buscamos un Senior Data Engineer Cloud GCP para un proyecto en el sector industrial. La persona seleccionada se incorporará a un equipo que trabaja con tecnologías punteras en entornos cloud, con posibilidad de teletrabajo.<br><br><h3>Requisitos</h3> del puesto:<br>- <h4>Experiencia mínima</h4> de 2 años trabajando en entornos cloud GCP, aplicando Best Practices.<br>- Experiencia en el desarrollo de pipelines y transformaciones de datos (ETLs) con BigQuery.<br>- Buen nivel de SQL y Python.<br>- Se valorará experiencia con SQL Server y Talend para ingestas.<br>- Nivel de inglés B2 mínimo.<br>Ubicación y modalidad de trabajo:<br>- Lugar de residencia: Madrid, Barcelona, Zaragoza o Sevilla.<br>- Modalidad: Teletrabajo con posibilidad de acudir a las oficinas si es necesario.<br>Si cumples con los requisitos y te interesa participar en un proyecto de larga duración en el sector industrial, no dudes en enviarnos tu candidatura.<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Programación<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>Seguro médico<br>Cheque restaurante<br>5 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B2",
            "anios_experiencia": "2",
            "porcentaje": "80",
            "skills_necesarias": [
                "SQL",
                "Python",
                "GCP (Google Cloud Platform)",
                "ETL",
                "BigQuery"
            ],
            "skills_valoradas": [
                "SQL",
                "Talend"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer (Remoto)",
        "empresa": "ALVEA SOLUCIONES TECNOLOGICAS, S.L.",
        "fecha_publicacion": "Publicada el 15 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-remoto/of-ic1035373a84bb4863a7f258e084f3f?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Medio\nExperiencia mínima\nAl menos 2 años\nConocimientos necesarios\nSCALA\nApache Spark\nDescripción\nDesde Alvea Soluciones Tecnológicas, estamos en búsqueda de un/a Data Engineer para formar parte del equipo de Big Data. Este proyecto es del sector bancario y se trabajaria en remoto 100%.\nImprescindible:\n- De 1 a 3 años de experiencia como Data Engineer.\n- Experiencia imprescindible en Spark y Scala.\n- Deseable experiencia en AWS\n¿Qué te ofrecemos?\n- Salario flexible y motivador.\n- Contratación indefinida desde el inicio.\n- Estabilidad laboral en un entorno dinámico y en constante crecimiento.\n- Oportunidades de desarrollo profesional y aprendizaje continuo.\n- Ambiente de trabajo colaborativo y equipos altamente competentes\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\nSeguro médico\n86 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Medio<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Conocimientos necesarios<br>SCALA<br>Apache Spark<br><br><h3>Descripción</h3><br>Desde Alvea Soluciones Tecnológicas, estamos en búsqueda de un/a Data Engineer para formar parte del equipo de Big Data. Este proyecto es del sector bancario y se trabajaria en remoto 100%.<br>Imprescindible:<br>- De 1 a 3 años de experiencia como Data Engineer.<br>- Experiencia imprescindible en Spark y Scala.<br>- Deseable experiencia en AWS<br>¿Qué te ofrecemos?<br>- Salario flexible y motivador.<br>- Contratación indefinida desde el inicio.<br>- Estabilidad laboral en un entorno dinámico y en constante crecimiento.<br>- Oportunidades de desarrollo profesional y aprendizaje continuo.<br>- Ambiente de trabajo colaborativo y equipos altamente competentes<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>Seguro médico<br>86 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "2",
            "porcentaje": "70",
            "skills_necesarias": [
                "Scala",
                "Spark"
            ],
            "skills_valoradas": [
                "AWS"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer EOS Spain",
        "empresa": "EOS SPAIN SL",
        "fecha_publicacion": "Publicada el 14 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-eos-spain/of-i767324856a479fb53c3fe1d7096565?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nAl menos 3 años\nImprescindible residente en\nEspaña\nIdiomas requeridos\nInglés - Nivel Avanzado\nConocimientos necesarios\nPhyton\nSQL\nAWS\nGCP\nAzure\nRequisitos mínimos\nLicenciatura en Ciencias de la Computación, Ingeniería, Matemáticas o un campo relacionado.\nExperiencia previa en un rol de Data Engineer o similar.\nDescripción\nEn EOS queremos incorporar nuevo talento al área de Data & Valuations, para ello queremos incorporar un perfil de Data Engineer\nComo Data Engineer, tu misión será diseñar y desarrollar pipelines de datos robustos y escalables que garanticen la calidad, integridad y seguridad de la información dentro de la organización.\nSerás responsable de implementar y gestionar arquitecturas de almacenamiento de datos, optimizando bases de datos para un rendimiento óptimo y asegurando la disponibilidad y consistencia de los datos a través de procesos de ETL.\nColaborarás con científicos de datos y analistas para entender y satisfacer sus necesidades de datos, utilizando tus habilidades en programación, SQL y ecosistemas Cloud.\nTu capacidad para resolver problemas y comunicarte de manera efectiva será fundamental para el éxito de los proyectos y la mejora continua de nuestros procesos de manejo de datos.\n¿Cuáles serán tus funciones y responsabilidades?\n- Diseñar y desarrollar pipelines de datos robustos, escalables y eficientes.\n- Implementar y gestionar arquitecturas de almacenamiento de datos en la nube o en servidores locales.\n- Asegurar la calidad, integridad y seguridad de los datos a través de procesos de ETL (Extract, Transform, Load).\n- Colaborar con científicos de datos, analistas y otras partes interesadas para comprender y satisfacer las necesidades de datos.\n- Optimizar y mantener bases de datos para un rendimiento óptimo.\n- Implementar procedimientos de monitoreo y alerta para asegurar la disponibilidad y consistencia de los datos.\n¿Cuáles son las habilidades requeridas?\n- Dominio de lenguajes de programación como Python\n- Sólidos conocimientos en SQL y experiencia con bases de datos\nrelacionales y no relacionales.\n- Experiencia en ecosistemas Cloud (AWS, GCP o Azure),\npreferiblemente en AWS.\n- Conocimientos en técnicas de modelado de datos y diseño de\nbases de datos.\n- Capacidad para gestionar grandes volúmenes de datos y\noptimizar el rendimiento de procesamiento de datos.\n¿Qué te espera en EOS?\n- Plan de carrera y desarrollo profesional.\n- Entorno de trabajo internacional e innovador.\n- Equipo de trabajo colaborativo.\n- Formación continua.\n- Flexibilidad.\n- Posibilidad de teletrabajo.\nTipo de industria de la oferta\nServicios financieros\nCategoría\nFinanzas y banca - Bolsa, valores e inversión\nDepartamento\nData & Valuations\nNivel\nEmpleado/a\nPersonal a cargo\n0\nNúmero de vacantes\n1\nDuración del contrato\nEstable\nHorario\nLunes/Jueves de 9 a 18 y Viernes de 08:30 a 15:00\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n19 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Imprescindible residente en<br>España<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br>Conocimientos necesarios<br>Phyton<br>SQL<br>AWS<br>GCP<br>Azure<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>Licenciatura en Ciencias de la Computación, Ingeniería, Matemáticas o un campo relacionado.<br>Experiencia previa en un rol de Data Engineer o similar.<br><br><h3>Descripción</h3><br>En EOS queremos incorporar nuevo talento al área de Data & Valuations, para ello queremos incorporar un perfil de Data Engineer<br>Como Data Engineer, tu misión será diseñar y desarrollar pipelines de datos robustos y escalables que garanticen la calidad, integridad y seguridad de la información dentro de la organización.<br>Serás responsable de implementar y gestionar arquitecturas de almacenamiento de datos, optimizando bases de datos para un rendimiento óptimo y asegurando la disponibilidad y consistencia de los datos a través de procesos de ETL.<br>Colaborarás con científicos de datos y analistas para entender y satisfacer sus necesidades de datos, utilizando tus habilidades en programación, SQL y ecosistemas Cloud.<br>Tu capacidad para resolver problemas y comunicarte de manera efectiva será fundamental para el éxito de los proyectos y la mejora continua de nuestros procesos de manejo de datos.<br>¿Cuáles serán tus funciones y responsabilidades?<br>- Diseñar y desarrollar pipelines de datos robustos, escalables y eficientes.<br>- Implementar y gestionar arquitecturas de almacenamiento de datos en la nube o en servidores locales.<br>- Asegurar la calidad, integridad y seguridad de los datos a través de procesos de ETL (Extract, Transform, Load).<br>- Colaborar con científicos de datos, analistas y otras partes interesadas para comprender y satisfacer las necesidades de datos.<br>- Optimizar y mantener bases de datos para un rendimiento óptimo.<br>- Implementar procedimientos de monitoreo y alerta para asegurar la disponibilidad y consistencia de los datos.<br>¿Cuáles son las habilidades requeridas?<br>- Dominio de lenguajes de programación como Python<br>- Sólidos conocimientos en SQL y experiencia con bases de datos<br>relacionales y no relacionales.<br>- Experiencia en ecosistemas Cloud (AWS, GCP o Azure),<br>preferiblemente en AWS.<br>- Conocimientos en técnicas de modelado de datos y diseño de<br>bases de datos.<br>- Capacidad para gestionar grandes volúmenes de datos y<br>optimizar el rendimiento de procesamiento de datos.<br>¿Qué te espera en EOS?<br>- Plan de carrera y desarrollo profesional.<br>- Entorno de trabajo internacional e innovador.<br>- Equipo de trabajo colaborativo.<br>- Formación continua.<br>- Flexibilidad.<br>- Posibilidad de teletrabajo.<br>Tipo de industria de la oferta<br>Servicios financieros<br>Categoría<br>Finanzas y banca - Bolsa, valores e inversión<br>Departamento<br>Data & Valuations<br>Nivel<br>Empleado/a<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Duración del contrato<br>Estable<br>Horario<br>Lunes/Jueves de 9 a 18 y Viernes de 08:30 a 15:00<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>19 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "3",
            "porcentaje": "85",
            "skills_necesarias": [
                "Python",
                "SQL",
                "AWS",
                "GCP (Google Cloud Platform)",
                "Azure"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "INGENIERO/A DE DATOS CON EXPERIENCIA EN SCALA",
        "empresa": "ColaVoro",
        "fecha_publicacion": "Publicada el 13 de ene",
        "min_salario": "25.000€",
        "max_salario": "33.000€",
        "url_oferta": "https://www.infojobs.net/san-fernando-de-henares/ingeniero-datos-con-experiencia-scala/of-i309111c83b4838a595f6f23b5d2fab?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nAl menos 1 año\nConocimientos necesarios\nSCALA\nDatos\nApache Spark\nParquet\nRequisitos mínimos\n-Ingeniero/a informático, telecomunicaciones o similar, con alto background en programación y tratamiento de datos\n- Sólidos conocimientos de programación en Scala\n- Experiencia en el uso de Apache Spark para el procesamiento de datos\n- Familiaridad con el formato de almacenamiento de datos Parquet\n- Experiencia en el manejo de grandes volúmenes de datos y en la optimización de consultas\n- Nivel avanzado de Scala, Apache Spark y Java SE 11\n- Nivel de inglés medio\nDeseable experiencia con otras tecnologías de Big Data como Hadoop, Hive o Kafka.\nDeseable experiencia en la implementación de soluciones con microservicios.\n-\nDescripción\nPrecisamos Ingeniero/a de Datos para incorporarse en uno de nuestros clientes situado en San Fernando de Henares (Madrid). Trabajo 100% remoto.\nFunciones:\n- Escribir y mantener código eficiente y escalable en Scala.\n- Desarrollar soluciones de procesamiento de datos a gran escala utilizando Apache Spark.\n- Implementar y optimizar el almacenamiento de datos en formato Parquet.\n- Colaborar con equipos multidisciplinarios para integrar soluciones de datos.\n- Analizar y resolver problemas complejos relacionados con el procesamiento y almacenamiento de datos.\n- Diseño de arquitecturas para procesamiento de datos.\nSe Ofrece:\n- Puesto Estable (contrato indefinido a través de Colavoro)\n- Jornada Completa, de Lunes a Viernes\n- Trabajo 100% remoto\n- Salario acorde a la formación y experiencia aportada\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - ERP, CRM, Business Intelligence\nNivel\nEspecialista\nNúmero de vacantes\n1\nSalario\nSalario: 25.000€ - 33.000€ Bruto/año\nBeneficios sociales\nTeletrabajo\n7 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br>Conocimientos necesarios<br>SCALA<br>Datos<br>Apache Spark<br>Parquet<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>-Ingeniero/a informático, telecomunicaciones o similar, con alto background en programación y tratamiento de datos<br>- Sólidos conocimientos de programación en Scala<br>- Experiencia en el uso de Apache Spark para el procesamiento de datos<br>- Familiaridad con el formato de almacenamiento de datos Parquet<br>- Experiencia en el manejo de grandes volúmenes de datos y en la optimización de consultas<br>- Nivel avanzado de Scala, Apache Spark y Java SE 11<br>- Nivel de inglés medio<br>Deseable experiencia con otras tecnologías de Big Data como Hadoop, Hive o Kafka.<br>Deseable experiencia en la implementación de soluciones con microservicios.<br>-<br><br><h3>Descripción</h3><br>Precisamos Ingeniero/a de Datos para incorporarse en uno de nuestros clientes situado en San Fernando de Henares (Madrid). Trabajo 100% remoto.<br>Funciones:<br>- Escribir y mantener código eficiente y escalable en Scala.<br>- Desarrollar soluciones de procesamiento de datos a gran escala utilizando Apache Spark.<br>- Implementar y optimizar el almacenamiento de datos en formato Parquet.<br>- Colaborar con equipos multidisciplinarios para integrar soluciones de datos.<br>- Analizar y resolver problemas complejos relacionados con el procesamiento y almacenamiento de datos.<br>- Diseño de arquitecturas para procesamiento de datos.<br>Se Ofrece:<br>- Puesto Estable (contrato indefinido a través de Colavoro)<br>- Jornada Completa, de Lunes a Viernes<br>- Trabajo 100% remoto<br>- Salario acorde a la formación y experiencia aportada<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - ERP, CRM, Business Intelligence<br>Nivel<br>Especialista<br>Número de vacantes<br>1<br>Salario<br>Salario: 25.000€ - 33.000€ Bruto/año<br>Beneficios sociales<br>Teletrabajo<br>7 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B1",
            "anios_experiencia": "1",
            "porcentaje": "75",
            "skills_necesarias": [
                "Scala",
                "Spark",
                "Parquet"
            ],
            "skills_valoradas": [
                "Hadoop",
                "Hive",
                "Kafka",
                "Java",
                "Microservicios"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Ingeniero/a de datos",
        "empresa": "DIMATICA",
        "fecha_publicacion": "Publicada el 13 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/ingeniero-datos/of-i182ec664694cb69a2ac6dcbdafcd2e?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nSin estudios\nExperiencia mínima\nAl menos 4 años\nIdiomas requeridos\nEspañol - Nivel Nativo o Bilingüe\nConocimientos necesarios\nSnowflake\nDBT\nSQL\nGitHub\nBases de datos\nAplicaciones Web\nDescripción\nEn DIMÁTICA, empresa reconocida como Microsoft GOLD PARTNER, estamos especializados en soluciones de diseño, desarrollo y mantenimiento de software, en entornos multiplataforma.\nPromovemos activamente la igualdad de género, con oportunidades de crecimiento y buen ambiente laboral.\nActualmente estamos construyendo una plataforma de datos innovadora desde cero y buscamos un Ingeniero de Datos que lidere este desafío tecnológico.\nLo que harás:\n-Diseñar y desarrollar una plataforma integral de datos basada en Snowflake.\n-Automatizar transformaciones de datos con DBT, asegurando flujos eficientes y escalables.\n-Migrar datos desde ecosistemas antiguos como SAP y Firebase a la nueva plataforma.\n-Crear cuadros de mando y data marts accesibles en herramientas como Power BI.\n-Colaborar con equipos multidisciplinarios (Marketing, Finanzas, Logística, RRHH).\n-Desarrollar aplicaciones web dinámicas que consuman datos procesados.\n-Gestionar código y versiones con GitHub para una colaboración fluida.\nLo que buscamos en ti:\n-Experiencia sólida en Snowflake: diseño, implementación y optimización.\n-Dominio de DBT para automatización de flujos de datos.\n-Conocimientos avanzados en SQL y optimización de consultas.\n-Experiencia en soluciones de visualización de datos como Power BI.\n-Familiaridad con GitHub y buenas prácticas de control de versiones.\n-Capacidad para desarrollar aplicaciones web conectadas a bases de datos.\n-Habilidad para trabajar en equipo y comunicar conceptos técnicos a públicos no técnicos.\n-Experiencia previa en migraciones de datos (SAP/Firebase a Snowflake) es un plus.\nUbicación y modelo de trabajo:\n-Híbrido: 3 días en oficina, 2 días en casa.\n-Sede: Zona O'Donnell (Calle Doctor Esquerdo).\nLo que ofrecemos:\nParticipar en un proyecto estratégico desde su fase inicial.\nTrabajo dinámico con equipos multidisciplinarios.\nEntorno que fomenta la innovación y el crecimiento profesional.\nReferencia\nAHE\nTipo de industria de la oferta\nDesarrollo de programación\nCategoría\nCompras, logística y almacén - Distribución y logística\nNivel\nEmpleado/a\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n12 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Sin estudios<br><h4>Experiencia mínima</h4><br>Al menos 4 años<br>Idiomas requeridos<br>Español - Nivel Nativo o Bilingüe<br>Conocimientos necesarios<br>Snowflake<br>DBT<br>SQL<br>GitHub<br>Bases de datos<br>Aplicaciones Web<br><br><h3>Descripción</h3><br>En DIMÁTICA, empresa reconocida como Microsoft GOLD PARTNER, estamos especializados en soluciones de diseño, desarrollo y mantenimiento de software, en entornos multiplataforma.<br>Promovemos activamente la igualdad de género, con oportunidades de crecimiento y buen ambiente laboral.<br>Actualmente estamos construyendo una plataforma de datos innovadora desde cero y buscamos un Ingeniero de Datos que lidere este desafío tecnológico.<br>Lo que harás:<br>-Diseñar y desarrollar una plataforma integral de datos basada en Snowflake.<br>-Automatizar transformaciones de datos con DBT, asegurando flujos eficientes y escalables.<br>-Migrar datos desde ecosistemas antiguos como SAP y Firebase a la nueva plataforma.<br>-Crear cuadros de mando y data marts accesibles en herramientas como Power BI.<br>-Colaborar con equipos multidisciplinarios (Marketing, Finanzas, Logística, RRHH).<br>-Desarrollar aplicaciones web dinámicas que consuman datos procesados.<br>-Gestionar código y versiones con GitHub para una colaboración fluida.<br>Lo que buscamos en ti:<br>-Experiencia sólida en Snowflake: diseño, implementación y optimización.<br>-Dominio de DBT para automatización de flujos de datos.<br>-Conocimientos avanzados en SQL y optimización de consultas.<br>-Experiencia en soluciones de visualización de datos como Power BI.<br>-Familiaridad con GitHub y buenas prácticas de control de versiones.<br>-Capacidad para desarrollar aplicaciones web conectadas a bases de datos.<br>-Habilidad para trabajar en equipo y comunicar conceptos técnicos a públicos no técnicos.<br>-Experiencia previa en migraciones de datos (SAP/Firebase a Snowflake) es un plus.<br>Ubicación y modelo de trabajo:<br>-Híbrido: 3 días en oficina, 2 días en casa.<br>-Sede: Zona O'Donnell (Calle Doctor Esquerdo).<br>Lo que ofrecemos:<br>Participar en un proyecto estratégico desde su fase inicial.<br>Trabajo dinámico con equipos multidisciplinarios.<br>Entorno que fomenta la innovación y el crecimiento profesional.<br>Referencia<br>AHE<br>Tipo de industria de la oferta<br>Desarrollo de programación<br>Categoría<br>Compras, logística y almacén - Distribución y logística<br>Nivel<br>Empleado/a<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>12 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "4",
            "porcentaje": "80",
            "skills_necesarias": [
                "Snowflake",
                "DBT (Data Build Tool)",
                "SQL",
                "Git",
                "Power BI"
            ],
            "skills_valoradas": [
                "Snowflake",
                "Desarrollo de aplicaciones web"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "46910 - Técnicos/as especialistas en análisis de datos - Seguimiento de hábitat (Madrid)",
        "empresa": "GRUPO TRAGSA",
        "fecha_publicacion": "Publicada el 09 de ene",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/46910-tecnicos-especialistas-analisis-datos-seguimiento-habitat-madrid/of-ifffb5fb9d746008b58e733c2318d20?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nMáster\nExperiencia mínima\nAl menos 1 año\nRequisitos mínimos\nFunciones:\n· Extracción, procesado y análisis de datos ecológicos, biológicos, ambientales y cartográficos.\n· Orientación y mejora sobre las metodologías y herramientas de programación a emplear para el procesado y análisis de datos.\n· Generación de información utilizando técnicas estadísticas y/o modelos de aprendizaje automáticos.\n· Administración de grandes bases de datos.\n· Generación y edición de gráficos complejos.\n· Apoyo en campo en la toma y gestión de datos empleando dispositivos móviles.\n· Preparación y redacción de informes sobre el seguimiento y evaluación del estado de conservación de los tipos de hábitats de interés comunitario.\n· Comunicación de avances y resultados de forma periódica al resto del equipo de trabajo.\nRequisitos:\nFormación\nTitulación\n· Poseer la titulación de Licenciatura, Ingeniería, Grado + Máster Oficial, Ingeniería Técnica, Diplomatura o Grado en alguna de las siguientes especialidades: Ciencias Ambientales, Ingeniería Informática, Matemáticas, Ingeniería del Software, Informática, Ingeniería de Montes, Biología, Ingeniería Forestal y del Medio Natural, Ingeniería Técnica Forestal o Ciencias del Mar (Titulación homologada en España)\nFormación Complementaria\n· Asignaturas o cursos de especialización relacionados con el seguimiento y la conservación de tipos de hábitat/ecosistemas: análisis de biodiversidad de ecosistemas, evaluación ambiental de ecosistemas, gestión sostenible del medio natural, biología de la conservación, etc.\nIdiomas\n· Inglés, Nivel Mínimo B2 (el nivel será verificado durante el transcurso del proceso de Selección).\nExperiencia Previa\n· Al menos 1 año de experiencia en la extracción y procesado de datos ecológicos, biológicos, ambientales y cartográficos empleando R, Python o similar.\n· Al menos 1 año de experiencia en el análisis y generación de gráficos complejos empleando R, Python o similar.\n· Al menos 1 año de experiencia en la administración y gestión de grandes bases de datos de origen ecológico, biológico, y cartográfico empleando lenguaje SQL o similar.\nOtros Requisitos Imprescindibles\n· Carnet de conducir B y disponibilidad para conducir\n· Experiencia mínima de 6 meses en conducción\nMéritos:\nFormación Complementaria\n· Máster, curso de postgrado o programas de más de 100 horas de duración relacionado con la gestión, seguimiento, conservación de tipos de hábitat y/o ecosistemas terrestres.\nOtros Factores Meritorios\n· Experiencia demostrable superior a 12 meses en extracción, procesado y análisis de datos ecológicos, biológicos, ambientales y cartográficos empleando R, Python o similar\n· Experiencia demostrable superior a 12 meses en la administración y gestión de grandes bases de datos de origen ecológico, biológico, y cartográfico empleando lenguaje SQL o similar\n· Experiencia demostrable en el uso de herramientas SIG, enfocadas a la gestión y análisis de bases de datos georreferenciados en publicaciones científicas y/o informes técnicos\n· Experiencia demostrable superior a 6 meses en la obtención de datos de origen biótico y abiótico en campañas de campo\n· Cursos de especialización relacionados con el manejo y análisis de datos ambientales y/o cartográficos en R, Phyton, ArcGIS, QGIS o similar\n· Nivel avanzado de Excel y Word\nDescripción\nTecnologías y Servicios Agrarios, S.A., S.M.E., M.P., empresa filial del GRUPO TRAGSA, especializada en la realización de actividades de ingeniería, consultoría y asistencia técnica en materias agrícolas, ganadería, forestal y medioambiental, busca incorporar 2 Técnicos/as especialistas en análisis de datos para el seguimiento de hábitat terrestres y la mejora del conocimiento del estado de conservación.\n*SOLO SE TENDRÁN EN CUENTA AQUELLAS CANDIDATURAS INSCRITAS A TRAVÉS DE LA PÁGINA WEG DEL GRUPO TRAGSA: https://www.tragsa.es/_layouts/15/GrupoTragsa/ficha-oferta-empleo.aspx?tipo=FTG&jobid=46910*\nSe ofrece:\n- Contrato de duración determinada de 6 meses aproximadamente, con opción de prórroga si procede y respetando los límites de duración máxima establecidos en la legislación laboral vigente para cada modalidad contractual. La tipología y duración del contrato será en función de la causa de la contratación, del proyecto y de las circunstancias de la/s persona/as seleccionada/s.\n- Jornada completa: siendo necesario trabajo en fin de semana puntualmente.\nSe formalizará la contratación atendiendo a la mayor titulación oficial acreditada y homologada aportada por la persona seleccionada de las indicadas en la oferta.\nEl plazo de recepción de candidaturas estará abierto desde hoy día 09/01/2025 hasta el próximo 23/01/2025 a las 23:59 h.\nPara poder participar en este proceso de selección será necesario adjuntar como anexo a la solicitud, o bien durante el trascurso del proceso de selección, la documentación acreditativa del cumplimiento de los requisitos de formación académica detallados en la oferta. La incorrecta acreditación de los documentos solicitados o la falsedad en lo indicado, supondrá la exclusión inmediata del proceso.\nEn caso de títulos obtenidos en universidades y/o centros extranjeros, se requiere que el mismo esté homologado en España debiendo adjuntar como Anexo a la solicitud la correspondiente documentación justificativa.\nEstar en posesión de la documentación acreditativa suficiente para poder formalizar un contrato de trabajo en España: Permiso de residencia y trabajo en vigor.\nLa inscripción y presentación de su solicitud de empleo supone la declaración responsable del cumplimiento de los requisitos recogidos en la misma, así como la veracidad de sus respuestas a las preguntas de filtrado o killer questions, que respondan en relación a la misma, pudiendo ser rechazados en caso de que se compruebe su incumplimiento o falta de veracidad.\nCon el objeto de dar cumplimiento al II Plan de Igualdad de la empresa para alcanzar una presencia equilibrada de mujeres y hombres en todos los niveles, áreas y ocupaciones donde exista desequilibrio, a igualdad de méritos y capacidades, se articulará la preferencia de contratación de la persona del sexo infrarrepresentado en el puesto. Se entiende por infrarrepresentación un porcentaje igual o menor al 40% en el ámbito de la empresa en el puesto ofertado\nCon el objeto de dar cumplimiento de la Norma RRH.09 para el Fomento de la incorporación de personas con discapacidad en el Grupo Tragsa, a igualdad de condiciones, se priorizarán las candidaturas de aquellas personas que cuenten con una discapacidad reconocida y acreditada igual o superior al 33%, siempre y cuando la discapacidad sea compatible con el adecuado desempeño del puesto.\nSi la persona que resulte seleccionada en este proceso mantiene una relación laboral vigente en la empresa, la suscripción del nuevo contrato conlleva la inexistencia de reserva de su actual puesto de trabajo, debiendo realizar previamente, los trámites legales oportunos.\nCualquier contratación temporal resultante de este proceso de selección garantizará por parte del Grupo Tragsa la operatividad y el mantenimiento de los proyectos/servicios, así como, el cumplimiento de la normativa interna y la legislación laboral vigente.\nEn caso de surgir bajas, se podrá contactar a los/as candidatos/as para ofrecer u\nTipo de industria de la oferta\nAgricultura, ganadería y pesca\nCategoría\nAdministración Pública - Empresas públicas\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\n9 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Máster<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>Funciones:<br>· Extracción, procesado y análisis de datos ecológicos, biológicos, ambientales y cartográficos.<br>· Orientación y mejora sobre las metodologías y herramientas de programación a emplear para el procesado y análisis de datos.<br>· Generación de información utilizando técnicas estadísticas y/o modelos de aprendizaje automáticos.<br>· Administración de grandes bases de datos.<br>· Generación y edición de gráficos complejos.<br>· Apoyo en campo en la toma y gestión de datos empleando dispositivos móviles.<br>· Preparación y redacción de informes sobre el seguimiento y evaluación del estado de conservación de los tipos de hábitats de interés comunitario.<br>· Comunicación de avances y resultados de forma periódica al resto del equipo de trabajo.<br><br><h3>Requisitos</h3>:<br>Formación<br>Titulación<br>· Poseer la titulación de Licenciatura, Ingeniería, Grado + Máster Oficial, Ingeniería Técnica, Diplomatura o Grado en alguna de las siguientes especialidades: Ciencias Ambientales, Ingeniería Informática, Matemáticas, Ingeniería del Software, Informática, Ingeniería de Montes, Biología, Ingeniería Forestal y del Medio Natural, Ingeniería Técnica Forestal o Ciencias del Mar (Titulación homologada en España)<br>Formación Complementaria<br>· Asignaturas o cursos de especialización relacionados con el seguimiento y la conservación de tipos de hábitat/ecosistemas: análisis de biodiversidad de ecosistemas, evaluación ambiental de ecosistemas, gestión sostenible del medio natural, biología de la conservación, etc.<br>Idiomas<br>· Inglés, Nivel Mínimo B2 (el nivel será verificado durante el transcurso del proceso de Selección).<br>Experiencia Previa<br>· Al menos 1 año de experiencia en la extracción y procesado de datos ecológicos, biológicos, ambientales y cartográficos empleando R, Python o similar.<br>· Al menos 1 año de experiencia en el análisis y generación de gráficos complejos empleando R, Python o similar.<br>· Al menos 1 año de experiencia en la administración y gestión de grandes bases de datos de origen ecológico, biológico, y cartográfico empleando lenguaje SQL o similar.<br>Otros <br><h3>Requisitos</h3> Imprescindibles<br>· Carnet de conducir B y disponibilidad para conducir<br>· <h4>Experiencia mínima</h4> de 6 meses en conducción<br>Méritos:<br>Formación Complementaria<br>· Máster, curso de postgrado o programas de más de 100 horas de duración relacionado con la gestión, seguimiento, conservación de tipos de hábitat y/o ecosistemas terrestres.<br>Otros Factores Meritorios<br>· Experiencia demostrable superior a 12 meses en extracción, procesado y análisis de datos ecológicos, biológicos, ambientales y cartográficos empleando R, Python o similar<br>· Experiencia demostrable superior a 12 meses en la administración y gestión de grandes bases de datos de origen ecológico, biológico, y cartográfico empleando lenguaje SQL o similar<br>· Experiencia demostrable en el uso de herramientas SIG, enfocadas a la gestión y análisis de bases de datos georreferenciados en publicaciones científicas y/o informes técnicos<br>· Experiencia demostrable superior a 6 meses en la obtención de datos de origen biótico y abiótico en campañas de campo<br>· Cursos de especialización relacionados con el manejo y análisis de datos ambientales y/o cartográficos en R, Phyton, ArcGIS, QGIS o similar<br>· Nivel avanzado de Excel y Word<br><br><h3>Descripción</h3><br>Tecnologías y Servicios Agrarios, S.A., S.M.E., M.P., empresa filial del GRUPO TRAGSA, especializada en la realización de actividades de ingeniería, consultoría y asistencia técnica en materias agrícolas, ganadería, forestal y medioambiental, busca incorporar 2 Técnicos/as especialistas en análisis de datos para el seguimiento de hábitat terrestres y la mejora del conocimiento del estado de conservación.<br>*SOLO SE TENDRÁN EN CUENTA AQUELLAS CANDIDATURAS INSCRITAS A TRAVÉS DE LA PÁGINA WEG DEL GRUPO TRAGSA: https://www.tragsa.es/_layouts/15/GrupoTragsa/ficha-oferta-empleo.aspx?tipo=FTG&jobid=46910*<br>Se ofrece:<br>- Contrato de duración determinada de 6 meses aproximadamente, con opción de prórroga si procede y respetando los límites de duración máxima establecidos en la legislación laboral vigente para cada modalidad contractual. La tipología y duración del contrato será en función de la causa de la contratación, del proyecto y de las circunstancias de la/s persona/as seleccionada/s.<br>- Jornada completa: siendo necesario trabajo en fin de semana puntualmente.<br>Se formalizará la contratación atendiendo a la mayor titulación oficial acreditada y homologada aportada por la persona seleccionada de las indicadas en la oferta.<br>El plazo de recepción de candidaturas estará abierto desde hoy día 09/01/2025 hasta el próximo 23/01/2025 a las 23:59 h.<br>Para poder participar en este proceso de selección será necesario adjuntar como anexo a la solicitud, o bien durante el trascurso del proceso de selección, la documentación acreditativa del cumplimiento de los requisitos de formación académica detallados en la oferta. La incorrecta acreditación de los documentos solicitados o la falsedad en lo indicado, supondrá la exclusión inmediata del proceso.<br>En caso de títulos obtenidos en universidades y/o centros extranjeros, se requiere que el mismo esté homologado en España debiendo adjuntar como Anexo a la solicitud la correspondiente documentación justificativa.<br>Estar en posesión de la documentación acreditativa suficiente para poder formalizar un contrato de trabajo en España: Permiso de residencia y trabajo en vigor.<br>La inscripción y presentación de su solicitud de empleo supone la declaración responsable del cumplimiento de los requisitos recogidos en la misma, así como la veracidad de sus respuestas a las preguntas de filtrado o killer questions, que respondan en relación a la misma, pudiendo ser rechazados en caso de que se compruebe su incumplimiento o falta de veracidad.<br>Con el objeto de dar cumplimiento al II Plan de Igualdad de la empresa para alcanzar una presencia equilibrada de mujeres y hombres en todos los niveles, áreas y ocupaciones donde exista desequilibrio, a igualdad de méritos y capacidades, se articulará la preferencia de contratación de la persona del sexo infrarrepresentado en el puesto. Se entiende por infrarrepresentación un porcentaje igual o menor al 40% en el ámbito de la empresa en el puesto ofertado<br>Con el objeto de dar cumplimiento de la Norma RRH.09 para el Fomento de la incorporación de personas con discapacidad en el Grupo Tragsa, a igualdad de condiciones, se priorizarán las candidaturas de aquellas personas que cuenten con una discapacidad reconocida y acreditada igual o superior al 33%, siempre y cuando la discapacidad sea compatible con el adecuado desempeño del puesto.<br>Si la persona que resulte seleccionada en este proceso mantiene una relación laboral vigente en la empresa, la suscripción del nuevo contrato conlleva la inexistencia de reserva de su actual puesto de trabajo, debiendo realizar previamente, los trámites legales oportunos.<br>Cualquier contratación temporal resultante de este proceso de selección garantizará por parte del Grupo Tragsa la operatividad y el mantenimiento de los proyectos/servicios, así como, el cumplimiento de la normativa interna y la legislación laboral vigente.<br>En caso de surgir bajas, se podrá contactar a los/as candidatos/as para ofrecer u<br>Tipo de industria de la oferta<br>Agricultura, ganadería y pesca<br>Categoría<br>Administración Pública - Empresas públicas<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>9 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "B2",
            "anios_experiencia": "1",
            "porcentaje": "70",
            "skills_necesarias": [
                "R",
                "Python",
                "SQL",
                "Bases de datos",
                "Análisis de datos",
                "Generación de gráficos"
            ],
            "skills_valoradas": [
                "Excel",
                "Word",
                "Herramientas SIG",
                "ArcGIS",
                "QGIS"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Especialista Análisis de Datos (Madrid) (12212)",
        "empresa": "Naturgy",
        "fecha_publicacion": "Publicada el 26 de dic",
        "min_salario": "30.000€",
        "max_salario": "33.000€",
        "url_oferta": "https://www.infojobs.net/madrid/especialista-analisis-datos-madrid-12212/of-id614dc6c8b4ada91c91c1d8fb729d0?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nNo Requerida\nImprescindible residente en\nEspaña\nIdiomas requeridos\nInglés - Nivel Avanzado\nConocimientos necesarios\nPython y SQL\nMicrosoft Office\nAnálisis de datos\nRequisitos mínimos\nTitulación: Licenciatura ADE, Data Analytics, Investigación de Mercados o Ingeniería.\nIdiomas: Inglés (mínimo C1). Valorable un segundo idioma.\nConocimientos Específicos\nConocimiento del mercado energético retail (electricidad, gas, servicios).\nConocimiento avanzado en herramientas de análisis de datos.\nHabilidades avanzadas de programación con Python y SQL ( PL/SQL)\nManejo avanzado herramientas de MS Office.\nRequisitos deseados\nExperiencia mínima de 2 años en roles de análisis de datos (Data Analytics) en el sector energético.\nConocimiento de los entornos SAP.\nConocimiento de infraestructuras relacionadas con entorno AWS.\nDescripción\nLos retos de tu día a día estarán orientados a:\nDefinición, desarrollo e implantación de los modelos retributivos en los diferentes canales de venta, así como su seguimiento y análisis de desviaciones con respecto a presupuesto.\nSeguimiento plan comercial y fijación de objetivos por canal de venta y zona geográfica.\nSeguimiento del plan de compras de la Dirección de Ventas Residencial y Pymes, seguimiento de las propuestas de adjudicación a proveedores y gestión de pedidos de compras en base al presupuesto aprobado.\nAutomatización, digitalización, seguimiento y mantenimiento del cuadro de mando de Venta Residencial & Pymes para realizar el seguimiento y análisis del Plan Comercial, con visión 360 de la actividad de segmento, proporcionando al equipo comercial indicadores KPI´S que faciliten su gestión.\nSeguimiento de costes y control de presupuesto de Ventas Residencial y Pymes.\nGestión integral del proceso de certificación y facturación a proveedores, con monitorización continua de los procesos vigentes.\nDigitalización y automatización (en entorno AWS) de todos los procesos relacionados con la actividad.\nReferencia\n12212\nTipo de industria de la oferta\nPetróleo y energía\nCategoría\nInformática y telecomunicaciones - Administración de bases de datos\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario: 30.000€ - 33.000€ Bruto/año\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\nTeléfono móvil\nSeguro médico\nCheque restaurante\n64 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>No Requerida<br>Imprescindible residente en<br>España<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br>Conocimientos necesarios<br>Python y SQL<br>Microsoft Office<br>Análisis de datos<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>Titulación: Licenciatura ADE, Data Analytics, Investigación de Mercados o Ingeniería.<br>Idiomas: Inglés (mínimo C1). Valorable un segundo idioma.<br>Conocimientos Específicos<br>Conocimiento del mercado energético retail (electricidad, gas, servicios).<br>Conocimiento avanzado en herramientas de análisis de datos.<br>Habilidades avanzadas de programación con Python y SQL ( PL/SQL)<br>Manejo avanzado herramientas de MS Office.<br><br><h3>Requisitos</h3> deseados<br><h4>Experiencia mínima</h4> de 2 años en roles de análisis de datos (Data Analytics) en el sector energético.<br>Conocimiento de los entornos SAP.<br>Conocimiento de infraestructuras relacionadas con entorno AWS.<br><br><h3>Descripción</h3><br>Los retos de tu día a día estarán orientados a:<br>Definición, desarrollo e implantación de los modelos retributivos en los diferentes canales de venta, así como su seguimiento y análisis de desviaciones con respecto a presupuesto.<br>Seguimiento plan comercial y fijación de objetivos por canal de venta y zona geográfica.<br>Seguimiento del plan de compras de la Dirección de Ventas Residencial y Pymes, seguimiento de las propuestas de adjudicación a proveedores y gestión de pedidos de compras en base al presupuesto aprobado.<br>Automatización, digitalización, seguimiento y mantenimiento del cuadro de mando de Venta Residencial & Pymes para realizar el seguimiento y análisis del Plan Comercial, con visión 360 de la actividad de segmento, proporcionando al equipo comercial indicadores KPI´S que faciliten su gestión.<br>Seguimiento de costes y control de presupuesto de Ventas Residencial y Pymes.<br>Gestión integral del proceso de certificación y facturación a proveedores, con monitorización continua de los procesos vigentes.<br>Digitalización y automatización (en entorno AWS) de todos los procesos relacionados con la actividad.<br>Referencia<br>12212<br>Tipo de industria de la oferta<br>Petróleo y energía<br>Categoría<br>Informática y telecomunicaciones - Administración de bases de datos<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario: 30.000€ - 33.000€ Bruto/año<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>Teléfono móvil<br>Seguro médico<br>Cheque restaurante<br>64 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "2",
            "porcentaje": "75",
            "skills_necesarias": [
                "Python",
                "SQL",
                "Microsoft Office",
                "Análisis de datos"
            ],
            "skills_valoradas": [
                "SAP",
                "AWS"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer - remoto!",
        "empresa": "Grupo ICA",
        "fecha_publicacion": "Publicada el 17 de dic",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer-remoto/of-iae40939ed643e2a1dee9b1d2f49fb2?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nAl menos 2 años\nConocimientos necesarios\nLinux\nC++\nPython\nClearCase\nGit\nDescripción\nDesde ICA Informática y Comunicaciones Avanzadas nos encontramos en búsqueda de un/a Data Engineer con al menos 2 años de experiencia para trabajar en un proyecto estable con modalidad 100% remoto.\nEXPERIENCIA Y CONOCIMIENTOS:\n- Linux y bash scripting.\n- Procesamiento de datos con Python.\n- Diseño modelos de datos.\n- Destreza con bases de datos relacionales y no relacionales.\n- Analítica de datos usando Python\n- Analítica de datos usando herramientas de Business Intelligence como Power BI.\n- C++\n- ClearCase\n- Git\nOfrecemos:\n-Proyección profesional.\n-Horario: oficina.\n-Salario competitivo\n-Plan de Formación\n-Plan de Retribución flexible\n-Plan de Conciliación\n¿Quiénes Somos?\nI.C.A Informática y Comunicaciones Avanzadas S.L. somos una empresa líder en consultoría tecnológica con sede en Madrid y con una trayectoria de más de 40 años en el sector. Desde nuestra fundación en 1983, hemos evolucionado constantemente para ofrecer soluciones innovadoras y servicios de alta calidad en el ámbito de la tecnología.\nContamos con un equipo de más de 250 profesionales altamente capacitados y especializados en el desarrollo de software y la implementación de sistemas avanzados, brindando soluciones personalizadas a clientes de diversos sectores.\nEn I.C.A estamos comprometidos con la responsabilidad empresarial, y nos enorgullece haber obtenido la certificación como Empresa Familiarmente Responsable. Esta distinción refleja nuestro compromiso con el bienestar de nuestros empleados, promoviendo un equilibrio armonioso entre la vida laboral, personal y familiar.\n¡Únete a nuestro equipo!\nTipo de industria de la oferta\nProgramación, Consultoria y otras Activ. informaticas\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n90 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Conocimientos necesarios<br>Linux<br>C++<br>Python<br>ClearCase<br>Git<br><br><h3>Descripción</h3><br>Desde ICA Informática y Comunicaciones Avanzadas nos encontramos en búsqueda de un/a Data Engineer con al menos 2 años de experiencia para trabajar en un proyecto estable con modalidad 100% remoto.<br>EXPERIENCIA Y CONOCIMIENTOS:<br>- Linux y bash scripting.<br>- Procesamiento de datos con Python.<br>- Diseño modelos de datos.<br>- Destreza con bases de datos relacionales y no relacionales.<br>- Analítica de datos usando Python<br>- Analítica de datos usando herramientas de Business Intelligence como Power BI.<br>- C++<br>- ClearCase<br>- Git<br>Ofrecemos:<br>-Proyección profesional.<br>-Horario: oficina.<br>-Salario competitivo<br>-Plan de Formación<br>-Plan de Retribución flexible<br>-Plan de Conciliación<br>¿Quiénes Somos?<br>I.C.A Informática y Comunicaciones Avanzadas S.L. somos una empresa líder en consultoría tecnológica con sede en Madrid y con una trayectoria de más de 40 años en el sector. Desde nuestra fundación en 1983, hemos evolucionado constantemente para ofrecer soluciones innovadoras y servicios de alta calidad en el ámbito de la tecnología.<br>Contamos con un equipo de más de 250 profesionales altamente capacitados y especializados en el desarrollo de software y la implementación de sistemas avanzados, brindando soluciones personalizadas a clientes de diversos sectores.<br>En I.C.A estamos comprometidos con la responsabilidad empresarial, y nos enorgullece haber obtenido la certificación como Empresa Familiarmente Responsable. Esta distinción refleja nuestro compromiso con el bienestar de nuestros empleados, promoviendo un equilibrio armonioso entre la vida laboral, personal y familiar.<br>¡Únete a nuestro equipo!<br>Tipo de industria de la oferta<br>Programación, Consultoria y otras Activ. informaticas<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>90 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "2",
            "porcentaje": "75",
            "skills_necesarias": [
                "Linux",
                "Python",
                "C++",
                "ClearCase",
                "Git"
            ],
            "skills_valoradas": [
                "Bash",
                "Power BI"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Engineer",
        "empresa": "Optimissa, Capital Markets Consulting",
        "fecha_publicacion": "Publicada el 17 de dic",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-engineer/of-i2cf6e476e748e1abd9518b260bb762?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nAl menos 1 año\nConocimientos necesarios\nSQL\nUso de bases de datos\nDescripción\nEn OPTIMISSA tenemos claro que el éxito de nuestros proyectos se debe a las personas que forman nuestro equipo. Por eso, si tienes al menos 2 años de experiencia como Data Engineer nos comprometemos a impulsar tu talento, satisfacer tus expectativas laborales y hacerte sentir como en casa. ¿Quieres construir hoy el mundo de mañana? ¡Sigue leyendo!\n¿Qué buscamos?\nIngeniero de datos con al menos 1 año de experiencia\nExperiencia con un volumen grande de datos.\nExperiencia trabajando con SQL\nNivel avanzado de Ingles\n¿Qué podemos ofrecerte?\nFormar parte de una gran empresa competitiva y en continuo crecimiento.\nIntegración en un equipo de profesionales altamente cualificado, con un buen clima laboral, innovador y dinámico.\nFormación especializada y desarrollo profesional continuo.\nBeneficios sociales y plan de compensación flexible.\nRetribución competitiva.\nModalidad hibrida en Madrid\nSi crees que eres talento, ¡apúntate!\nReferencia\nMCO\nTipo de industria de la oferta\nBanca\nCategoría\nInformática y telecomunicaciones - Telecomunicaciones\nNivel\nEmpleado/a\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\nSeguro médico\nCheque restaurante\n40 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>Al menos 1 año<br>Conocimientos necesarios<br>SQL<br>Uso de bases de datos<br><br><h3>Descripción</h3><br>En OPTIMISSA tenemos claro que el éxito de nuestros proyectos se debe a las personas que forman nuestro equipo. Por eso, si tienes al menos 2 años de experiencia como Data Engineer nos comprometemos a impulsar tu talento, satisfacer tus expectativas laborales y hacerte sentir como en casa. ¿Quieres construir hoy el mundo de mañana? ¡Sigue leyendo!<br>¿Qué buscamos?<br>Ingeniero de datos con al menos 1 año de experiencia<br>Experiencia con un volumen grande de datos.<br>Experiencia trabajando con SQL<br>Nivel avanzado de Ingles<br>¿Qué podemos ofrecerte?<br>Formar parte de una gran empresa competitiva y en continuo crecimiento.<br>Integración en un equipo de profesionales altamente cualificado, con un buen clima laboral, innovador y dinámico.<br>Formación especializada y desarrollo profesional continuo.<br>Beneficios sociales y plan de compensación flexible.<br>Retribución competitiva.<br>Modalidad hibrida en Madrid<br>Si crees que eres talento, ¡apúntate!<br>Referencia<br>MCO<br>Tipo de industria de la oferta<br>Banca<br>Categoría<br>Informática y telecomunicaciones - Telecomunicaciones<br>Nivel<br>Empleado/a<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>Seguro médico<br>Cheque restaurante<br>40 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "1",
            "porcentaje": "70",
            "skills_necesarias": [
                "SQL",
                "Bases de datos"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "AZURE DATA ENGINEER",
        "empresa": "DEVOTEAM",
        "fecha_publicacion": "Publicada el 16 de dic",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/azure-data-engineer/of-i82a01b79304ad8947ede904ada616e?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=3&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nCiclo Formativo Grado Superior - Informática y Comunicaciones\nExperiencia mínima\nAl menos 3 años\nImprescindible residente en\nEspaña\nConocimientos necesarios\nInteligencia artificial\nazure\ndata engineer\ningeniero de datos\nRequisitos mínimos\nDebe tener al menos 3 años de experiencia con Azure Datafactory, Databricks,Synapse.\nDeseable conocimiento en Microsoft Fabric\nExperiencia en la creación de modelos y transformaciones de datos\nDescripción\nEn Devoteam buscamos ampliar el equipo de Data incorporando un AZURE DATA ENGINEER para el equipo de proyectos Microsoft.\nEs 100% teletrabajo pero únicamente para residentes en Territorio Español-\nHorario flexible.\nDebe tener al menos 3 años de experiencia con Azure Datafactory, Databricks,Synapse.\nDeseable conocimiento en Microsoft Fabric\nExperiencia en la creación de modelos y transformaciones de datos\nSe trabaja multicliente - Multiproyecto\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - ERP, CRM, Business Intelligence\nNivel\nEmpleado/a\nPersonal a cargo\n0\nNúmero de vacantes\n1\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n8 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Ciclo Formativo Grado Superior - Informática y Comunicaciones<br><h4>Experiencia mínima</h4><br>Al menos 3 años<br>Imprescindible residente en<br>España<br>Conocimientos necesarios<br>Inteligencia artificial<br>azure<br>data engineer<br>ingeniero de datos<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>Debe tener al menos 3 años de experiencia con Azure Datafactory, Databricks,Synapse.<br>Deseable conocimiento en Microsoft Fabric<br>Experiencia en la creación de modelos y transformaciones de datos<br><br><h3>Descripción</h3><br>En Devoteam buscamos ampliar el equipo de Data incorporando un AZURE DATA ENGINEER para el equipo de proyectos Microsoft.<br>Es 100% teletrabajo pero únicamente para residentes en Territorio Español-<br>Horario flexible.<br>Debe tener al menos 3 años de experiencia con Azure Datafactory, Databricks,Synapse.<br>Deseable conocimiento en Microsoft Fabric<br>Experiencia en la creación de modelos y transformaciones de datos<br>Se trabaja multicliente - Multiproyecto<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - ERP, CRM, Business Intelligence<br>Nivel<br>Empleado/a<br>Personal a cargo<br>0<br>Número de vacantes<br>1<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>8 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "3",
            "porcentaje": "75",
            "skills_necesarias": [
                "Azure",
                "Databricks",
                "Synapse",
                "Creación de modelos de datos",
                "Transformaciones de datos"
            ],
            "skills_valoradas": [
                "Microsoft Office",
                "IA"
            ]
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "Data Junior con francés",
        "empresa": "Sopra Steria - Programa Junior para Primer Empleo",
        "fecha_publicacion": "Publicada el 11 de dic",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/data-junior-con-frances/of-i7f97b263f8465abe0693d1cb4c22cb?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=4&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado\nExperiencia mínima\nNo Requerida\nIdiomas requeridos\nFrancés - Nivel Avanzado\nConocimientos necesarios\nFrancés\nJunior\nData\nInformatica\nMatemáticas\nSoftware\nRequisitos mínimos\n¿Buscas desarrollarte como data? No hace falta tener experiencia, pero nos gustaría que tuvieras, finalizada o a punto de finalizar, algunas de estas titulaciones:\n· Ingeniería Informática, Ciencia de Datos, Big Data, Telecomunicaciones, Industrial, Matemáticas, Física u otras ingenierías.\n· B2 Francés.\n¿Te gustan los retos? ¡Este es tu lugar!\n¡Únete a la experiencia Sopra Steria a través de nuestro programa TakeUp!\nDescripción\nPorque trabajar en Sopra Steria, también es sentir Sopra Steria.\nSomos un reconocido líder europeo en consultoría, servicios digitales y desarrollo de software, con cerca de 56.000 empleados en casi 30 países y más de 4.000 en España.\nNos enfocamos en las personas, en su formación y en su desarrollo profesional, lo que nos impulsa a crecer y mejorar constantemente.\nTenemos pasión por lo digital y al igual que tú, buscamos la mejor de las aventuras. Queremos que tu día a día se convierta en la mejor de tus inspiraciones. Que aprendas, aportes, te diviertas, crezcas y que, sobre todo, disfrutes al máximo.\nSi quieres formar parte de un equipo \"Great Place to Work\", ¡Sigue leyendo!\n¿Buscas tu primera experiencia en la que formarte y crecer en un entorno internacional?\n¿Te apasionan las nuevas tecnologías?\n¡Tenemos una misión para ti!\n· Ofrecemos formación inicial.\n· Formarás parte de un proyecto de entre los siguientes sectores: Banca y Seguros, Administración Pública, Transporte, Retail, Aeroline, Telecomunicaciones, Utilities y Energía.\nOfrecemos:\n· Contrato indefinido y jornada completa.\n· 23 días de vacaciones.\n· Formación continua: competencias técnicas, transversales y de idiomas. Contamos con acceso a certificaciones, formaciones de los principales Partners Tecnológicos, plataformas online y ¡mucho más!\n· Seguro de vida y de accidentes.\n· Posibilidad de acogerte a nuestra retribución flexible (seguro médico, cheques guarderías, transporte, comida y formación)\n· Acceso a Privilege Club, donde encontrarás descuentos interesantes en las principales marcas.\n· Onboarding personalizado y detallado. Te acompañamos en todo momento para que te sientas #soprano desde el primer momento.\n· Oficina con espacios reservados al ocio. ¡Trabajo y diversión unido!\n· Compañerismo y buen ambiente, el poder de la unión lo tenemos presente.\nY lo más importante...Tienes la posibilidad de desarrollar tu carrera profesional con nosotros: Crearemos juntos un plan de carrera personalizado. Te formarás, marcaremos objetivos y llevaremos a cabo un seguimiento para asegurarnos de que lo conseguimos juntos. Escuchamos tus prioridades y luchamos por ellas.\n¡Aquí tu voz importa! ¡Únete a nosotros y sé parte de algo más!\nThe world is how we shape it\nTipo de industria de la oferta\nServicios y tecnología de la información\nCategoría\nInformática y telecomunicaciones - Análisis\nNivel\nEmpleado/a\nNúmero de vacantes\n3\nSalario\nSalario no disponible\nBeneficios sociales\nFlexibilidad horaria\nTeletrabajo\nSeguro médico\nCheque restaurante\n31 inscritos a esta oferta para 3 vacantes\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado<br><h4>Experiencia mínima</h4><br>No Requerida<br>Idiomas requeridos<br>Francés - Nivel Avanzado<br>Conocimientos necesarios<br>Francés<br>Junior<br>Data<br>Informatica<br>Matemáticas<br>Software<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>¿Buscas desarrollarte como data? No hace falta tener experiencia, pero nos gustaría que tuvieras, finalizada o a punto de finalizar, algunas de estas titulaciones:<br>· Ingeniería Informática, Ciencia de Datos, Big Data, Telecomunicaciones, Industrial, Matemáticas, Física u otras ingenierías.<br>· B2 Francés.<br>¿Te gustan los retos? ¡Este es tu lugar!<br>¡Únete a la experiencia Sopra Steria a través de nuestro programa TakeUp!<br><br><h3>Descripción</h3><br>Porque trabajar en Sopra Steria, también es sentir Sopra Steria.<br>Somos un reconocido líder europeo en consultoría, servicios digitales y desarrollo de software, con cerca de 56.000 empleados en casi 30 países y más de 4.000 en España.<br>Nos enfocamos en las personas, en su formación y en su desarrollo profesional, lo que nos impulsa a crecer y mejorar constantemente.<br>Tenemos pasión por lo digital y al igual que tú, buscamos la mejor de las aventuras. Queremos que tu día a día se convierta en la mejor de tus inspiraciones. Que aprendas, aportes, te diviertas, crezcas y que, sobre todo, disfrutes al máximo.<br>Si quieres formar parte de un equipo \"Great Place to Work\", ¡Sigue leyendo!<br>¿Buscas tu primera experiencia en la que formarte y crecer en un entorno internacional?<br>¿Te apasionan las nuevas tecnologías?<br>¡Tenemos una misión para ti!<br>· Ofrecemos formación inicial.<br>· Formarás parte de un proyecto de entre los siguientes sectores: Banca y Seguros, Administración Pública, Transporte, Retail, Aeroline, Telecomunicaciones, Utilities y Energía.<br>Ofrecemos:<br>· Contrato indefinido y jornada completa.<br>· 23 días de vacaciones.<br>· Formación continua: competencias técnicas, transversales y de idiomas. Contamos con acceso a certificaciones, formaciones de los principales Partners Tecnológicos, plataformas online y ¡mucho más!<br>· Seguro de vida y de accidentes.<br>· Posibilidad de acogerte a nuestra retribución flexible (seguro médico, cheques guarderías, transporte, comida y formación)<br>· Acceso a Privilege Club, donde encontrarás descuentos interesantes en las principales marcas.<br>· Onboarding personalizado y detallado. Te acompañamos en todo momento para que te sientas #soprano desde el primer momento.<br>· Oficina con espacios reservados al ocio. ¡Trabajo y diversión unido!<br>· Compañerismo y buen ambiente, el poder de la unión lo tenemos presente.<br>Y lo más importante...Tienes la posibilidad de desarrollar tu carrera profesional con nosotros: Crearemos juntos un plan de carrera personalizado. Te formarás, marcaremos objetivos y llevaremos a cabo un seguimiento para asegurarnos de que lo conseguimos juntos. Escuchamos tus prioridades y luchamos por ellas.<br>¡Aquí tu voz importa! ¡Únete a nosotros y sé parte de algo más!<br>The world is how we shape it<br>Tipo de industria de la oferta<br>Servicios y tecnología de la información<br>Categoría<br>Informática y telecomunicaciones - Análisis<br>Nivel<br>Empleado/a<br>Número de vacantes<br>3<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Flexibilidad horaria<br>Teletrabajo<br>Seguro médico<br>Cheque restaurante<br>31 inscritos a esta oferta para 3 vacantes<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "No especificado",
            "anios_experiencia": "No Requerida",
            "porcentaje": "60",
            "skills_necesarias": [
                "Data",
                "Software"
            ],
            "skills_valoradas": []
        }
    },
    {
        "plataforma": "infojobs",
        "titulo_oferta": "IT Talent Acquisition inglés",
        "empresa": "LHH Recruitment Solutions",
        "fecha_publicacion": "Publicada el 15 de ene (Publicada de nuevo)",
        "min_salario": "No especificado",
        "max_salario": "No especificado",
        "url_oferta": "https://www.infojobs.net/madrid/it-talent-acquisition-ingles/of-i466d68718e44839c993f03e624cabf?applicationOrigin=search-new%7Celement%7E54064150242&searchId=54064150242&page=4&sortBy=RELEVANCE",
        "descripcion": "Requisitos\nEstudios mínimos\nGrado - Grado en Relaciones Laborales y Recursos Humanos\nExperiencia mínima\nAl menos 2 años\nImprescindible residente en\nProvincia Puesto Vacante\nIdiomas requeridos\nInglés - Nivel Avanzado\nConocimientos necesarios\nSelección de personal\nEntrevistas basadas en las competencias\nTécnicas de selección de personal\nFuentes de reclutamiento\nRequisitos mínimos\nExperiencia de al menos 2 años en selección de perfiles IT.\nImprescindible buen conocimiento del sector IT y sus Perfiles: Ciberseguridad, Data, Sistemas, Desarrollo, ...\nInglés: B2-C1\nDescripción\nSi te apasionan las personas, y si tu respuesta a las siguientes preguntas es afirmativa, ¡has encontrado tu sitio!.¿Tienes experiencia en reclutamiento y selección de personal del sector IT? ¿Estas habituado a realizar selección en inglés? ¿Estás buscando un proyecto estable? Si es así, ¡esta es tu oportunidad! Desde el canal MRX de LHH estamos buscando un Talent Acquisition Specialist IT para uno de nuestros clientes en Madrid.\n- Buscamos una persona habituada a realizar búsquedas de perfiles de Ciberseguridad, IA, Data Scientist, Data Engineer, Java, Desarrolladores, Programdores, DevOps, ...\n- Es muy valorable que tengas un buen manejo en inglés.\n- Formarás parte de un equipo que te acompañará desde el primer día y dispondrás de un plan de formación inicial para facilitar tu adaptación a esta nueva etapa de tu trayectoria laboral.\n- Se trata de un proyecto estable. Podrás crecer profesionalmente y alcanzar tu plan de carrera gracias a la formación que tendrás a tu disposición y que te permitirá adquirir nuevos conocimientos, habilidades y destrezas.\n- Trabajarás de lunes a viernes de 9 a 18h, y disfrutarás de un salario competitivo y con un gran número de beneficios sociales a los que tendrás acceso desde el primer día de incorporación (seguro médico, formación, ticket guardería, etc.).\nTipo de industria de la oferta\nOtras actividades\nCategoría\nRecursos humanos - Selección de personal\nNivel\nEspecialista\nNúmero de vacantes\n1\nHorario\nPartido\nSalario\nSalario no disponible\nBeneficios sociales\nTeletrabajo\n110 inscritos a esta oferta\nNuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.\nDenunciar oferta\nLos datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "descripcion_original": "<br><h3>Requisitos</h3><br><h4>Estudios mínimos</h4><br>Grado - Grado en Relaciones Laborales y Recursos Humanos<br><h4>Experiencia mínima</h4><br>Al menos 2 años<br>Imprescindible residente en<br>Provincia Puesto Vacante<br>Idiomas requeridos<br>Inglés - Nivel Avanzado<br>Conocimientos necesarios<br>Selección de personal<br>Entrevistas basadas en las competencias<br>Técnicas de selección de personal<br>Fuentes de reclutamiento<br><br><h3><br><h3>Requisitos</h3> mínimos</h3><br>Experiencia de al menos 2 años en selección de perfiles IT.<br>Imprescindible buen conocimiento del sector IT y sus Perfiles: Ciberseguridad, Data, Sistemas, Desarrollo, ...<br>Inglés: B2-C1<br><br><h3>Descripción</h3><br>Si te apasionan las personas, y si tu respuesta a las siguientes preguntas es afirmativa, ¡has encontrado tu sitio!.¿Tienes experiencia en reclutamiento y selección de personal del sector IT? ¿Estas habituado a realizar selección en inglés? ¿Estás buscando un proyecto estable? Si es así, ¡esta es tu oportunidad! Desde el canal MRX de LHH estamos buscando un Talent Acquisition Specialist IT para uno de nuestros clientes en Madrid.<br>- Buscamos una persona habituada a realizar búsquedas de perfiles de Ciberseguridad, IA, Data Scientist, Data Engineer, Java, Desarrolladores, Programdores, DevOps, ...<br>- Es muy valorable que tengas un buen manejo en inglés.<br>- Formarás parte de un equipo que te acompañará desde el primer día y dispondrás de un plan de formación inicial para facilitar tu adaptación a esta nueva etapa de tu trayectoria laboral.<br>- Se trata de un proyecto estable. Podrás crecer profesionalmente y alcanzar tu plan de carrera gracias a la formación que tendrás a tu disposición y que te permitirá adquirir nuevos conocimientos, habilidades y destrezas.<br>- Trabajarás de lunes a viernes de 9 a 18h, y disfrutarás de un salario competitivo y con un gran número de beneficios sociales a los que tendrás acceso desde el primer día de incorporación (seguro médico, formación, ticket guardería, etc.).<br>Tipo de industria de la oferta<br>Otras actividades<br>Categoría<br>Recursos humanos - Selección de personal<br>Nivel<br>Especialista<br>Número de vacantes<br>1<br>Horario<br>Partido<br>Salario<br>Salario no disponible<br>Beneficios sociales<br>Teletrabajo<br>110 inscritos a esta oferta<br>Nuestro consejo: inscríbete si tienes el perfil, puede que se ajuste más que el de otros inscritos.<br>Denunciar oferta<br>Los datos bancarios, de pago y datos personales (DNI, foto) nunca deben proporcionarse al solicitar un empleo. Consulta nuestros consejos para una búsqueda de empleo segura.",
        "transformacion": {
            "nivel_ingles": "C1",
            "anios_experiencia": "2",
            "porcentaje": "50",
            "skills_necesarias": [
                "Selección de personal",
                "Entrevistas basadas en competencias",
                "Técnicas de selección de personal",
                "Fuentes de reclutamiento"
            ],
            "skills_valoradas": [
                "Ciberseguridad",
                "Data",
                "Sistemas",
                "Desarrollo",
                "IA"
            ]
        }
    }
]